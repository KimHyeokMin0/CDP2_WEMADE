{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 환경 세팅"
      ],
      "metadata": {
        "id": "KdS30midVNQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYf6_qhT4F0-",
        "outputId": "a17e029a-9412-4e62-f52c-e842eca56fe4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.15.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.15.0"
      ],
      "metadata": {
        "id": "KuYBiwac_VDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d7c4d2-0036-49c2-8365-97a41d5055e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow_decision_forests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2CxArSj_WpO",
        "outputId": "8de1526a-228c-4007-907f-198f97a82bb1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow_decision_forests as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_decision_forests==1.8.0"
      ],
      "metadata": {
        "id": "lvGuPqak_bYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de320e3-2af7-426b-8763-b5b815dff9f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_decision_forests==1.8.0\n",
            "  Downloading tensorflow_decision_forests-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests==1.8.0) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests==1.8.0) (2.0.3)\n",
            "Requirement already satisfied: tensorflow~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests==1.8.0) (2.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests==1.8.0) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests==1.8.0) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests==1.8.0) (0.43.0)\n",
            "Collecting wurlitzer (from tensorflow_decision_forests==1.8.0)\n",
            "  Downloading wurlitzer-3.1.0-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests==1.8.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests==1.8.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests==1.8.0) (2024.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.0) (3.2.2)\n",
            "Installing collected packages: wurlitzer, tensorflow_decision_forests\n",
            "Successfully installed tensorflow_decision_forests-1.8.0 wurlitzer-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MJ_obTDq4Rx",
        "outputId": "cfd3f8d4-e99c-4bd5-9a3f-b70e567a1028"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-4.19.0-py3-none-any.whl (89 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m81.9/89.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flax>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.8.3)\n",
            "Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (6.4.0)\n",
            "Requirement already satisfied: jax>=0.4.13 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.26)\n",
            "Requirement already satisfied: jaxlib>=0.4.13 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: tensorflow<3,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (2.15.0)\n",
            "Requirement already satisfied: tf-keras>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-decision-forests>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (1.8.0)\n",
            "Requirement already satisfied: six<2,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.16.1)\n",
            "Collecting packaging~=23.1 (from tensorflowjs)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (1.25.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (1.0.8)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (0.2.2)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (13.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->tensorflowjs) (1.11.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (18.1.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.0.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.43.0)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (2.16.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.0.3)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->flax>=0.7.2->tensorflowjs) (0.1.86)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.7.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2024.1)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->flax>=0.7.2->tensorflowjs) (0.12.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (2023.6.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.18.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.2.2)\n",
            "Installing collected packages: packaging, tensorflowjs\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed packaging-23.2 tensorflowjs-4.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습/검증 데이터 수집"
      ],
      "metadata": {
        "id": "hEPNEvZjXQuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그 전에 mount하기\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgbAnw-bxj00",
        "outputId": "c0ec3287-7bef-46e8-ae28-87d3ba5bc09e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflowjs as tfjs"
      ],
      "metadata": {
        "id": "3tOmVT9txkri"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 2005\n",
        "\n",
        "data05 = pd.read_sas('/content/drive/MyDrive/datasets/hn05_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected05 = data05[['DI1_dg', 'sex', 'age', 'HE_SBP', 'HE_DBP', 'HE_PLS']]\n",
        "selected05.rename(columns={'HE_SBP': 'HE_sbp'}, inplace=True)\n",
        "selected05.rename(columns={'HE_DBP': 'HE_dbp'}, inplace=True)\n",
        "\n",
        "# 체질량지수가 존재하지 않아 키와 체중 값을 사용해 가공 (신장 : HE_HT, 체중: HE_WT)\n",
        "selected05['HE_BMI'] = data05['HE_WT'] / ((data05['HE_HT'] / 100) ** 2)\n",
        "\n",
        "#흡연 여부\n",
        "selected05['sm_present'] = ((data05['BS1_1'].isin([1, 2])) & (data05['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주3회 이상 걷기 운동을 30분이상 실천한 여부\n",
        "selected05['pa_walk'] = (data05['BE3_31'].isin([4, 5, 6, 7, 8]) & data05['BE3_32'].isin([3, 4, 5, 6])).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : BR1 (모름 : 99)\n",
        "selected05['total_sleep'] = np.where(data05['BR1'].isin([99]), None, data05['BR1'])\n",
        "\n",
        "print(selected05.shape)\n",
        "selected05 = selected05.dropna()\n",
        "idx = selected05[selected05['DI1_dg'] == 8].index\n",
        "selected05 = selected05.drop(idx)\n",
        "print(selected05.shape)\n",
        "\n",
        "\n",
        "# 07 / 08 / 09\n",
        "\n",
        "data07 = pd.read_sas('/content/drive/MyDrive/datasets/hn07_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected07 = data07[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS', 'HE_BMI']]\n",
        "\n",
        "#흡연 여부\n",
        "selected07['sm_present'] = ((data07['BS1_1'].isin([1, 2])) & (data07['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주3회 이상 걷기 운동을 30분이상 실천한 여부\n",
        "data07['pa_hb30_1'] = np.where((data07['BE3_32'].isin([88,99]) | data07['BE3_33'].isin([88,99])), 0, data07['BE3_32'] * 60 + data07['BE3_33'])\n",
        "selected07['pa_walk'] = (data07['BE3_31'].isin([4, 5, 6, 7, 8]) & (data07['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : BP8 (모름 : 99)\n",
        "selected07['total_sleep'] = np.where(data07['BP8'].isin([99]), None, data07['BP8'])\n",
        "\n",
        "print(selected07.shape)\n",
        "selected07 = selected07.dropna()\n",
        "idx = selected07[selected07['DI1_dg'] == 8].index\n",
        "selected07 = selected07.drop(idx)\n",
        "print(selected07.shape)\n",
        "print('-' * 20)\n",
        "\n",
        "\n",
        "data08 = pd.read_sas('/content/drive/MyDrive/datasets/hn08_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected08 = data08[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS', 'HE_BMI']]\n",
        "\n",
        "#흡연 여부\n",
        "selected08['sm_present'] = ((data08['BS1_1'].isin([1, 2])) & (data08['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주3회 이상 걷기 운동을 30분이상 실천한 여부\n",
        "data08['pa_hb30_1'] = np.where((data08['BE3_32'].isin([88,99]) | data08['BE3_33'].isin([88,99])), 0, data08['BE3_32'] * 60 + data08['BE3_33'])\n",
        "selected08['pa_walk'] = (data08['BE3_31'].isin([4, 5, 6, 7, 8]) & (data08['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : BP8 (모름 : 99)\n",
        "selected08['total_sleep'] = np.where(data08['BP8'].isin([99]), None, data08['BP8'])\n",
        "\n",
        "print(selected08.shape)\n",
        "selected08 = selected08.dropna()\n",
        "idx = selected08[selected08['DI1_dg'] == 8].index\n",
        "selected08 = selected08.drop(idx)\n",
        "print(selected08.shape)\n",
        "print('-' * 20)\n",
        "\n",
        "\n",
        "data09 = pd.read_sas('/content/drive/MyDrive/datasets/hn09_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected09 = data09[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS', 'HE_BMI']]\n",
        "\n",
        "#흡연 여부\n",
        "selected09['sm_present'] = ((data09['BS1_1'].isin([1, 2])) & (data09['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주3회 이상 걷기 운동을 30분이상 실천한 여부\n",
        "data09['pa_hb30_1'] = np.where((data09['BE3_32'].isin([88,99]) | data09['BE3_33'].isin([88,99])), 0, data09['BE3_32'] * 60 + data09['BE3_33'])\n",
        "selected09['pa_walk'] = (data09['BE3_31'].isin([4, 5, 6, 7, 8]) & (data09['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : BP8 (모름 : 99)\n",
        "selected09['total_sleep'] = np.where(data09['BP8'].isin([99]), None, data09['BP8'])\n",
        "\n",
        "print(selected09.shape)\n",
        "selected09 = selected09.dropna()\n",
        "idx = selected09[selected09['DI1_dg'] == 8].index\n",
        "selected09 = selected09.drop(idx)\n",
        "print(selected09.shape)\n",
        "\n",
        "\n",
        "# 10 / 11 / 12\n",
        "data10 = pd.read_sas('/content/drive/MyDrive/datasets/hn10_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected10 = data10[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS', 'HE_BMI']]\n",
        "\n",
        "#흡연 여부\n",
        "selected10['sm_present'] = ((data10['BS1_1'].isin([1, 2])) & (data10['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주3회 이상 걷기 운동을 30분이상 실천한 여부\n",
        "data10['pa_hb30_1'] = np.where((data10['BE3_32'].isin([88,99]) | data10['BE3_33'].isin([88,99])), 0, data10['BE3_32'] * 60 + data10['BE3_33'])\n",
        "selected10['pa_walk'] = (data10['BE3_31'].isin([4, 5, 6, 7, 8]) & (data10['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : BP8 (비해당 : 88, 모름 : 99)\n",
        "selected10['total_sleep'] = np.where(data10['BP8'].isin([88, 99]), None, data10['BP8'])\n",
        "\n",
        "print(selected10.shape)\n",
        "selected10 = selected10.dropna()\n",
        "idx = selected10[selected10['DI1_dg'] == 8].index\n",
        "selected10 = selected10.drop(idx)\n",
        "print(selected10.shape)\n",
        "print('-' * 20)\n",
        "\n",
        "\n",
        "data11 = pd.read_sas('/content/drive/MyDrive/datasets/hn11_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected11 = data11[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS', 'HE_BMI']]\n",
        "\n",
        "#흡연 여부\n",
        "selected11['sm_present'] = ((data11['BS1_1'].isin([1, 2])) & (data11['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주3회 이상 걷기 운동을 30분이상 실천한 여부\n",
        "data11['pa_hb30_1'] = np.where((data11['BE3_32'].isin([88,99]) | data11['BE3_33'].isin([88,99])), 0, data11['BE3_32'] * 60 + data11['BE3_33'])\n",
        "selected11['pa_walk'] = (data11['BE3_31'].isin([4, 5, 6, 7, 8]) & (data11['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : BP8 (비해당 : 88, 모름 : 99)\n",
        "selected11['total_sleep'] = np.where(data11['BP8'].isin([88, 99]), None, data11['BP8'])\n",
        "\n",
        "print(selected11.shape)\n",
        "selected11 = selected11.dropna()\n",
        "idx = selected11[selected11['DI1_dg'] == 8].index\n",
        "selected11 = selected11.drop(idx)\n",
        "print(selected11.shape)\n",
        "print('-' * 20)\n",
        "\n",
        "\n",
        "data12 = pd.read_sas('/content/drive/MyDrive/datasets/hn12_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected12 = data12[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS', 'HE_BMI']]\n",
        "\n",
        "#흡연 여부\n",
        "selected12['sm_present'] = ((data12['BS1_1'].isin([1, 2])) & (data12['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주3회 이상 걷기 운동을 30분이상 실천한 여부\n",
        "data12['pa_hb30_1'] = np.where((data12['BE3_32'].isin([88,99]) | data12['BE3_33'].isin([88,99])), 0, data12['BE3_32'] * 60 + data12['BE3_33'])\n",
        "selected12['pa_walk'] = (data12['BE3_31'].isin([4, 5, 6, 7, 8]) & (data12['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : BP8 (비해당 : 88, 모름 : 99)\n",
        "selected12['total_sleep'] = np.where(data12['BP8'].isin([88, 99]), None, data12['BP8'])\n",
        "\n",
        "print(selected12.shape)\n",
        "selected12 = selected12.dropna()\n",
        "idx = selected12[selected12['DI1_dg'] == 8].index\n",
        "selected12 = selected12.drop(idx)\n",
        "print(selected12.shape)\n",
        "\n",
        "\n",
        "# 13 / 14 / 15\n",
        "\n",
        "data13 = pd.read_sas('/content/drive/MyDrive/datasets/hn13_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected13 = data13[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS', 'HE_BMI']]\n",
        "\n",
        "#흡연 여부\n",
        "selected13['sm_present'] = ((data13['BS1_1'].isin([1, 2])) & (data13['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주3회 이상 걷기 운동을 30분이상 실천한 여부\n",
        "data13['pa_hb30_1'] = np.where((data13['BE3_32'].isin([88,99]) | data13['BE3_33'].isin([88,99])), 0, data13['BE3_32'] * 60 + data13['BE3_33'])\n",
        "selected13['pa_walk'] = (data13['BE3_31'].isin([4, 5, 6, 7, 8]) & (data13['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : BP8 (비해당 : 88, 모름 : 99)\n",
        "selected13['total_sleep'] = np.where(data13['BP8'].isin([88, 99]), None, data13['BP8'])\n",
        "\n",
        "print(selected13.shape)\n",
        "selected13 = selected13.dropna()\n",
        "idx = selected13[selected13['DI1_dg'] == 8].index\n",
        "selected13 = selected13.drop(idx)\n",
        "print(selected13.shape)\n",
        "print('-' * 20)\n",
        "\n",
        "\n",
        "data14 = pd.read_sas('/content/drive/MyDrive/datasets/hn14_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected14 = data14[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS', 'HE_BMI']]\n",
        "\n",
        "#흡연 여부\n",
        "selected14['sm_present'] = ((data14['BS1_1'].isin([1, 2])) & (data14['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주3회 이상 걷기 운동을 30분이상 실천한 여부\n",
        "data14['pa_hb30_1'] = np.where((data14['BE3_32'].isin([88,99]) | data14['BE3_33'].isin([88,99])), 0, data14['BE3_32'] * 60 + data14['BE3_33'])\n",
        "selected14['pa_walk'] = (data14['BE3_31'].isin([4, 5, 6, 7, 8]) & (data14['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : BP8 (비해당 : 88, 모름 : 99)\n",
        "selected14['total_sleep'] = np.where(data14['BP8'].isin([88, 99]), None, data14['BP8'])\n",
        "\n",
        "print(selected14.shape)\n",
        "selected14 = selected14.dropna()\n",
        "idx = selected14[selected14['DI1_dg'] == 8].index\n",
        "selected14 = selected14.drop(idx)\n",
        "print(selected14.shape)\n",
        "print('-' * 20)\n",
        "\n",
        "\n",
        "data15 = pd.read_sas('/content/drive/MyDrive/datasets/hn15_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected15 = data15[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS', 'HE_BMI']]\n",
        "\n",
        "#흡연 여부\n",
        "selected15['sm_present'] = ((data15['BS1_1'].isin([1, 2])) & (data15['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주3회 이상 걷기 운동을 30분이상 실천한 여부\n",
        "data15['pa_hb30_1'] = np.where((data15['BE3_32'].isin([88,99]) | data15['BE3_33'].isin([88,99])), 0, data15['BE3_32'] * 60 + data15['BE3_33'])\n",
        "selected15['pa_walk'] = (data15['BE3_31'].isin([4, 5, 6, 7, 8]) & (data15['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : BP8 (비해당 : 88, 모름 : 99)\n",
        "selected15['total_sleep'] = np.where(data15['BP8'].isin([88, 99]), None, data15['BP8'])\n",
        "\n",
        "print(selected15.shape)\n",
        "selected15 = selected15.dropna()\n",
        "idx = selected15[selected15['DI1_dg'] == 8].index\n",
        "selected15 = selected15.drop(idx)\n",
        "print(selected15.shape)\n",
        "\n",
        "\n",
        "# 16 / 17 / 18\n",
        "\n",
        "data16 = pd.read_sas('/content/drive/MyDrive/datasets/hn16_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected16 = data16[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS', 'HE_BMI']]\n",
        "\n",
        "#흡연 여부\n",
        "selected16['sm_present'] = ((data16['BS1_1'].isin([1, 2])) & (data16['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주5회 걷기 운동을 30분이상 실천한 여부\n",
        "data16['pa_hb30_1'] = np.where((data16['BE3_32'].isin([88,99]) | data16['BE3_33'].isin([88,99])), 0, data16['BE3_32'] * 60 + data16['BE3_33'])\n",
        "selected16['pa_walk'] = (data16['BE3_31'].isin([4, 5, 6, 7, 8]) & (data16['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : Total_slp_wk (모름 : 99)\n",
        "selected16['total_sleep'] = np.where(data16['Total_slp_wk'].isin([8888, 9999]), None, data16['Total_slp_wk'] / 60)\n",
        "\n",
        "print(selected16.shape)\n",
        "selected16 = selected16.dropna()\n",
        "idx = selected16[selected16['DI1_dg'] == 8].index\n",
        "selected16 = selected16.drop(idx)\n",
        "print(selected16.shape)\n",
        "\n",
        "\n",
        "data17 = pd.read_sas('/content/drive/MyDrive/datasets/hn17_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected17 = data17[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS', 'HE_BMI']]\n",
        "\n",
        "#흡연 여부\n",
        "selected17['sm_present'] = ((data17['BS1_1'].isin([1, 2])) & (data17['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주5회 걷기 운동을 30분이상 실천한 여부\n",
        "data17['pa_hb30_1'] = np.where((data17['BE3_32'].isin([88,99]) | data17['BE3_33'].isin([88,99])), 0, data17['BE3_32'] * 60 + data17['BE3_33'])\n",
        "selected17['pa_walk'] = (data17['BE3_31'].isin([4, 5, 6, 7, 8]) & (data17['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : Total_slp_wk (모름 : 99)\n",
        "selected17['total_sleep'] = np.where(data17['Total_slp_wk'].isin([8888, 9999]), None, data17['Total_slp_wk'] / 60)\n",
        "\n",
        "print(selected17.shape)\n",
        "selected17 = selected17.dropna()\n",
        "idx = selected17[selected17['DI1_dg'] == 8].index\n",
        "selected17 = selected17.drop(idx)\n",
        "print(selected17.shape)\n",
        "\n",
        "\n",
        "data18 = pd.read_sas('/content/drive/MyDrive/datasets/hn18_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected18 = data18[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS', 'HE_BMI']]\n",
        "\n",
        "#흡연 여부\n",
        "selected18['sm_present'] = ((data18['BS1_1'].isin([1, 2])) & (data18['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주5회 걷기 운동을 30분이상 실천한 여부\n",
        "data18['pa_hb30_1'] = np.where((data18['BE3_32'].isin([88,99]) | data18['BE3_33'].isin([88,99])), 0, data18['BE3_32'] * 60 + data18['BE3_33'])\n",
        "selected18['pa_walk'] = (data18['BE3_31'].isin([4, 5, 6, 7, 8]) & (data18['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간 : Total_slp_wk (모름 : 99)\n",
        "selected18['total_sleep'] = np.where(data18['Total_slp_wk'].isin([8888, 9999]), None, data18['Total_slp_wk'] / 60)\n",
        "\n",
        "print(selected18.shape)\n",
        "selected18 = selected18.dropna()\n",
        "idx = selected18[selected18['DI1_dg'] == 8].index\n",
        "selected18 = selected18.drop(idx)\n",
        "print(selected18.shape)\n",
        "\n",
        "\n",
        "# 19 / 20 / 21\n",
        "\n",
        "data19 = pd.read_sas('/content/drive/MyDrive/datasets/hn19_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected19 = data19[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS_15', 'HE_BMI']]\n",
        "selected19.rename(columns={'HE_PLS_15': 'HE_PLS'}, inplace=True)\n",
        "\n",
        "#흡연 여부\n",
        "selected19['sm_present'] = ((data19['BS1_1'].isin([1, 2])) & (data19['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주5회 걷기 운동을 30분이상 실천한 여부\n",
        "data19['pa_hb30_1'] = np.where((data19['BE3_32'].isin([88,99]) | data19['BE3_33'].isin([88,99])), 0, data19['BE3_32'] * 60 + data19['BE3_33'])\n",
        "selected19['pa_walk'] = (data19['BE3_31'].isin([4, 5, 6, 7, 8]) & (data19['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간\n",
        "selected19['total_sleep'] = np.where(data19['BP16_1'].isin([88, 99]), None, data19['BP16_1'])\n",
        "\n",
        "print(selected19.shape)\n",
        "selected19 = selected19.dropna()\n",
        "idx = selected19[selected19['DI1_dg'] == 8].index\n",
        "selected19 = selected19.drop(idx)\n",
        "print(selected19.shape)\n",
        "\n",
        "\n",
        "data20 = pd.read_sas('/content/drive/MyDrive/datasets/hn20_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected20 = data20[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS_30', 'HE_BMI']]\n",
        "selected20['HE_PLS_30'] = round(selected20['HE_PLS_30'] / 2)\n",
        "selected20.rename(columns={'HE_PLS_30': 'HE_PLS'}, inplace=True)\n",
        "\n",
        "#흡연 여부\n",
        "selected20['sm_present'] = ((data20['BS1_1'].isin([1, 2])) & (data20['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주5회 걷기 운동을 30분이상 실천한 여부\n",
        "data20['pa_hb30_1'] = np.where((data20['BE3_32'].isin([88,99]) | data20['BE3_33'].isin([88,99])), 0, data20['BE3_32'] * 60 + data20['BE3_33'])\n",
        "selected20['pa_walk'] = (data20['BE3_31'].isin([4, 5, 6, 7, 8]) & (data20['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간\n",
        "selected20['total_sleep'] = np.where(data20['BP16_1'].isin([88, 99]), None, data20['BP16_1'])\n",
        "\n",
        "print(selected20.shape)\n",
        "selected20 = selected20.dropna()\n",
        "idx = selected20[selected20['DI1_dg'] == 8].index\n",
        "selected20 = selected20.drop(idx)\n",
        "print(selected20.shape)\n",
        "\n",
        "\n",
        "data21 = pd.read_sas('/content/drive/MyDrive/datasets/hn21_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected21 = data21[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS_30', 'HE_BMI']]\n",
        "selected21['HE_PLS_30'] = round(selected21['HE_PLS_30'] / 2)\n",
        "selected21.rename(columns={'HE_PLS_30': 'HE_PLS'}, inplace=True)\n",
        "\n",
        "#흡연 여부\n",
        "selected21['sm_present'] = ((data21['BS1_1'].isin([1, 2])) & (data21['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주5회 걷기 운동을 30분이상 실천한 여부\n",
        "data21['pa_hb30_1'] = np.where((data21['BE3_32'].isin([88,99]) | data21['BE3_33'].isin([88,99])), 0, data21['BE3_32'] * 60 + data21['BE3_33'])\n",
        "selected21['pa_walk'] = (data21['BE3_31'].isin([4, 5, 6, 7, 8]) & (data21['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간\n",
        "\n",
        "selected21['total_sleep'] = np.where((data21['BP16_11'].isin([88,99]) | data21['BP16_12'].isin([88,99]) | data21['BP16_13'].isin([88,99]) | data21['BP16_14'].isin([88,99])),\n",
        "                         None, (data21['BP16_13'] + 24+ data21['BP16_14']/60 - (data21['BP16_11'] + 24 + data21['BP16_12']/60) + 24)%24)\n",
        "\n",
        "print(selected21.shape)\n",
        "selected21 = selected21.dropna()\n",
        "idx = selected21[selected21['DI1_dg'] == 8].index\n",
        "selected21 = selected21.drop(idx)\n",
        "print(selected21.shape)\n",
        "\n",
        "\n",
        "# 22\n",
        "\n",
        "data22 = pd.read_sas('/content/drive/MyDrive/datasets/hn22_all.sas7bdat', format = 'sas7bdat')\n",
        "\n",
        "selected22 = data22[['DI1_dg', 'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_PLS_30', 'HE_BMI']]\n",
        "selected22['HE_PLS_30'] = round(selected22['HE_PLS_30'] / 2)\n",
        "selected22.rename(columns={'HE_PLS_30': 'HE_PLS'}, inplace=True)\n",
        "\n",
        "#흡연 여부\n",
        "selected22['sm_present'] = ((data22['BS1_1'].isin([1, 2])) & (data22['BS3_1'].isin([1, 2]))).astype(int)\n",
        "\n",
        "#pa_walk : 주5회 걷기 운동을 30분이상 실천한 여부\n",
        "data22['pa_hb30_1'] = np.where((data22['BE3_32'].isin([88,99]) | data22['BE3_33'].isin([88,99])), 0, data22['BE3_32'] * 60 + data22['BE3_33'])\n",
        "selected22['pa_walk'] = (data22['BE3_31'].isin([4, 5, 6, 7, 8]) & (data22['pa_hb30_1'] >= 30)).astype(int)\n",
        "\n",
        "# 하루 평균 수면시간\n",
        "selected22['total_sleep'] = np.where(data22['BP16_1'].isin([88, 99]), None, data22['BP16_1'])\n",
        "\n",
        "print(selected22.shape)\n",
        "selected22 = selected22.dropna()\n",
        "idx = selected22[selected22['DI1_dg'] == 8].index\n",
        "selected22 = selected22.drop(idx)\n",
        "print(selected22.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77edd4c-41ca-423d-eacb-6ca77ba5effc",
        "collapsed": true,
        "id": "E0J0rqfWXfMN"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected05.rename(columns={'HE_SBP': 'HE_sbp'}, inplace=True)\n",
            "<ipython-input-8-af51349857b2>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected05.rename(columns={'HE_DBP': 'HE_dbp'}, inplace=True)\n",
            "<ipython-input-8-af51349857b2>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected05['HE_BMI'] = data05['HE_WT'] / ((data05['HE_HT'] / 100) ** 2)\n",
            "<ipython-input-8-af51349857b2>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected05['sm_present'] = ((data05['BS1_1'].isin([1, 2])) & (data05['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected05['pa_walk'] = (data05['BE3_31'].isin([4, 5, 6, 7, 8]) & data05['BE3_32'].isin([3, 4, 5, 6])).astype(int)\n",
            "<ipython-input-8-af51349857b2>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected05['total_sleep'] = np.where(data05['BR1'].isin([99]), None, data05['BR1'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34145, 10)\n",
            "(854, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected07['sm_present'] = ((data07['BS1_1'].isin([1, 2])) & (data07['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data07['pa_hb30_1'] = np.where((data07['BE3_32'].isin([88,99]) | data07['BE3_33'].isin([88,99])), 0, data07['BE3_32'] * 60 + data07['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected07['pa_walk'] = (data07['BE3_31'].isin([4, 5, 6, 7, 8]) & (data07['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected07['total_sleep'] = np.where(data07['BP8'].isin([99]), None, data07['BP8'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4594, 10)\n",
            "(490, 10)\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:60: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected08['sm_present'] = ((data08['BS1_1'].isin([1, 2])) & (data08['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data08['pa_hb30_1'] = np.where((data08['BE3_32'].isin([88,99]) | data08['BE3_33'].isin([88,99])), 0, data08['BE3_32'] * 60 + data08['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:64: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected08['pa_walk'] = (data08['BE3_31'].isin([4, 5, 6, 7, 8]) & (data08['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected08['total_sleep'] = np.where(data08['BP8'].isin([99]), None, data08['BP8'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9744, 10)\n",
            "(1308, 10)\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:82: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected09['sm_present'] = ((data09['BS1_1'].isin([1, 2])) & (data09['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data09['pa_hb30_1'] = np.where((data09['BE3_32'].isin([88,99]) | data09['BE3_33'].isin([88,99])), 0, data09['BE3_32'] * 60 + data09['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:86: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected09['pa_walk'] = (data09['BE3_31'].isin([4, 5, 6, 7, 8]) & (data09['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:89: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected09['total_sleep'] = np.where(data09['BP8'].isin([99]), None, data09['BP8'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10533, 10)\n",
            "(1447, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:104: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected10['sm_present'] = ((data10['BS1_1'].isin([1, 2])) & (data10['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data10['pa_hb30_1'] = np.where((data10['BE3_32'].isin([88,99]) | data10['BE3_33'].isin([88,99])), 0, data10['BE3_32'] * 60 + data10['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:108: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected10['pa_walk'] = (data10['BE3_31'].isin([4, 5, 6, 7, 8]) & (data10['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected10['total_sleep'] = np.where(data10['BP8'].isin([88, 99]), None, data10['BP8'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8958, 10)\n",
            "(1258, 10)\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:126: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected11['sm_present'] = ((data11['BS1_1'].isin([1, 2])) & (data11['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:129: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data11['pa_hb30_1'] = np.where((data11['BE3_32'].isin([88,99]) | data11['BE3_33'].isin([88,99])), 0, data11['BE3_32'] * 60 + data11['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:130: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected11['pa_walk'] = (data11['BE3_31'].isin([4, 5, 6, 7, 8]) & (data11['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:133: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected11['total_sleep'] = np.where(data11['BP8'].isin([88, 99]), None, data11['BP8'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8518, 10)\n",
            "(1255, 10)\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:148: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected12['sm_present'] = ((data12['BS1_1'].isin([1, 2])) & (data12['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data12['pa_hb30_1'] = np.where((data12['BE3_32'].isin([88,99]) | data12['BE3_33'].isin([88,99])), 0, data12['BE3_32'] * 60 + data12['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:152: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected12['pa_walk'] = (data12['BE3_31'].isin([4, 5, 6, 7, 8]) & (data12['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:155: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected12['total_sleep'] = np.where(data12['BP8'].isin([88, 99]), None, data12['BP8'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8058, 10)\n",
            "(1162, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:171: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected13['sm_present'] = ((data13['BS1_1'].isin([1, 2])) & (data13['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data13['pa_hb30_1'] = np.where((data13['BE3_32'].isin([88,99]) | data13['BE3_33'].isin([88,99])), 0, data13['BE3_32'] * 60 + data13['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:175: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected13['pa_walk'] = (data13['BE3_31'].isin([4, 5, 6, 7, 8]) & (data13['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected13['total_sleep'] = np.where(data13['BP8'].isin([88, 99]), None, data13['BP8'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8018, 10)\n",
            "(4841, 10)\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:193: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected14['sm_present'] = ((data14['BS1_1'].isin([1, 2])) & (data14['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data14['pa_hb30_1'] = np.where((data14['BE3_32'].isin([88,99]) | data14['BE3_33'].isin([88,99])), 0, data14['BE3_32'] * 60 + data14['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:197: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected14['pa_walk'] = (data14['BE3_31'].isin([4, 5, 6, 7, 8]) & (data14['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:200: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected14['total_sleep'] = np.where(data14['BP8'].isin([88, 99]), None, data14['BP8'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7550, 10)\n",
            "(4851, 10)\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:215: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected15['sm_present'] = ((data15['BS1_1'].isin([1, 2])) & (data15['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:218: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data15['pa_hb30_1'] = np.where((data15['BE3_32'].isin([88,99]) | data15['BE3_33'].isin([88,99])), 0, data15['BE3_32'] * 60 + data15['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:219: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected15['pa_walk'] = (data15['BE3_31'].isin([4, 5, 6, 7, 8]) & (data15['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:222: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected15['total_sleep'] = np.where(data15['BP8'].isin([88, 99]), None, data15['BP8'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7380, 10)\n",
            "(4947, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:238: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected16['sm_present'] = ((data16['BS1_1'].isin([1, 2])) & (data16['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:241: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data16['pa_hb30_1'] = np.where((data16['BE3_32'].isin([88,99]) | data16['BE3_33'].isin([88,99])), 0, data16['BE3_32'] * 60 + data16['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:242: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected16['pa_walk'] = (data16['BE3_31'].isin([4, 5, 6, 7, 8]) & (data16['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:245: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected16['total_sleep'] = np.where(data16['Total_slp_wk'].isin([8888, 9999]), None, data16['Total_slp_wk'] / 60)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8150, 10)\n",
            "(5340, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:259: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected17['sm_present'] = ((data17['BS1_1'].isin([1, 2])) & (data17['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:262: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data17['pa_hb30_1'] = np.where((data17['BE3_32'].isin([88,99]) | data17['BE3_33'].isin([88,99])), 0, data17['BE3_32'] * 60 + data17['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:263: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected17['pa_walk'] = (data17['BE3_31'].isin([4, 5, 6, 7, 8]) & (data17['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:266: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected17['total_sleep'] = np.where(data17['Total_slp_wk'].isin([8888, 9999]), None, data17['Total_slp_wk'] / 60)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8127, 10)\n",
            "(5344, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:280: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected18['sm_present'] = ((data18['BS1_1'].isin([1, 2])) & (data18['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:283: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data18['pa_hb30_1'] = np.where((data18['BE3_32'].isin([88,99]) | data18['BE3_33'].isin([88,99])), 0, data18['BE3_32'] * 60 + data18['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:284: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected18['pa_walk'] = (data18['BE3_31'].isin([4, 5, 6, 7, 8]) & (data18['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:287: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected18['total_sleep'] = np.where(data18['Total_slp_wk'].isin([8888, 9999]), None, data18['Total_slp_wk'] / 60)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7992, 10)\n",
            "(5470, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:301: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected19.rename(columns={'HE_PLS_15': 'HE_PLS'}, inplace=True)\n",
            "<ipython-input-8-af51349857b2>:304: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected19['sm_present'] = ((data19['BS1_1'].isin([1, 2])) & (data19['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:307: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data19['pa_hb30_1'] = np.where((data19['BE3_32'].isin([88,99]) | data19['BE3_33'].isin([88,99])), 0, data19['BE3_32'] * 60 + data19['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected19['pa_walk'] = (data19['BE3_31'].isin([4, 5, 6, 7, 8]) & (data19['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:311: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected19['total_sleep'] = np.where(data19['BP16_1'].isin([88, 99]), None, data19['BP16_1'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8110, 10)\n",
            "(5695, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:323: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected20['HE_PLS_30'] = round(selected20['HE_PLS_30'] / 2)\n",
            "<ipython-input-8-af51349857b2>:324: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected20.rename(columns={'HE_PLS_30': 'HE_PLS'}, inplace=True)\n",
            "<ipython-input-8-af51349857b2>:327: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected20['sm_present'] = ((data20['BS1_1'].isin([1, 2])) & (data20['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:330: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data20['pa_hb30_1'] = np.where((data20['BE3_32'].isin([88,99]) | data20['BE3_33'].isin([88,99])), 0, data20['BE3_32'] * 60 + data20['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:331: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected20['pa_walk'] = (data20['BE3_31'].isin([4, 5, 6, 7, 8]) & (data20['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:334: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected20['total_sleep'] = np.where(data20['BP16_1'].isin([88, 99]), None, data20['BP16_1'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7359, 10)\n",
            "(5180, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:346: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected21['HE_PLS_30'] = round(selected21['HE_PLS_30'] / 2)\n",
            "<ipython-input-8-af51349857b2>:347: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected21.rename(columns={'HE_PLS_30': 'HE_PLS'}, inplace=True)\n",
            "<ipython-input-8-af51349857b2>:350: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected21['sm_present'] = ((data21['BS1_1'].isin([1, 2])) & (data21['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:353: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data21['pa_hb30_1'] = np.where((data21['BE3_32'].isin([88,99]) | data21['BE3_33'].isin([88,99])), 0, data21['BE3_32'] * 60 + data21['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:354: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected21['pa_walk'] = (data21['BE3_31'].isin([4, 5, 6, 7, 8]) & (data21['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:358: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected21['total_sleep'] = np.where((data21['BP16_11'].isin([88,99]) | data21['BP16_12'].isin([88,99]) | data21['BP16_13'].isin([88,99]) | data21['BP16_14'].isin([88,99])),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7090, 10)\n",
            "(4613, 10)\n",
            "(6265, 10)\n",
            "(4393, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-af51349857b2>:373: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected22['HE_PLS_30'] = round(selected22['HE_PLS_30'] / 2)\n",
            "<ipython-input-8-af51349857b2>:374: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected22.rename(columns={'HE_PLS_30': 'HE_PLS'}, inplace=True)\n",
            "<ipython-input-8-af51349857b2>:377: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected22['sm_present'] = ((data22['BS1_1'].isin([1, 2])) & (data22['BS3_1'].isin([1, 2]))).astype(int)\n",
            "<ipython-input-8-af51349857b2>:380: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data22['pa_hb30_1'] = np.where((data22['BE3_32'].isin([88,99]) | data22['BE3_33'].isin([88,99])), 0, data22['BE3_32'] * 60 + data22['BE3_33'])\n",
            "<ipython-input-8-af51349857b2>:381: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected22['pa_walk'] = (data22['BE3_31'].isin([4, 5, 6, 7, 8]) & (data22['pa_hb30_1'] >= 30)).astype(int)\n",
            "<ipython-input-8-af51349857b2>:384: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected22['total_sleep'] = np.where(data22['BP16_1'].isin([88, 99]), None, data22['BP16_1'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "Kqd9B2ML-P0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이상치 제거(1) -> 제곱값 취함 -> 이상치 제거(2) -> z-스코어 정규화"
      ],
      "metadata": {
        "id": "92VPa28T-RoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이상치 제거 (1)\n",
        "df = pd.concat([selected05, selected07, selected08, selected09, selected10, selected11, selected12, selected13, selected14,\n",
        "                          selected15, selected16, selected17, selected18, selected19, selected20, selected21, selected22], axis=0, ignore_index=True)\n",
        "idx = df[df['DI1_dg'] == 9].index\n",
        "df = df.drop(idx)\n",
        "df = df.sort_index(ascending=False)\n",
        "df['sex'] = df['sex'] - 1\n",
        "df['total_sleep'] = df['total_sleep'].astype('float')\n",
        "\n",
        "df0 = df[df['DI1_dg'] == 0]\n",
        "df1 = df[df['DI1_dg'] == 1]\n",
        "\n",
        "# age 이상치\n",
        "\n",
        "outlier = df0[df0['age'] > 73].index\n",
        "df0 = df0.drop(outlier)\n",
        "\n",
        "Q1 = df1['age'].quantile(q = 0.25)\n",
        "Q3 = df1['age'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Min = Q1 - 1.5 * IQR\n",
        "\n",
        "outlier = df1[df1['age'] < Min].index\n",
        "# df1.loc[outlier]\n",
        "df1 = df1.drop(outlier)\n",
        "\n",
        "\n",
        "# 수축기 혈압 이상치\n",
        "\n",
        "Q1 = df0['HE_sbp'].quantile(q = 0.25)\n",
        "Q3 = df0['HE_sbp'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Max = Q3 + 1.5 * IQR\n",
        "\n",
        "outlier = df0[df0['HE_sbp'] > Max].index\n",
        "df0 = df0.drop(outlier)\n",
        "\n",
        "\n",
        "Q1 = df1['HE_sbp'].quantile(q = 0.25)\n",
        "Q3 = df1['HE_sbp'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Min = Q1 - 1.5 * IQR\n",
        "\n",
        "outlier = df1[df1['HE_sbp'] < Min].index\n",
        "df1 = df1.drop(outlier)\n",
        "\n",
        "\n",
        "# 이완기 혈압 이상치\n",
        "\n",
        "Q1 = df0['HE_dbp'].quantile(q = 0.25)\n",
        "Q3 = df0['HE_dbp'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Max = Q3 + 1.5 * IQR\n",
        "\n",
        "outlier = df0[df0['HE_dbp'] > Max].index\n",
        "df0 = df0.drop(outlier)\n",
        "\n",
        "\n",
        "Q1 = df1['HE_dbp'].quantile(q = 0.25)\n",
        "Q3 = df1['HE_dbp'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Min = Q1 - 1.5 * IQR\n",
        "\n",
        "outlier = df1[df1['HE_dbp'] < Min].index\n",
        "df1 = df1.drop(outlier)\n",
        "\n",
        "\n",
        "# BMI 이상치\n",
        "\n",
        "Q1 = df0['HE_BMI'].quantile(q = 0.25)\n",
        "Q3 = df0['HE_BMI'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Max = Q3 + 1.5 * IQR\n",
        "\n",
        "outlier = df0[df0['HE_BMI'] > Max].index\n",
        "df0 = df0.drop(outlier)\n",
        "\n",
        "Q1 = df1['HE_BMI'].quantile(q = 0.25)\n",
        "Q3 = df1['HE_BMI'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Min = Q1 - 1.5 * IQR\n",
        "\n",
        "outlier = df1[df1['HE_BMI'] < Min].index\n",
        "df1 = df1.drop(outlier)\n",
        "\n",
        "\n",
        "# 수면시간 이상치\n",
        "\n",
        "Q1 = df0['total_sleep'].quantile(q = 0.25)\n",
        "Q3 = df0['total_sleep'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Min = Q1 - 1.5 * IQR\n",
        "\n",
        "outlier = df0[df0['total_sleep'] < Min].index\n",
        "df0 = df0.drop(outlier)\n",
        "# outlier = df0[df0['total_sleep'] > 15].index\n",
        "# df0 = df0.drop(outlier)\n",
        "\n",
        "Q1 = df1['total_sleep'].quantile(q = 0.25)\n",
        "Q3 = df1['total_sleep'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Max = Q3 + 1.5 * IQR\n",
        "\n",
        "outlier = df1[df1['total_sleep'] > Max].index\n",
        "df1 = df1.drop(outlier)\n",
        "outlier = df1[df1['total_sleep'] < 2].index\n",
        "df1 = df1.drop(outlier)\n",
        "\n",
        "\n",
        "# 의도에서 벗어나는 데이터(이상치)들도 제거해야 하지 않을까?\n",
        "\n",
        "outlier = df0.loc[(df0.loc[:,'HE_sbp'] > 140), 'HE_sbp'].index\n",
        "df0 = df0.drop(outlier)\n",
        "outlier = df0.loc[(df0.loc[:, 'HE_dbp'] > 90), 'HE_dbp'].index\n",
        "df0 = df0.drop(outlier)\n",
        "# 고혈압 기준 혈압을 갖고 있는 정상군\n",
        "\n",
        "outlier = df1.loc[(df1.loc[:,'HE_sbp'] < 100), 'HE_sbp'].index\n",
        "df1 = df1.drop(outlier)\n",
        "outlier = df1.loc[(df1.loc[:, 'HE_dbp'] < 60), 'HE_dbp'].index\n",
        "df1 = df1.drop(outlier)\n",
        "# 저혈압 기준 혈압을 갖고 있는 환자군\n",
        "\n",
        "\n",
        "outlier = df0.loc[(df0.loc[:,'HE_BMI'] > 30), 'HE_BMI'].index\n",
        "df0 = df0.drop(outlier)\n",
        "# 비만\n",
        "\n",
        "outlier = df1.loc[(df1.loc[:, 'HE_BMI'] < 18.5), 'HE_BMI'].index\n",
        "df1 = df1.drop(outlier)\n",
        "# 저체중\n",
        "\n",
        "\n",
        "outlier = df0.loc[(df0.loc[:,'total_sleep'] < 5), 'total_sleep'].index\n",
        "df0 = df0.drop(outlier)\n",
        "\n",
        "outlier = df1.loc[(df1.loc[:, 'total_sleep'] > 8), 'total_sleep'].index\n",
        "df1 = df1.drop(outlier)\n"
      ],
      "metadata": {
        "id": "vMIHmvHS-hga"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 제곱값 + 이상치 제거(2)\n",
        "\n",
        "def square(df_input):\n",
        "    return df_input.apply(lambda x: x * x, axis=0)\n",
        "\n",
        "df0 = square(df0)\n",
        "df1 = square(df1)\n",
        "\n",
        "\n",
        "# age 이상치\n",
        "\n",
        "Q1 = df1['age'].quantile(q = 0.25)\n",
        "Q3 = df1['age'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Min = Q1 - 1.5 * IQR\n",
        "\n",
        "outlier = df1[df1['age'] < Min].index\n",
        "# df1.loc[outlier]\n",
        "df1 = df1.drop(outlier)\n",
        "\n",
        "\n",
        "# 수축기 혈압 이상치\n",
        "\n",
        "Q1 = df0['HE_sbp'].quantile(q = 0.25)\n",
        "Q3 = df0['HE_sbp'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Max = Q3 + 1.5 * IQR\n",
        "\n",
        "outlier = df0[df0['HE_sbp'] > Max].index\n",
        "df0 = df0.drop(outlier)\n",
        "\n",
        "\n",
        "Q1 = df1['HE_sbp'].quantile(q = 0.25)\n",
        "Q3 = df1['HE_sbp'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Min = Q1 - 1.5 * IQR\n",
        "\n",
        "outlier = df1[df1['HE_sbp'] < Min].index\n",
        "df1 = df1.drop(outlier)\n",
        "\n",
        "\n",
        "# 이완기 혈압 이상치\n",
        "\n",
        "Q1 = df0['HE_dbp'].quantile(q = 0.25)\n",
        "Q3 = df0['HE_dbp'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Max = Q3 + 1.5 * IQR\n",
        "\n",
        "outlier = df0[df0['HE_dbp'] > Max].index\n",
        "df0 = df0.drop(outlier)\n",
        "\n",
        "\n",
        "Q1 = df1['HE_dbp'].quantile(q = 0.25)\n",
        "Q3 = df1['HE_dbp'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Min = Q1 - 1.5 * IQR\n",
        "\n",
        "outlier = df1[df1['HE_dbp'] < Min].index\n",
        "df1 = df1.drop(outlier)\n",
        "\n",
        "\n",
        "# BMI 이상치\n",
        "\n",
        "Q1 = df0['HE_BMI'].quantile(q = 0.25)\n",
        "Q3 = df0['HE_BMI'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Max = Q3 + 1.5 * IQR\n",
        "\n",
        "outlier = df0[df0['HE_BMI'] > Max].index\n",
        "df0 = df0.drop(outlier)\n",
        "\n",
        "Q1 = df1['HE_BMI'].quantile(q = 0.25)\n",
        "Q3 = df1['HE_BMI'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Min = Q1 - 1.5 * IQR\n",
        "\n",
        "outlier = df1[df1['HE_BMI'] < Min].index\n",
        "df1 = df1.drop(outlier)\n",
        "\n",
        "\n",
        "# 수면시간 이상치\n",
        "\n",
        "Q1 = df0['total_sleep'].quantile(q = 0.25)\n",
        "Q3 = df0['total_sleep'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Min = Q1 - 1.5 * IQR\n",
        "\n",
        "outlier = df0[df0['total_sleep'] < Min].index\n",
        "df0 = df0.drop(outlier)\n",
        "# outlier = df0[df0['total_sleep'] > 15].index\n",
        "# df0 = df0.drop(outlier)\n",
        "\n",
        "Q1 = df1['total_sleep'].quantile(q = 0.25)\n",
        "Q3 = df1['total_sleep'].quantile(q = 0.75)\n",
        "IQR = Q3 - Q1\n",
        "Max = Q3 + 1.5 * IQR\n",
        "\n",
        "outlier = df1[df1['total_sleep'] > Max].index\n",
        "df1 = df1.drop(outlier)"
      ],
      "metadata": {
        "id": "GPvZbwQ9Ba-4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df0, df1], axis=0, ignore_index=True)"
      ],
      "metadata": {
        "id": "xm66vqkZbCQ8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "r2oYR0Q6bDnm",
        "outputId": "9fe965b0-8031-4725-cf8b-6008b4d3ac09"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 46354 entries, 0 to 46353\n",
            "Data columns (total 10 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   DI1_dg       46354 non-null  float64\n",
            " 1   sex          46354 non-null  float64\n",
            " 2   age          46354 non-null  float64\n",
            " 3   HE_sbp       46354 non-null  float64\n",
            " 4   HE_dbp       46354 non-null  float64\n",
            " 5   HE_PLS       46354 non-null  float64\n",
            " 6   HE_BMI       46354 non-null  float64\n",
            " 7   sm_present   46354 non-null  int64  \n",
            " 8   pa_walk      46354 non-null  int64  \n",
            " 9   total_sleep  46354 non-null  float64\n",
            "dtypes: float64(8), int64(2)\n",
            "memory usage: 3.5 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             DI1_dg           sex           age       HE_sbp        HE_dbp  \\\n",
              "count  46354.000000  46354.000000  46354.000000  46354.00000  46354.000000   \n",
              "mean       0.347910      0.592009   2850.478988  14246.06733   5725.101507   \n",
              "std        0.476312      0.491467   1632.110824   4091.54374   1439.500727   \n",
              "min        0.000000      0.000000    361.000000   5112.25000   1444.000000   \n",
              "25%        0.000000      0.000000   1444.000000  11342.25000   4761.000000   \n",
              "50%        0.000000      1.000000   2704.000000  13456.00000   5625.000000   \n",
              "75%        1.000000      1.000000   4096.000000  16384.00000   6561.000000   \n",
              "max        1.000000      1.000000   7921.000000  51984.00000  21904.000000   \n",
              "\n",
              "             HE_PLS        HE_BMI    sm_present       pa_walk   total_sleep  \n",
              "count  46354.000000  46354.000000  46354.000000  46354.000000  46354.000000  \n",
              "mean     315.843875    575.804000      0.184623      0.559089     47.680787  \n",
              "std       82.486101    159.758407      0.387995      0.496502     17.105735  \n",
              "min       64.000000    130.951911      0.000000      0.000000      4.000000  \n",
              "25%      256.000000    461.285061      0.000000      0.000000     36.000000  \n",
              "50%      289.000000    557.790762      0.000000      1.000000     49.000000  \n",
              "75%      361.000000    668.756647      0.000000      1.000000     64.000000  \n",
              "max     2809.000000   2866.284614      1.000000      1.000000    441.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b568a103-11a2-4f64-a768-642c1cde79ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DI1_dg</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>HE_sbp</th>\n",
              "      <th>HE_dbp</th>\n",
              "      <th>HE_PLS</th>\n",
              "      <th>HE_BMI</th>\n",
              "      <th>sm_present</th>\n",
              "      <th>pa_walk</th>\n",
              "      <th>total_sleep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.00000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.347910</td>\n",
              "      <td>0.592009</td>\n",
              "      <td>2850.478988</td>\n",
              "      <td>14246.06733</td>\n",
              "      <td>5725.101507</td>\n",
              "      <td>315.843875</td>\n",
              "      <td>575.804000</td>\n",
              "      <td>0.184623</td>\n",
              "      <td>0.559089</td>\n",
              "      <td>47.680787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.476312</td>\n",
              "      <td>0.491467</td>\n",
              "      <td>1632.110824</td>\n",
              "      <td>4091.54374</td>\n",
              "      <td>1439.500727</td>\n",
              "      <td>82.486101</td>\n",
              "      <td>159.758407</td>\n",
              "      <td>0.387995</td>\n",
              "      <td>0.496502</td>\n",
              "      <td>17.105735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>361.000000</td>\n",
              "      <td>5112.25000</td>\n",
              "      <td>1444.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>130.951911</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1444.000000</td>\n",
              "      <td>11342.25000</td>\n",
              "      <td>4761.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>461.285061</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2704.000000</td>\n",
              "      <td>13456.00000</td>\n",
              "      <td>5625.000000</td>\n",
              "      <td>289.000000</td>\n",
              "      <td>557.790762</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>49.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4096.000000</td>\n",
              "      <td>16384.00000</td>\n",
              "      <td>6561.000000</td>\n",
              "      <td>361.000000</td>\n",
              "      <td>668.756647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>64.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7921.000000</td>\n",
              "      <td>51984.00000</td>\n",
              "      <td>21904.000000</td>\n",
              "      <td>2809.000000</td>\n",
              "      <td>2866.284614</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>441.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b568a103-11a2-4f64-a768-642c1cde79ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b568a103-11a2-4f64-a768-642c1cde79ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b568a103-11a2-4f64-a768-642c1cde79ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6d8299fa-9ab8-432e-a2cf-eb9936e683fa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d8299fa-9ab8-432e-a2cf-eb9936e683fa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6d8299fa-9ab8-432e-a2cf-eb9936e683fa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"DI1_dg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16388.47122808311,\n        \"min\": 0.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.34790956551753893,\n          1.0,\n          0.47631228632475187\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16388.407626150463,\n        \"min\": 0.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5920093195840704,\n          1.0,\n          0.49146667828866875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15497.990878705601,\n        \"min\": 361.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2850.478987789619,\n          2704.0,\n          46354.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HE_sbp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18342.35818269747,\n        \"min\": 4091.5437396481566,\n        \"max\": 51984.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          14246.067329680287,\n          13456.0,\n          46354.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HE_dbp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15411.698196493217,\n        \"min\": 1439.5007268281315,\n        \"max\": 46354.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5725.101506881822,\n          5625.0,\n          46354.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HE_PLS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16203.16070868869,\n        \"min\": 64.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          315.84387539370925,\n          289.0,\n          46354.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HE_BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16138.586049161373,\n        \"min\": 130.9519110385199,\n        \"max\": 46354.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          575.8039999629589,\n          557.7907624550442,\n          46354.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sm_present\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16388.53444197795,\n        \"min\": 0.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.18462268628381584,\n          1.0,\n          0.3879953577272705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pa_walk\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16388.40903458618,\n        \"min\": 0.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5590887517797817,\n          1.0,\n          0.49650159867170013\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_sleep\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16355.964006188513,\n        \"min\": 4.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          47.68078670545033,\n          49.0,\n          46354.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 분할 + 테스트"
      ],
      "metadata": {
        "id": "I8iJ09OAbkO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# StandardScaler - 성능이 좋았던 z-스코어 표준화 수행\n",
        "\n",
        "def standard_norm(df_input):\n",
        "    return df_input.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
        "\n",
        "df_temp = standard_norm(df)\n",
        "df['age'] = df_temp['age']\n",
        "df['HE_sbp'] = df_temp['HE_sbp']\n",
        "df['HE_dbp'] = df_temp['HE_dbp']\n",
        "df['HE_BMI'] = df_temp['HE_BMI']\n",
        "df['HE_PLS'] = df_temp['HE_PLS']\n",
        "df['total_sleep'] = df_temp['total_sleep']\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(df[['sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_BMI', 'HE_PLS', 'total_sleep', 'sm_present', 'pa_walk']],\n",
        "#                                                     df['DI1_dg'], test_size = 0.2, random_state = 42, stratify = df['DI1_dg'])\n",
        "x_train, x_test, y_train, y_test = train_test_split(df[['sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_BMI', 'total_sleep', 'sm_present', 'pa_walk']],\n",
        "                                                    df['DI1_dg'], test_size = 0.2, random_state = 72, stratify = df['DI1_dg'])\n",
        "\n",
        "x_train = x_train.astype('float')\n",
        "x_test = x_test.astype('float')\n",
        "y_train = y_train.astype('int')\n",
        "y_test = y_test.astype('int')"
      ],
      "metadata": {
        "id": "ifmz0TvGbmEU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "NGNaVQiaLZgg",
        "outputId": "b0351146-fae1-4820-989e-55fd087eabfe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                sex           age        HE_sbp        HE_dbp        HE_BMI  \\\n",
              "count  37083.000000  37083.000000  37083.000000  37083.000000  37083.000000   \n",
              "mean       0.592724     -0.000116     -0.000136     -0.001748     -0.000868   \n",
              "std        0.491334      1.001245      0.999768      1.003108      1.001064   \n",
              "min        0.000000     -1.525312     -2.232365     -2.974018     -2.784530   \n",
              "25%        0.000000     -0.861755     -0.709712     -0.669747     -0.716819   \n",
              "50%        1.000000     -0.089748     -0.193098     -0.121467     -0.113829   \n",
              "75%        1.000000      0.763135      0.522525      0.580686      0.583136   \n",
              "max        1.000000      2.998277      8.672260     11.239243     14.337152   \n",
              "\n",
              "        total_sleep    sm_present       pa_walk  \n",
              "count  37083.000000  37083.000000  37083.000000  \n",
              "mean      -0.001470      0.185611      0.560419  \n",
              "std        0.999072      0.388797      0.496343  \n",
              "min       -2.553576      0.000000      0.000000  \n",
              "25%       -0.682858      0.000000      0.000000  \n",
              "50%        0.077121      0.000000      1.000000  \n",
              "75%        0.954020      0.000000      1.000000  \n",
              "max       22.993413      1.000000      1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f188b172-14c4-4361-9bdc-dcb8c9be9ede\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>HE_sbp</th>\n",
              "      <th>HE_dbp</th>\n",
              "      <th>HE_BMI</th>\n",
              "      <th>total_sleep</th>\n",
              "      <th>sm_present</th>\n",
              "      <th>pa_walk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>37083.000000</td>\n",
              "      <td>37083.000000</td>\n",
              "      <td>37083.000000</td>\n",
              "      <td>37083.000000</td>\n",
              "      <td>37083.000000</td>\n",
              "      <td>37083.000000</td>\n",
              "      <td>37083.000000</td>\n",
              "      <td>37083.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.592724</td>\n",
              "      <td>-0.000116</td>\n",
              "      <td>-0.000136</td>\n",
              "      <td>-0.001748</td>\n",
              "      <td>-0.000868</td>\n",
              "      <td>-0.001470</td>\n",
              "      <td>0.185611</td>\n",
              "      <td>0.560419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.491334</td>\n",
              "      <td>1.001245</td>\n",
              "      <td>0.999768</td>\n",
              "      <td>1.003108</td>\n",
              "      <td>1.001064</td>\n",
              "      <td>0.999072</td>\n",
              "      <td>0.388797</td>\n",
              "      <td>0.496343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.525312</td>\n",
              "      <td>-2.232365</td>\n",
              "      <td>-2.974018</td>\n",
              "      <td>-2.784530</td>\n",
              "      <td>-2.553576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.861755</td>\n",
              "      <td>-0.709712</td>\n",
              "      <td>-0.669747</td>\n",
              "      <td>-0.716819</td>\n",
              "      <td>-0.682858</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.089748</td>\n",
              "      <td>-0.193098</td>\n",
              "      <td>-0.121467</td>\n",
              "      <td>-0.113829</td>\n",
              "      <td>0.077121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.763135</td>\n",
              "      <td>0.522525</td>\n",
              "      <td>0.580686</td>\n",
              "      <td>0.583136</td>\n",
              "      <td>0.954020</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.998277</td>\n",
              "      <td>8.672260</td>\n",
              "      <td>11.239243</td>\n",
              "      <td>14.337152</td>\n",
              "      <td>22.993413</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f188b172-14c4-4361-9bdc-dcb8c9be9ede')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f188b172-14c4-4361-9bdc-dcb8c9be9ede button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f188b172-14c4-4361-9bdc-dcb8c9be9ede');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33092eba-f815-49aa-b8d1-8c683f0ffd31\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33092eba-f815-49aa-b8d1-8c683f0ffd31')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33092eba-f815-49aa-b8d1-8c683f0ffd31 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"x_train\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13110.61411388264,\n        \"min\": 0.0,\n        \"max\": 37083.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5927244289836313,\n          1.0,\n          0.4913335834496157\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13110.705007078592,\n        \"min\": -1.5253124674187553,\n        \"max\": 37083.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.00011577811260339067,\n          -0.0897481872256184,\n          37083.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HE_sbp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13110.464245771538,\n        \"min\": -2.2323645818987945,\n        \"max\": 37083.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.0001360441787089029,\n          -0.19309761301689693,\n          37083.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HE_dbp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13110.363665803017,\n        \"min\": -2.974018301689237,\n        \"max\": 37083.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.0017476662139834858,\n          -0.12146677221004189,\n          37083.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HE_BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13110.199926045465,\n        \"min\": -2.7845300680086105,\n        \"max\": 37083.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.0008682252469105697,\n          -0.1138291981002227,\n          37083.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_sleep\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13109.722597946597,\n        \"min\": -2.5535756224146335,\n        \"max\": 37083.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.0014700659200838685,\n          0.07712111351023346,\n          37083.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sm_present\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13110.74086828529,\n        \"min\": 0.0,\n        \"max\": 37083.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.18561065717444653,\n          1.0,\n          0.38879739900266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pa_walk\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13110.615492567129,\n        \"min\": 0.0,\n        \"max\": 37083.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5604185206159157,\n          1.0,\n          0.4963428711493617\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "activation function(활성화함수) 비교"
      ],
      "metadata": {
        "id": "3EXQaJqHXvM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp17 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='sigmoid'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='sigmoid'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='sigmoid'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='sigmoid'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp17.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp17.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp17.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQC6iYJ00zP-",
        "outputId": "1ad21de7-b93e-44c6-8b34-9652e730e313"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 5s 8ms/step - loss: 0.6897 - accuracy: 0.6079 - val_loss: 0.6420 - val_accuracy: 0.6521\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.6581 - accuracy: 0.6320 - val_loss: 0.6295 - val_accuracy: 0.6521\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.6357 - accuracy: 0.6483 - val_loss: 0.5780 - val_accuracy: 0.6521\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.5913 - accuracy: 0.6749 - val_loss: 0.4819 - val_accuracy: 0.6521\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.5477 - accuracy: 0.7066 - val_loss: 0.4253 - val_accuracy: 0.8462\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.5262 - accuracy: 0.7243 - val_loss: 0.4056 - val_accuracy: 0.8422\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.5135 - accuracy: 0.7376 - val_loss: 0.3972 - val_accuracy: 0.8397\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.5046 - accuracy: 0.7405 - val_loss: 0.3932 - val_accuracy: 0.8398\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4967 - accuracy: 0.7455 - val_loss: 0.3904 - val_accuracy: 0.8379\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4903 - accuracy: 0.7645 - val_loss: 0.3889 - val_accuracy: 0.8392\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4929 - accuracy: 0.7641 - val_loss: 0.3892 - val_accuracy: 0.8360\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4875 - accuracy: 0.7726 - val_loss: 0.3879 - val_accuracy: 0.8371\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4832 - accuracy: 0.7788 - val_loss: 0.3863 - val_accuracy: 0.8376\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4839 - accuracy: 0.7803 - val_loss: 0.3853 - val_accuracy: 0.8376\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4814 - accuracy: 0.7804 - val_loss: 0.3840 - val_accuracy: 0.8373\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4814 - accuracy: 0.7795 - val_loss: 0.3836 - val_accuracy: 0.8370\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.4804 - accuracy: 0.7832 - val_loss: 0.3836 - val_accuracy: 0.8369\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.7883 - val_loss: 0.3820 - val_accuracy: 0.8383\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.4769 - accuracy: 0.7835 - val_loss: 0.3806 - val_accuracy: 0.8368\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4732 - accuracy: 0.7882 - val_loss: 0.3795 - val_accuracy: 0.8367\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4722 - accuracy: 0.7903 - val_loss: 0.3787 - val_accuracy: 0.8372\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4751 - accuracy: 0.7875 - val_loss: 0.3772 - val_accuracy: 0.8397\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4718 - accuracy: 0.7901 - val_loss: 0.3767 - val_accuracy: 0.8392\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4697 - accuracy: 0.7917 - val_loss: 0.3753 - val_accuracy: 0.8389\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4711 - accuracy: 0.7930 - val_loss: 0.3748 - val_accuracy: 0.8395\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4685 - accuracy: 0.7914 - val_loss: 0.3733 - val_accuracy: 0.8403\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4674 - accuracy: 0.7927 - val_loss: 0.3716 - val_accuracy: 0.8413\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4665 - accuracy: 0.7940 - val_loss: 0.3715 - val_accuracy: 0.8408\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4677 - accuracy: 0.7923 - val_loss: 0.3708 - val_accuracy: 0.8404\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.4653 - accuracy: 0.7967 - val_loss: 0.3690 - val_accuracy: 0.8405\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.4676 - accuracy: 0.7928 - val_loss: 0.3681 - val_accuracy: 0.8404\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.4636 - accuracy: 0.7948 - val_loss: 0.3666 - val_accuracy: 0.8409\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4637 - accuracy: 0.7951 - val_loss: 0.3658 - val_accuracy: 0.8407\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4667 - accuracy: 0.7916 - val_loss: 0.3654 - val_accuracy: 0.8412\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4653 - accuracy: 0.7952 - val_loss: 0.3649 - val_accuracy: 0.8419\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4641 - accuracy: 0.7961 - val_loss: 0.3626 - val_accuracy: 0.8424\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4632 - accuracy: 0.7966 - val_loss: 0.3622 - val_accuracy: 0.8420\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4604 - accuracy: 0.7988 - val_loss: 0.3598 - val_accuracy: 0.8421\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4579 - accuracy: 0.7983 - val_loss: 0.3585 - val_accuracy: 0.8430\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4557 - accuracy: 0.7998 - val_loss: 0.3573 - val_accuracy: 0.8426\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4593 - accuracy: 0.7978 - val_loss: 0.3559 - val_accuracy: 0.8428\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4552 - accuracy: 0.8007 - val_loss: 0.3551 - val_accuracy: 0.8439\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.4575 - accuracy: 0.7996 - val_loss: 0.3538 - val_accuracy: 0.8427\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.4527 - accuracy: 0.8020 - val_loss: 0.3530 - val_accuracy: 0.8439\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.4611 - accuracy: 0.7938 - val_loss: 0.3529 - val_accuracy: 0.8446\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.4525 - accuracy: 0.8031 - val_loss: 0.3512 - val_accuracy: 0.8444\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4564 - accuracy: 0.8013 - val_loss: 0.3508 - val_accuracy: 0.8441\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4528 - accuracy: 0.8000 - val_loss: 0.3503 - val_accuracy: 0.8453\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.8000 - val_loss: 0.3490 - val_accuracy: 0.8445\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4534 - accuracy: 0.8020 - val_loss: 0.3483 - val_accuracy: 0.8461\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3483 - accuracy: 0.8461\n",
            "정확률= 0.8460791707038879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp17 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='tanh'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='tanh'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='tanh'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='tanh'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp17.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp17.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp17.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nai09pTKoRB0",
        "outputId": "629d9aef-9149-4da6-e0a9-4fee355d9588"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 2s 4ms/step - loss: 0.6452 - accuracy: 0.6275 - val_loss: 0.3906 - val_accuracy: 0.8411\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.7805 - val_loss: 0.3633 - val_accuracy: 0.8493\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4493 - accuracy: 0.8123 - val_loss: 0.3641 - val_accuracy: 0.8494\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4305 - accuracy: 0.8221 - val_loss: 0.3637 - val_accuracy: 0.8509\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4218 - accuracy: 0.8280 - val_loss: 0.3596 - val_accuracy: 0.8497\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.4151 - accuracy: 0.8292 - val_loss: 0.3560 - val_accuracy: 0.8500\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8315 - val_loss: 0.3515 - val_accuracy: 0.8505\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4011 - accuracy: 0.8347 - val_loss: 0.3462 - val_accuracy: 0.8500\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3995 - accuracy: 0.8349 - val_loss: 0.3409 - val_accuracy: 0.8524\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3907 - accuracy: 0.8372 - val_loss: 0.3383 - val_accuracy: 0.8515\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3875 - accuracy: 0.8388 - val_loss: 0.3365 - val_accuracy: 0.8517\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3878 - accuracy: 0.8367 - val_loss: 0.3334 - val_accuracy: 0.8529\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3881 - accuracy: 0.8362 - val_loss: 0.3314 - val_accuracy: 0.8521\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3865 - accuracy: 0.8381 - val_loss: 0.3311 - val_accuracy: 0.8543\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3828 - accuracy: 0.8390 - val_loss: 0.3293 - val_accuracy: 0.8521\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3833 - accuracy: 0.8379 - val_loss: 0.3280 - val_accuracy: 0.8521\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3831 - accuracy: 0.8389 - val_loss: 0.3285 - val_accuracy: 0.8515\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3829 - accuracy: 0.8388 - val_loss: 0.3286 - val_accuracy: 0.8515\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3829 - accuracy: 0.8388 - val_loss: 0.3280 - val_accuracy: 0.8526\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3815 - accuracy: 0.8367 - val_loss: 0.3279 - val_accuracy: 0.8521\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3794 - accuracy: 0.8382 - val_loss: 0.3285 - val_accuracy: 0.8524\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3780 - accuracy: 0.8406 - val_loss: 0.3273 - val_accuracy: 0.8519\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3781 - accuracy: 0.8398 - val_loss: 0.3253 - val_accuracy: 0.8520\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3796 - accuracy: 0.8389 - val_loss: 0.3254 - val_accuracy: 0.8536\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3783 - accuracy: 0.8386 - val_loss: 0.3267 - val_accuracy: 0.8520\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8409 - val_loss: 0.3252 - val_accuracy: 0.8526\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8400 - val_loss: 0.3247 - val_accuracy: 0.8521\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3803 - accuracy: 0.8386 - val_loss: 0.3244 - val_accuracy: 0.8521\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3807 - accuracy: 0.8374 - val_loss: 0.3255 - val_accuracy: 0.8515\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3781 - accuracy: 0.8381 - val_loss: 0.3249 - val_accuracy: 0.8528\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3770 - accuracy: 0.8397 - val_loss: 0.3253 - val_accuracy: 0.8518\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3771 - accuracy: 0.8411 - val_loss: 0.3259 - val_accuracy: 0.8523\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3792 - accuracy: 0.8400 - val_loss: 0.3247 - val_accuracy: 0.8514\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3770 - accuracy: 0.8395 - val_loss: 0.3236 - val_accuracy: 0.8521\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3766 - accuracy: 0.8387 - val_loss: 0.3257 - val_accuracy: 0.8516\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3790 - accuracy: 0.8390 - val_loss: 0.3240 - val_accuracy: 0.8526\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3778 - accuracy: 0.8393 - val_loss: 0.3252 - val_accuracy: 0.8535\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3776 - accuracy: 0.8396 - val_loss: 0.3241 - val_accuracy: 0.8528\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3788 - accuracy: 0.8387 - val_loss: 0.3237 - val_accuracy: 0.8526\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3743 - accuracy: 0.8385 - val_loss: 0.3271 - val_accuracy: 0.8509\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3790 - accuracy: 0.8393 - val_loss: 0.3250 - val_accuracy: 0.8501\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3762 - accuracy: 0.8398 - val_loss: 0.3239 - val_accuracy: 0.8527\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3771 - accuracy: 0.8413 - val_loss: 0.3238 - val_accuracy: 0.8522\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3782 - accuracy: 0.8387 - val_loss: 0.3256 - val_accuracy: 0.8524\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3772 - accuracy: 0.8387 - val_loss: 0.3244 - val_accuracy: 0.8524\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3798 - accuracy: 0.8365 - val_loss: 0.3239 - val_accuracy: 0.8533\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3771 - accuracy: 0.8393 - val_loss: 0.3257 - val_accuracy: 0.8517\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3759 - accuracy: 0.8405 - val_loss: 0.3240 - val_accuracy: 0.8523\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3777 - accuracy: 0.8395 - val_loss: 0.3241 - val_accuracy: 0.8519\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3761 - accuracy: 0.8394 - val_loss: 0.3270 - val_accuracy: 0.8514\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8514\n",
            "정확률= 0.8513644933700562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp17 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp17.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp17.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp17.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH6byrIY1Qiw",
        "outputId": "00afaef9-13d3-4004-ed41-6f3738de29d3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 4s 6ms/step - loss: 0.6774 - accuracy: 0.6303 - val_loss: 0.6235 - val_accuracy: 0.6531\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.6071 - accuracy: 0.6784 - val_loss: 0.5056 - val_accuracy: 0.7413\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.5537 - accuracy: 0.7246 - val_loss: 0.4364 - val_accuracy: 0.8242\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.7541 - val_loss: 0.4050 - val_accuracy: 0.8395\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4950 - accuracy: 0.7713 - val_loss: 0.3790 - val_accuracy: 0.8469\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4827 - accuracy: 0.7807 - val_loss: 0.3664 - val_accuracy: 0.8446\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4698 - accuracy: 0.7834 - val_loss: 0.3596 - val_accuracy: 0.8459\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.3513 - val_accuracy: 0.8480\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4554 - accuracy: 0.7918 - val_loss: 0.3425 - val_accuracy: 0.8499\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4463 - accuracy: 0.7968 - val_loss: 0.3296 - val_accuracy: 0.8528\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.7973 - val_loss: 0.3277 - val_accuracy: 0.8515\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4415 - accuracy: 0.7966 - val_loss: 0.3252 - val_accuracy: 0.8529\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4428 - accuracy: 0.8029 - val_loss: 0.3262 - val_accuracy: 0.8516\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4389 - accuracy: 0.8028 - val_loss: 0.3200 - val_accuracy: 0.8541\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4370 - accuracy: 0.8057 - val_loss: 0.3222 - val_accuracy: 0.8528\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.4362 - accuracy: 0.8086 - val_loss: 0.3206 - val_accuracy: 0.8543\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4342 - accuracy: 0.8099 - val_loss: 0.3203 - val_accuracy: 0.8536\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4301 - accuracy: 0.8082 - val_loss: 0.3182 - val_accuracy: 0.8538\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4312 - accuracy: 0.8103 - val_loss: 0.3181 - val_accuracy: 0.8529\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4308 - accuracy: 0.8120 - val_loss: 0.3209 - val_accuracy: 0.8534\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4346 - accuracy: 0.8106 - val_loss: 0.3223 - val_accuracy: 0.8532\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4304 - accuracy: 0.8122 - val_loss: 0.3165 - val_accuracy: 0.8529\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4273 - accuracy: 0.8110 - val_loss: 0.3151 - val_accuracy: 0.8532\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.8124 - val_loss: 0.3193 - val_accuracy: 0.8515\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4322 - accuracy: 0.8093 - val_loss: 0.3196 - val_accuracy: 0.8519\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4308 - accuracy: 0.8101 - val_loss: 0.3190 - val_accuracy: 0.8531\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4295 - accuracy: 0.8098 - val_loss: 0.3168 - val_accuracy: 0.8520\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4271 - accuracy: 0.8137 - val_loss: 0.3177 - val_accuracy: 0.8521\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.4279 - accuracy: 0.8120 - val_loss: 0.3179 - val_accuracy: 0.8518\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4329 - accuracy: 0.8114 - val_loss: 0.3182 - val_accuracy: 0.8524\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.4266 - accuracy: 0.8121 - val_loss: 0.3213 - val_accuracy: 0.8534\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4293 - accuracy: 0.8130 - val_loss: 0.3174 - val_accuracy: 0.8519\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4273 - accuracy: 0.8138 - val_loss: 0.3204 - val_accuracy: 0.8528\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4318 - accuracy: 0.8108 - val_loss: 0.3163 - val_accuracy: 0.8521\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4298 - accuracy: 0.8142 - val_loss: 0.3176 - val_accuracy: 0.8528\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4289 - accuracy: 0.8126 - val_loss: 0.3172 - val_accuracy: 0.8528\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4280 - accuracy: 0.8143 - val_loss: 0.3201 - val_accuracy: 0.8534\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4275 - accuracy: 0.8129 - val_loss: 0.3184 - val_accuracy: 0.8522\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4276 - accuracy: 0.8118 - val_loss: 0.3186 - val_accuracy: 0.8523\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4275 - accuracy: 0.8118 - val_loss: 0.3209 - val_accuracy: 0.8527\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4268 - accuracy: 0.8110 - val_loss: 0.3175 - val_accuracy: 0.8531\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4264 - accuracy: 0.8123 - val_loss: 0.3166 - val_accuracy: 0.8531\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4260 - accuracy: 0.8135 - val_loss: 0.3188 - val_accuracy: 0.8521\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.4252 - accuracy: 0.8139 - val_loss: 0.3185 - val_accuracy: 0.8526\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4291 - accuracy: 0.8121 - val_loss: 0.3192 - val_accuracy: 0.8544\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.4256 - accuracy: 0.8129 - val_loss: 0.3169 - val_accuracy: 0.8534\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4290 - accuracy: 0.8134 - val_loss: 0.3159 - val_accuracy: 0.8529\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4272 - accuracy: 0.8134 - val_loss: 0.3186 - val_accuracy: 0.8519\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4281 - accuracy: 0.8114 - val_loss: 0.3170 - val_accuracy: 0.8518\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4289 - accuracy: 0.8107 - val_loss: 0.3149 - val_accuracy: 0.8515\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8515\n",
            "정확률= 0.8514723181724548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp17 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp17.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp17.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp17.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlVa2hgO1Vqm",
        "outputId": "267039a0-6d96-4a72-addd-86eb4b593f2e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 4s 7ms/step - loss: 0.6012 - accuracy: 0.7169 - val_loss: 0.3772 - val_accuracy: 0.8436\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4616 - accuracy: 0.7923 - val_loss: 0.3270 - val_accuracy: 0.8496\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4259 - accuracy: 0.8113 - val_loss: 0.3211 - val_accuracy: 0.8486\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4103 - accuracy: 0.8165 - val_loss: 0.3167 - val_accuracy: 0.8532\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4021 - accuracy: 0.8224 - val_loss: 0.3171 - val_accuracy: 0.8505\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3945 - accuracy: 0.8263 - val_loss: 0.3145 - val_accuracy: 0.8530\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3920 - accuracy: 0.8255 - val_loss: 0.3139 - val_accuracy: 0.8538\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3903 - accuracy: 0.8263 - val_loss: 0.3152 - val_accuracy: 0.8534\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3851 - accuracy: 0.8295 - val_loss: 0.3134 - val_accuracy: 0.8546\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3834 - accuracy: 0.8294 - val_loss: 0.3131 - val_accuracy: 0.8538\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3847 - accuracy: 0.8292 - val_loss: 0.3136 - val_accuracy: 0.8535\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3838 - accuracy: 0.8318 - val_loss: 0.3129 - val_accuracy: 0.8526\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3799 - accuracy: 0.8337 - val_loss: 0.3130 - val_accuracy: 0.8526\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3798 - accuracy: 0.8333 - val_loss: 0.3131 - val_accuracy: 0.8517\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3814 - accuracy: 0.8304 - val_loss: 0.3124 - val_accuracy: 0.8545\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3824 - accuracy: 0.8314 - val_loss: 0.3126 - val_accuracy: 0.8523\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3807 - accuracy: 0.8305 - val_loss: 0.3129 - val_accuracy: 0.8519\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3755 - accuracy: 0.8327 - val_loss: 0.3122 - val_accuracy: 0.8528\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3780 - accuracy: 0.8329 - val_loss: 0.3120 - val_accuracy: 0.8535\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3773 - accuracy: 0.8335 - val_loss: 0.3113 - val_accuracy: 0.8537\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3774 - accuracy: 0.8338 - val_loss: 0.3118 - val_accuracy: 0.8522\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3766 - accuracy: 0.8329 - val_loss: 0.3114 - val_accuracy: 0.8530\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3777 - accuracy: 0.8320 - val_loss: 0.3115 - val_accuracy: 0.8519\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3793 - accuracy: 0.8314 - val_loss: 0.3113 - val_accuracy: 0.8530\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3763 - accuracy: 0.8323 - val_loss: 0.3109 - val_accuracy: 0.8534\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3761 - accuracy: 0.8340 - val_loss: 0.3109 - val_accuracy: 0.8537\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8353 - val_loss: 0.3111 - val_accuracy: 0.8526\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3776 - accuracy: 0.8350 - val_loss: 0.3113 - val_accuracy: 0.8523\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3724 - accuracy: 0.8337 - val_loss: 0.3111 - val_accuracy: 0.8536\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3766 - accuracy: 0.8316 - val_loss: 0.3113 - val_accuracy: 0.8528\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3738 - accuracy: 0.8362 - val_loss: 0.3120 - val_accuracy: 0.8521\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3731 - accuracy: 0.8344 - val_loss: 0.3104 - val_accuracy: 0.8540\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3761 - accuracy: 0.8329 - val_loss: 0.3103 - val_accuracy: 0.8536\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3796 - accuracy: 0.8315 - val_loss: 0.3108 - val_accuracy: 0.8527\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3777 - accuracy: 0.8315 - val_loss: 0.3108 - val_accuracy: 0.8526\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8326 - val_loss: 0.3102 - val_accuracy: 0.8529\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3740 - accuracy: 0.8344 - val_loss: 0.3106 - val_accuracy: 0.8516\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3780 - accuracy: 0.8326 - val_loss: 0.3103 - val_accuracy: 0.8530\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3735 - accuracy: 0.8352 - val_loss: 0.3103 - val_accuracy: 0.8524\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3717 - accuracy: 0.8349 - val_loss: 0.3102 - val_accuracy: 0.8528\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8327 - val_loss: 0.3104 - val_accuracy: 0.8522\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3781 - accuracy: 0.8326 - val_loss: 0.3112 - val_accuracy: 0.8529\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8315 - val_loss: 0.3103 - val_accuracy: 0.8529\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3757 - accuracy: 0.8321 - val_loss: 0.3099 - val_accuracy: 0.8533\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3764 - accuracy: 0.8323 - val_loss: 0.3107 - val_accuracy: 0.8528\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3741 - accuracy: 0.8348 - val_loss: 0.3101 - val_accuracy: 0.8529\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3765 - accuracy: 0.8335 - val_loss: 0.3100 - val_accuracy: 0.8526\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3716 - accuracy: 0.8336 - val_loss: 0.3099 - val_accuracy: 0.8522\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3732 - accuracy: 0.8337 - val_loss: 0.3096 - val_accuracy: 0.8530\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3743 - accuracy: 0.8335 - val_loss: 0.3098 - val_accuracy: 0.8522\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8522\n",
            "정확률= 0.8522273898124695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp17 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='elu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='elu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='elu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='elu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp17.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp17.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp17.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3h7cdO61c9V",
        "outputId": "9c19d460-dd91-48b1-f4df-e09dda6713e4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 5ms/step - loss: 0.7227 - accuracy: 0.6078 - val_loss: 0.4534 - val_accuracy: 0.8056\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.7397 - val_loss: 0.3473 - val_accuracy: 0.8463\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.3327 - val_accuracy: 0.8502\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.4325 - accuracy: 0.8097 - val_loss: 0.3306 - val_accuracy: 0.8500\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4176 - accuracy: 0.8191 - val_loss: 0.3305 - val_accuracy: 0.8493\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4066 - accuracy: 0.8238 - val_loss: 0.3296 - val_accuracy: 0.8502\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4015 - accuracy: 0.8276 - val_loss: 0.3291 - val_accuracy: 0.8497\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3992 - accuracy: 0.8294 - val_loss: 0.3291 - val_accuracy: 0.8503\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3947 - accuracy: 0.8313 - val_loss: 0.3285 - val_accuracy: 0.8502\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3929 - accuracy: 0.8307 - val_loss: 0.3281 - val_accuracy: 0.8509\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3892 - accuracy: 0.8326 - val_loss: 0.3278 - val_accuracy: 0.8499\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3927 - accuracy: 0.8330 - val_loss: 0.3286 - val_accuracy: 0.8513\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3869 - accuracy: 0.8333 - val_loss: 0.3266 - val_accuracy: 0.8504\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3855 - accuracy: 0.8355 - val_loss: 0.3265 - val_accuracy: 0.8515\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3884 - accuracy: 0.8340 - val_loss: 0.3261 - val_accuracy: 0.8510\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3868 - accuracy: 0.8358 - val_loss: 0.3255 - val_accuracy: 0.8515\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3850 - accuracy: 0.8352 - val_loss: 0.3252 - val_accuracy: 0.8510\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3850 - accuracy: 0.8357 - val_loss: 0.3259 - val_accuracy: 0.8515\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3821 - accuracy: 0.8373 - val_loss: 0.3255 - val_accuracy: 0.8517\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3831 - accuracy: 0.8379 - val_loss: 0.3248 - val_accuracy: 0.8519\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3807 - accuracy: 0.8381 - val_loss: 0.3244 - val_accuracy: 0.8515\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3848 - accuracy: 0.8365 - val_loss: 0.3245 - val_accuracy: 0.8515\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3795 - accuracy: 0.8399 - val_loss: 0.3253 - val_accuracy: 0.8524\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3822 - accuracy: 0.8379 - val_loss: 0.3241 - val_accuracy: 0.8522\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3831 - accuracy: 0.8378 - val_loss: 0.3241 - val_accuracy: 0.8515\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3833 - accuracy: 0.8374 - val_loss: 0.3245 - val_accuracy: 0.8520\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3812 - accuracy: 0.8378 - val_loss: 0.3234 - val_accuracy: 0.8513\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3827 - accuracy: 0.8372 - val_loss: 0.3230 - val_accuracy: 0.8511\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3790 - accuracy: 0.8402 - val_loss: 0.3236 - val_accuracy: 0.8529\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3792 - accuracy: 0.8387 - val_loss: 0.3234 - val_accuracy: 0.8507\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3788 - accuracy: 0.8402 - val_loss: 0.3232 - val_accuracy: 0.8511\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3806 - accuracy: 0.8395 - val_loss: 0.3228 - val_accuracy: 0.8506\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3830 - accuracy: 0.8377 - val_loss: 0.3231 - val_accuracy: 0.8520\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3833 - accuracy: 0.8385 - val_loss: 0.3232 - val_accuracy: 0.8519\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3816 - accuracy: 0.8371 - val_loss: 0.3233 - val_accuracy: 0.8529\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3789 - accuracy: 0.8376 - val_loss: 0.3227 - val_accuracy: 0.8511\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3815 - accuracy: 0.8389 - val_loss: 0.3224 - val_accuracy: 0.8517\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3815 - accuracy: 0.8377 - val_loss: 0.3223 - val_accuracy: 0.8516\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3783 - accuracy: 0.8383 - val_loss: 0.3223 - val_accuracy: 0.8510\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3795 - accuracy: 0.8377 - val_loss: 0.3228 - val_accuracy: 0.8527\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3796 - accuracy: 0.8402 - val_loss: 0.3224 - val_accuracy: 0.8524\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3804 - accuracy: 0.8380 - val_loss: 0.3218 - val_accuracy: 0.8533\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3789 - accuracy: 0.8390 - val_loss: 0.3225 - val_accuracy: 0.8541\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3791 - accuracy: 0.8393 - val_loss: 0.3220 - val_accuracy: 0.8518\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3807 - accuracy: 0.8366 - val_loss: 0.3217 - val_accuracy: 0.8513\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3825 - accuracy: 0.8361 - val_loss: 0.3219 - val_accuracy: 0.8515\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3796 - accuracy: 0.8401 - val_loss: 0.3227 - val_accuracy: 0.8529\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3761 - accuracy: 0.8398 - val_loss: 0.3215 - val_accuracy: 0.8520\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3794 - accuracy: 0.8384 - val_loss: 0.3221 - val_accuracy: 0.8515\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3814 - accuracy: 0.8386 - val_loss: 0.3221 - val_accuracy: 0.8517\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8517\n",
            "정확률= 0.8516880869865417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-"
      ],
      "metadata": {
        "id": "PGTxF0eA4b_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['test'] = df['sm_present'] - df['pa_walk']\n",
        "# 둘을 혼합해서 사용해보려 했으나, 썩 유의미하진 않았습니다."
      ],
      "metadata": {
        "id": "5m2AnmszYVuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "ZAYXAtzEay4Q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df.corr(), annot = True, cmap = 'viridis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "GBcaUTugn65l",
        "outputId": "5066747d-0d69-4371-8c55-b99d2074665d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency"
      ],
      "metadata": {
        "id": "yKbw3o99S8Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df['DI1_dg'], df['sex'], margins=True)"
      ],
      "metadata": {
        "id": "86wa3GjuTbNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df['DI1_dg'], df['sm_present'], margins=True)"
      ],
      "metadata": {
        "id": "OcuWvvC2S9ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df['DI1_dg'], df['pa_walk'], margins=True)"
      ],
      "metadata": {
        "id": "giaRIpWNTUCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 분산 동질성 분석 / 통계적 유의성 측정"
      ],
      "metadata": {
        "id": "9q8A5rRBkMoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "box-cox 변환을 수행한 후에 분산 동질성 분석과 통계적 유의성을 측정해보기로 했습니다."
      ],
      "metadata": {
        "id": "DkUPAtobqo2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import power_transform\n",
        "\n",
        "df[['age']] = power_transform(df[['age']],method = 'box-cox', standardize = False)\n",
        "df[['HE_sbp']] = power_transform(df[['HE_sbp']],method = 'box-cox', standardize = False)\n",
        "df[['HE_dbp']] = power_transform(df[['HE_dbp']],method = 'box-cox', standardize = False)\n",
        "df[['HE_BMI']] = power_transform(df[['HE_BMI']],method = 'box-cox', standardize = False)\n",
        "df[['total_sleep']] = power_transform(df[['total_sleep']],method = 'box-cox', standardize = False)"
      ],
      "metadata": {
        "id": "9lUx6qkGY6E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "from scipy.stats import levene\n",
        "from scipy.stats import jarque_bera\n",
        "from scipy.stats import ttest_ind"
      ],
      "metadata": {
        "id": "3zPrGKmTq2HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = df[df['DI1_dg'] == 0]\n",
        "df1 = df[df['DI1_dg'] == 1]"
      ],
      "metadata": {
        "id": "X0qIy0iettBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stat_sbp, p_sbp = levene(df0['HE_sbp'], df1['HE_sbp'])\n",
        "print('HE_sbp 분산 동질성 분석')\n",
        "if p_sbp > 0.05:\n",
        "    print(\"결과: 두집단의 분산의 동질성 검정결과는 유의하다. 집단의 분산은 동질하다.\\n\")\n",
        "else:\n",
        "    print(\"결과: 집단의 분산의 동질성검정결과는 유의하지 않다.\\n\")\n",
        "\n",
        "stat_dbp, p_dbp = levene(df0['HE_dbp'], df1['HE_dbp'])\n",
        "print('HE_dbp 분산 동질성 분석')\n",
        "if p_dbp > 0.05:\n",
        "    print(\"결과: 두집단의 분산의 동질성 검정결과는 유의하다. 집단의 분산은 동질하다.\\n\")\n",
        "else:\n",
        "    print(\"결과: 집단의 분산의 동질성검정결과는 유의하지 않다.\\n\")\n",
        "\n",
        "stat_BMI, p_BMI = levene(df0['HE_BMI'], df1['HE_BMI'])\n",
        "print('HE_BMI 분산 동질성 분석')\n",
        "if p_BMI > 0.05:\n",
        "    print(\"결과: 두집단의 분산의 동질성 검정결과는 유의하다. 집단의 분산은 동질하다.\\n\")\n",
        "else:\n",
        "    print(\"결과: 집단의 분산의 동질성검정결과는 유의하지 않다.\\n\")\n",
        "\n",
        "stat_sleep, p_sleep = levene(df0['total_sleep'], df1['total_sleep'])\n",
        "print('total_sleep 분산 동질성 분석')\n",
        "if p_sleep > 0.05:\n",
        "    print(\"결과: 두집단의 분산의 동질성 검정결과는 유의하다. 집단의 분산은 동질하다.\\n\")\n",
        "else:\n",
        "    print(\"결과: 집단의 분산의 동질성검정결과는 유의하지 않다.\\n\")\n",
        "\n",
        "stat_age, p_age = levene(df0['age'], df1['age'])\n",
        "print('age 분산 동질성 분석')\n",
        "if p_age > 0.05:\n",
        "    print(\"결과: 두집단의 분산의 동질성 검정결과는 유의하다. 집단의 분산은 동질하다.\\n\")\n",
        "else:\n",
        "    print(\"결과: 집단의 분산의 동질성검정결과는 유의하지 않다.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW0hKsRutxF_",
        "outputId": "5cf8b381-93d4-4ed5-ceea-bc576e48fe78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HE_sbp 분산 동질성 분석\n",
            "결과: 집단의 분산의 동질성검정결과는 유의하지 않다.\n",
            "\n",
            "HE_dbp 분산 동질성 분석\n",
            "결과: 집단의 분산의 동질성검정결과는 유의하지 않다.\n",
            "\n",
            "HE_BMI 분산 동질성 분석\n",
            "결과: 집단의 분산의 동질성검정결과는 유의하지 않다.\n",
            "\n",
            "total_sleep 분산 동질성 분석\n",
            "결과: 집단의 분산의 동질성검정결과는 유의하지 않다.\n",
            "\n",
            "age 분산 동질성 분석\n",
            "결과: 집단의 분산의 동질성검정결과는 유의하지 않다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "분산의 동질성이 없으므로,  Welch’s t-검정 방법을 사용해 수행합니다."
      ],
      "metadata": {
        "id": "wnpH_gmE6czR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "st_sbp, pp_sbp = ttest_ind(df0['HE_sbp'], df1['HE_sbp'], equal_var = False)\n",
        "print('HE_sbp 통계적 유의성 분석')\n",
        "if pp_sbp > 0.05:\n",
        "    print(\"통계적으로 유의하지 않았다.\\n\")\n",
        "else:\n",
        "    print(\"통계적으로 유의한 차이가 발생했다.\\n\")\n",
        "\n",
        "st_dbp, pp_dbp = ttest_ind(df0['HE_dbp'], df1['HE_dbp'], equal_var = False)\n",
        "print('HE_dbp 통계적 유의성 분석')\n",
        "if pp_dbp > 0.05:\n",
        "    print(\"통계적으로 유의하지 않았다.\\n\")\n",
        "else:\n",
        "    print(\"통계적으로 유의한 차이가 발생했다.\\n\")\n",
        "\n",
        "st_BMI, pp_BMI = ttest_ind(df0['HE_BMI'], df1['HE_BMI'], equal_var = False)\n",
        "print('HE_BMI 통계적 유의성 분석')\n",
        "if pp_BMI > 0.05:\n",
        "    print(\"통계적으로 유의하지 않았다.\\n\")\n",
        "else:\n",
        "    print(\"통계적으로 유의한 차이가 발생했다.\\n\")\n",
        "\n",
        "st_sleep, pp_sleep = ttest_ind(df0['total_sleep'], df1['total_sleep'], equal_var = False)\n",
        "print('total_sleep 통계적 유의성 분석')\n",
        "if pp_sleep > 0.05:\n",
        "    print(\"통계적으로 유의하지 않았다.\\n\")\n",
        "else:\n",
        "    print(\"통계적으로 유의한 차이가 발생했다.\\n\")\n",
        "\n",
        "st_age, pp_age = ttest_ind(df0['age'], df1['age'], equal_var = False)\n",
        "print('age 통계적 유의성 분석')\n",
        "if pp_age > 0.05:\n",
        "    print(\"통계적으로 유의하지 않았다.\\n\")\n",
        "else:\n",
        "    print(\"통계적으로 유의한 차이가 발생했다.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kyjju0PuqA-",
        "outputId": "61d8112b-3b9e-4951-91e5-ed5a06db2893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HE_sbp 통계적 유의성 분석\n",
            "통계적으로 유의한 차이가 발생했다.\n",
            "\n",
            "HE_dbp 통계적 유의성 분석\n",
            "통계적으로 유의한 차이가 발생했다.\n",
            "\n",
            "HE_BMI 통계적 유의성 분석\n",
            "통계적으로 유의한 차이가 발생했다.\n",
            "\n",
            "total_sleep 통계적 유의성 분석\n",
            "통계적으로 유의한 차이가 발생했다.\n",
            "\n",
            "age 통계적 유의성 분석\n",
            "통계적으로 유의한 차이가 발생했다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 수정사항 + DNN 모델"
      ],
      "metadata": {
        "id": "Sera77zFc6sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'sex', 'age', 'HE_sbp', 'HE_dbp', 'HE_BMI', 'total_sleep', 'sm_present', 'pa_walk'\n",
        "\n",
        "\n",
        "▲ 변수 개수를 조정해가며 학습시켜본 결과, 위의 8개 변수들을 선정했을 때, 모델 성능이 가장 좋았습니다.\n",
        "15초 맥박수(HE_PLS)는 고혈압 환자군이 정상군보다 맥박수가 높다는 가정에 위배되어 제외하였습니다."
      ],
      "metadata": {
        "id": "sVTYN-Z6mwrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sigmoid, tanh, relu, leaky_relu, elu의 활성화함수를 사용했고, leaky_relu가 가장 좋은 성능을 보여 leaky_relu를 사용하기로 결정하였습니다."
      ],
      "metadata": {
        "id": "SWlCZgAlwEAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. DNN - 1 / 8 / X / leaky_relu"
      ],
      "metadata": {
        "id": "UkBUqgYq6gCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp1 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp1.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp1.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp1.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8622"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5CR21Tdc93g",
        "outputId": "f0258a46-4d2e-4dfd-d432-135a18f8e5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 5ms/step - loss: 0.5705 - accuracy: 0.6753 - val_loss: 0.3783 - val_accuracy: 0.8306\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3470 - accuracy: 0.8412 - val_loss: 0.3236 - val_accuracy: 0.8511\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3221 - accuracy: 0.8510 - val_loss: 0.3136 - val_accuracy: 0.8537\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3159 - accuracy: 0.8530 - val_loss: 0.3096 - val_accuracy: 0.8559\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3127 - accuracy: 0.8539 - val_loss: 0.3070 - val_accuracy: 0.8569\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3107 - accuracy: 0.8545 - val_loss: 0.3053 - val_accuracy: 0.8578\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3093 - accuracy: 0.8555 - val_loss: 0.3043 - val_accuracy: 0.8580\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3083 - accuracy: 0.8557 - val_loss: 0.3034 - val_accuracy: 0.8583\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3075 - accuracy: 0.8556 - val_loss: 0.3028 - val_accuracy: 0.8592\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3068 - accuracy: 0.8559 - val_loss: 0.3022 - val_accuracy: 0.8593\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3061 - accuracy: 0.8560 - val_loss: 0.3017 - val_accuracy: 0.8596\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3056 - accuracy: 0.8557 - val_loss: 0.3008 - val_accuracy: 0.8604\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3051 - accuracy: 0.8556 - val_loss: 0.3006 - val_accuracy: 0.8598\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3046 - accuracy: 0.8560 - val_loss: 0.2999 - val_accuracy: 0.8609\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3041 - accuracy: 0.8568 - val_loss: 0.3007 - val_accuracy: 0.8599\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3038 - accuracy: 0.8563 - val_loss: 0.2992 - val_accuracy: 0.8595\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3034 - accuracy: 0.8557 - val_loss: 0.2989 - val_accuracy: 0.8604\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3029 - accuracy: 0.8569 - val_loss: 0.2982 - val_accuracy: 0.8619\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3025 - accuracy: 0.8559 - val_loss: 0.2979 - val_accuracy: 0.8617\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3021 - accuracy: 0.8565 - val_loss: 0.2972 - val_accuracy: 0.8611\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3018 - accuracy: 0.8567 - val_loss: 0.2974 - val_accuracy: 0.8614\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3013 - accuracy: 0.8568 - val_loss: 0.2968 - val_accuracy: 0.8609\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3007 - accuracy: 0.8572 - val_loss: 0.2968 - val_accuracy: 0.8593\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3005 - accuracy: 0.8571 - val_loss: 0.2959 - val_accuracy: 0.8611\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3001 - accuracy: 0.8572 - val_loss: 0.2963 - val_accuracy: 0.8609\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2998 - accuracy: 0.8576 - val_loss: 0.2953 - val_accuracy: 0.8612\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2994 - accuracy: 0.8576 - val_loss: 0.2951 - val_accuracy: 0.8615\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2990 - accuracy: 0.8575 - val_loss: 0.2947 - val_accuracy: 0.8614\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2988 - accuracy: 0.8583 - val_loss: 0.2951 - val_accuracy: 0.8620\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2982 - accuracy: 0.8571 - val_loss: 0.2941 - val_accuracy: 0.8622\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2981 - accuracy: 0.8580 - val_loss: 0.2940 - val_accuracy: 0.8606\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2976 - accuracy: 0.8582 - val_loss: 0.2939 - val_accuracy: 0.8608\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2975 - accuracy: 0.8582 - val_loss: 0.2939 - val_accuracy: 0.8610\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2971 - accuracy: 0.8584 - val_loss: 0.2936 - val_accuracy: 0.8622\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2969 - accuracy: 0.8580 - val_loss: 0.2934 - val_accuracy: 0.8620\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2967 - accuracy: 0.8586 - val_loss: 0.2929 - val_accuracy: 0.8608\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2964 - accuracy: 0.8592 - val_loss: 0.2926 - val_accuracy: 0.8618\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2961 - accuracy: 0.8585 - val_loss: 0.2924 - val_accuracy: 0.8618\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2960 - accuracy: 0.8585 - val_loss: 0.2924 - val_accuracy: 0.8611\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2956 - accuracy: 0.8586 - val_loss: 0.2926 - val_accuracy: 0.8626\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2955 - accuracy: 0.8590 - val_loss: 0.2920 - val_accuracy: 0.8604\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2952 - accuracy: 0.8588 - val_loss: 0.2915 - val_accuracy: 0.8607\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2949 - accuracy: 0.8593 - val_loss: 0.2921 - val_accuracy: 0.8599\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2948 - accuracy: 0.8589 - val_loss: 0.2915 - val_accuracy: 0.8612\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2944 - accuracy: 0.8596 - val_loss: 0.2913 - val_accuracy: 0.8617\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2942 - accuracy: 0.8595 - val_loss: 0.2913 - val_accuracy: 0.8617\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2940 - accuracy: 0.8593 - val_loss: 0.2914 - val_accuracy: 0.8619\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2938 - accuracy: 0.8591 - val_loss: 0.2906 - val_accuracy: 0.8614\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2936 - accuracy: 0.8591 - val_loss: 0.2902 - val_accuracy: 0.8620\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2933 - accuracy: 0.8597 - val_loss: 0.2899 - val_accuracy: 0.8622\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2899 - accuracy: 0.8622\n",
            "정확률= 0.8621953725814819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. DNN - 1 / 16 / X / leaky_relu"
      ],
      "metadata": {
        "id": "vusnxl_p6qNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp2 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp2.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp2.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp2.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8669"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7mWl0La6xUJ",
        "outputId": "555fa371-7676-413a-91a4-68a539e0466f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 8ms/step - loss: 0.4911 - accuracy: 0.7574 - val_loss: 0.3429 - val_accuracy: 0.8513\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3264 - accuracy: 0.8493 - val_loss: 0.3133 - val_accuracy: 0.8560\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3154 - accuracy: 0.8524 - val_loss: 0.3097 - val_accuracy: 0.8558\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3127 - accuracy: 0.8534 - val_loss: 0.3079 - val_accuracy: 0.8578\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3109 - accuracy: 0.8540 - val_loss: 0.3061 - val_accuracy: 0.8581\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3094 - accuracy: 0.8548 - val_loss: 0.3048 - val_accuracy: 0.8579\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3081 - accuracy: 0.8558 - val_loss: 0.3037 - val_accuracy: 0.8592\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3070 - accuracy: 0.8556 - val_loss: 0.3032 - val_accuracy: 0.8591\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3060 - accuracy: 0.8562 - val_loss: 0.3018 - val_accuracy: 0.8604\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3051 - accuracy: 0.8569 - val_loss: 0.3006 - val_accuracy: 0.8613\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3043 - accuracy: 0.8567 - val_loss: 0.2997 - val_accuracy: 0.8614\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3037 - accuracy: 0.8571 - val_loss: 0.2990 - val_accuracy: 0.8621\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3028 - accuracy: 0.8574 - val_loss: 0.2983 - val_accuracy: 0.8619\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3022 - accuracy: 0.8571 - val_loss: 0.2974 - val_accuracy: 0.8617\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3015 - accuracy: 0.8575 - val_loss: 0.2969 - val_accuracy: 0.8631\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3007 - accuracy: 0.8580 - val_loss: 0.2961 - val_accuracy: 0.8630\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3001 - accuracy: 0.8582 - val_loss: 0.2951 - val_accuracy: 0.8653\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2994 - accuracy: 0.8582 - val_loss: 0.2963 - val_accuracy: 0.8624\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 3s 11ms/step - loss: 0.2988 - accuracy: 0.8589 - val_loss: 0.2945 - val_accuracy: 0.8634\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2981 - accuracy: 0.8586 - val_loss: 0.2936 - val_accuracy: 0.8632\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2974 - accuracy: 0.8592 - val_loss: 0.2932 - val_accuracy: 0.8635\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.2966 - accuracy: 0.8591 - val_loss: 0.2927 - val_accuracy: 0.8635\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2961 - accuracy: 0.8596 - val_loss: 0.2923 - val_accuracy: 0.8634\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2956 - accuracy: 0.8592 - val_loss: 0.2922 - val_accuracy: 0.8647\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2951 - accuracy: 0.8596 - val_loss: 0.2913 - val_accuracy: 0.8640\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2944 - accuracy: 0.8598 - val_loss: 0.2909 - val_accuracy: 0.8634\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2940 - accuracy: 0.8596 - val_loss: 0.2909 - val_accuracy: 0.8637\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2934 - accuracy: 0.8598 - val_loss: 0.2902 - val_accuracy: 0.8652\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2930 - accuracy: 0.8599 - val_loss: 0.2901 - val_accuracy: 0.8639\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2924 - accuracy: 0.8602 - val_loss: 0.2897 - val_accuracy: 0.8654\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2919 - accuracy: 0.8609 - val_loss: 0.2896 - val_accuracy: 0.8656\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2915 - accuracy: 0.8604 - val_loss: 0.2889 - val_accuracy: 0.8650\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2912 - accuracy: 0.8607 - val_loss: 0.2890 - val_accuracy: 0.8658\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2908 - accuracy: 0.8610 - val_loss: 0.2883 - val_accuracy: 0.8655\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2903 - accuracy: 0.8612 - val_loss: 0.2878 - val_accuracy: 0.8653\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2899 - accuracy: 0.8608 - val_loss: 0.2879 - val_accuracy: 0.8660\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2895 - accuracy: 0.8614 - val_loss: 0.2868 - val_accuracy: 0.8661\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2891 - accuracy: 0.8619 - val_loss: 0.2869 - val_accuracy: 0.8658\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2887 - accuracy: 0.8615 - val_loss: 0.2858 - val_accuracy: 0.8662\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2883 - accuracy: 0.8618 - val_loss: 0.2859 - val_accuracy: 0.8658\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2878 - accuracy: 0.8619 - val_loss: 0.2862 - val_accuracy: 0.8665\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2875 - accuracy: 0.8624 - val_loss: 0.2852 - val_accuracy: 0.8658\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2872 - accuracy: 0.8620 - val_loss: 0.2855 - val_accuracy: 0.8662\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2870 - accuracy: 0.8619 - val_loss: 0.2850 - val_accuracy: 0.8665\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2866 - accuracy: 0.8617 - val_loss: 0.2842 - val_accuracy: 0.8663\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2862 - accuracy: 0.8632 - val_loss: 0.2848 - val_accuracy: 0.8667\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2860 - accuracy: 0.8622 - val_loss: 0.2836 - val_accuracy: 0.8676\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2857 - accuracy: 0.8623 - val_loss: 0.2838 - val_accuracy: 0.8663\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2855 - accuracy: 0.8624 - val_loss: 0.2830 - val_accuracy: 0.8670\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2852 - accuracy: 0.8626 - val_loss: 0.2835 - val_accuracy: 0.8669\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2835 - accuracy: 0.8669\n",
            "정확률= 0.8669398427009583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. DNN - 2 / 8 / X / leaky_relu"
      ],
      "metadata": {
        "id": "d9gTTE4B7FyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp3 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp3.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp3.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp3.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8647"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCVe31Ha7HmA",
        "outputId": "fbf64a53-26d5-4d0e-e9fd-c78937b88a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 6ms/step - loss: 0.5156 - accuracy: 0.7290 - val_loss: 0.3372 - val_accuracy: 0.8456\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3251 - accuracy: 0.8489 - val_loss: 0.3137 - val_accuracy: 0.8549\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.8525 - val_loss: 0.3093 - val_accuracy: 0.8584\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3128 - accuracy: 0.8532 - val_loss: 0.3074 - val_accuracy: 0.8566\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.8540 - val_loss: 0.3049 - val_accuracy: 0.8593\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3088 - accuracy: 0.8546 - val_loss: 0.3033 - val_accuracy: 0.8591\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3070 - accuracy: 0.8556 - val_loss: 0.3024 - val_accuracy: 0.8594\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3056 - accuracy: 0.8560 - val_loss: 0.3012 - val_accuracy: 0.8605\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3043 - accuracy: 0.8561 - val_loss: 0.2997 - val_accuracy: 0.8583\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3030 - accuracy: 0.8569 - val_loss: 0.2984 - val_accuracy: 0.8599\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3021 - accuracy: 0.8566 - val_loss: 0.2978 - val_accuracy: 0.8609\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3011 - accuracy: 0.8577 - val_loss: 0.2975 - val_accuracy: 0.8589\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3002 - accuracy: 0.8578 - val_loss: 0.2967 - val_accuracy: 0.8599\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2995 - accuracy: 0.8579 - val_loss: 0.2959 - val_accuracy: 0.8594\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2986 - accuracy: 0.8584 - val_loss: 0.2951 - val_accuracy: 0.8605\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2981 - accuracy: 0.8582 - val_loss: 0.2945 - val_accuracy: 0.8604\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2973 - accuracy: 0.8588 - val_loss: 0.2943 - val_accuracy: 0.8609\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2966 - accuracy: 0.8586 - val_loss: 0.2940 - val_accuracy: 0.8618\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2959 - accuracy: 0.8593 - val_loss: 0.2943 - val_accuracy: 0.8615\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2955 - accuracy: 0.8591 - val_loss: 0.2931 - val_accuracy: 0.8624\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2948 - accuracy: 0.8599 - val_loss: 0.2924 - val_accuracy: 0.8622\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2944 - accuracy: 0.8596 - val_loss: 0.2920 - val_accuracy: 0.8615\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2938 - accuracy: 0.8595 - val_loss: 0.2918 - val_accuracy: 0.8618\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2933 - accuracy: 0.8595 - val_loss: 0.2912 - val_accuracy: 0.8621\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2929 - accuracy: 0.8592 - val_loss: 0.2908 - val_accuracy: 0.8625\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2923 - accuracy: 0.8598 - val_loss: 0.2905 - val_accuracy: 0.8634\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2918 - accuracy: 0.8600 - val_loss: 0.2902 - val_accuracy: 0.8621\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2914 - accuracy: 0.8599 - val_loss: 0.2897 - val_accuracy: 0.8624\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2908 - accuracy: 0.8604 - val_loss: 0.2893 - val_accuracy: 0.8617\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2904 - accuracy: 0.8606 - val_loss: 0.2894 - val_accuracy: 0.8626\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2901 - accuracy: 0.8615 - val_loss: 0.2884 - val_accuracy: 0.8625\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2897 - accuracy: 0.8609 - val_loss: 0.2880 - val_accuracy: 0.8625\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2889 - accuracy: 0.8614 - val_loss: 0.2882 - val_accuracy: 0.8624\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2885 - accuracy: 0.8615 - val_loss: 0.2875 - val_accuracy: 0.8619\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2878 - accuracy: 0.8617 - val_loss: 0.2870 - val_accuracy: 0.8619\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2879 - accuracy: 0.8612 - val_loss: 0.2869 - val_accuracy: 0.8619\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.8619 - val_loss: 0.2874 - val_accuracy: 0.8615\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2867 - accuracy: 0.8618 - val_loss: 0.2864 - val_accuracy: 0.8615\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2864 - accuracy: 0.8618 - val_loss: 0.2857 - val_accuracy: 0.8623\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2860 - accuracy: 0.8622 - val_loss: 0.2856 - val_accuracy: 0.8632\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2857 - accuracy: 0.8616 - val_loss: 0.2857 - val_accuracy: 0.8613\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2853 - accuracy: 0.8623 - val_loss: 0.2856 - val_accuracy: 0.8640\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2850 - accuracy: 0.8622 - val_loss: 0.2853 - val_accuracy: 0.8648\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2848 - accuracy: 0.8622 - val_loss: 0.2853 - val_accuracy: 0.8646\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2846 - accuracy: 0.8620 - val_loss: 0.2845 - val_accuracy: 0.8633\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2841 - accuracy: 0.8623 - val_loss: 0.2843 - val_accuracy: 0.8631\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2839 - accuracy: 0.8628 - val_loss: 0.2842 - val_accuracy: 0.8644\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2838 - accuracy: 0.8632 - val_loss: 0.2845 - val_accuracy: 0.8646\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2835 - accuracy: 0.8630 - val_loss: 0.2835 - val_accuracy: 0.8647\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2832 - accuracy: 0.8631 - val_loss: 0.2829 - val_accuracy: 0.8647\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2829 - accuracy: 0.8647\n",
            "정확률= 0.8646754622459412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. DNN - 2 / 16 / X / leaky_relu"
      ],
      "metadata": {
        "id": "nuRqv1tv7Uxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp4 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp4.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp4.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp4.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8667"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0ltWZfn7Y79",
        "outputId": "89097e23-4fe0-43d7-e725-f0f29f22397c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3891 - accuracy: 0.8255 - val_loss: 0.3156 - val_accuracy: 0.8556\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3151 - accuracy: 0.8532 - val_loss: 0.3070 - val_accuracy: 0.8590\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3092 - accuracy: 0.8557 - val_loss: 0.3031 - val_accuracy: 0.8591\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3056 - accuracy: 0.8560 - val_loss: 0.3000 - val_accuracy: 0.8623\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3027 - accuracy: 0.8574 - val_loss: 0.2974 - val_accuracy: 0.8612\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3005 - accuracy: 0.8577 - val_loss: 0.2965 - val_accuracy: 0.8625\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2983 - accuracy: 0.8592 - val_loss: 0.2935 - val_accuracy: 0.8625\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2965 - accuracy: 0.8602 - val_loss: 0.2924 - val_accuracy: 0.8639\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2946 - accuracy: 0.8603 - val_loss: 0.2907 - val_accuracy: 0.8652\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2929 - accuracy: 0.8616 - val_loss: 0.2899 - val_accuracy: 0.8644\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2914 - accuracy: 0.8608 - val_loss: 0.2882 - val_accuracy: 0.8660\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2901 - accuracy: 0.8624 - val_loss: 0.2876 - val_accuracy: 0.8648\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.8620 - val_loss: 0.2862 - val_accuracy: 0.8651\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2874 - accuracy: 0.8632 - val_loss: 0.2861 - val_accuracy: 0.8631\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2865 - accuracy: 0.8628 - val_loss: 0.2839 - val_accuracy: 0.8654\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.8628 - val_loss: 0.2838 - val_accuracy: 0.8677\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.8637 - val_loss: 0.2829 - val_accuracy: 0.8667\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2833 - accuracy: 0.8640 - val_loss: 0.2817 - val_accuracy: 0.8678\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2822 - accuracy: 0.8641 - val_loss: 0.2814 - val_accuracy: 0.8661\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2817 - accuracy: 0.8641 - val_loss: 0.2807 - val_accuracy: 0.8664\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2807 - accuracy: 0.8644 - val_loss: 0.2809 - val_accuracy: 0.8670\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2803 - accuracy: 0.8645 - val_loss: 0.2794 - val_accuracy: 0.8680\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2798 - accuracy: 0.8651 - val_loss: 0.2790 - val_accuracy: 0.8673\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2788 - accuracy: 0.8656 - val_loss: 0.2796 - val_accuracy: 0.8680\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2783 - accuracy: 0.8646 - val_loss: 0.2776 - val_accuracy: 0.8675\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.8653 - val_loss: 0.2778 - val_accuracy: 0.8677\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.8653 - val_loss: 0.2772 - val_accuracy: 0.8663\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2767 - accuracy: 0.8653 - val_loss: 0.2766 - val_accuracy: 0.8670\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.8660 - val_loss: 0.2782 - val_accuracy: 0.8664\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2758 - accuracy: 0.8657 - val_loss: 0.2761 - val_accuracy: 0.8678\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2752 - accuracy: 0.8657 - val_loss: 0.2761 - val_accuracy: 0.8680\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.8659 - val_loss: 0.2756 - val_accuracy: 0.8680\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2747 - accuracy: 0.8663 - val_loss: 0.2758 - val_accuracy: 0.8687\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8666 - val_loss: 0.2752 - val_accuracy: 0.8682\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2738 - accuracy: 0.8662 - val_loss: 0.2744 - val_accuracy: 0.8687\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2734 - accuracy: 0.8662 - val_loss: 0.2739 - val_accuracy: 0.8694\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2733 - accuracy: 0.8674 - val_loss: 0.2748 - val_accuracy: 0.8670\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2727 - accuracy: 0.8666 - val_loss: 0.2740 - val_accuracy: 0.8656\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2726 - accuracy: 0.8668 - val_loss: 0.2738 - val_accuracy: 0.8678\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2723 - accuracy: 0.8669 - val_loss: 0.2742 - val_accuracy: 0.8675\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2723 - accuracy: 0.8671 - val_loss: 0.2738 - val_accuracy: 0.8666\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2716 - accuracy: 0.8672 - val_loss: 0.2730 - val_accuracy: 0.8689\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2719 - accuracy: 0.8671 - val_loss: 0.2730 - val_accuracy: 0.8679\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2715 - accuracy: 0.8673 - val_loss: 0.2729 - val_accuracy: 0.8661\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2711 - accuracy: 0.8673 - val_loss: 0.2730 - val_accuracy: 0.8673\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2710 - accuracy: 0.8675 - val_loss: 0.2735 - val_accuracy: 0.8661\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2706 - accuracy: 0.8680 - val_loss: 0.2725 - val_accuracy: 0.8681\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2706 - accuracy: 0.8677 - val_loss: 0.2731 - val_accuracy: 0.8687\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2704 - accuracy: 0.8687 - val_loss: 0.2721 - val_accuracy: 0.8670\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2703 - accuracy: 0.8672 - val_loss: 0.2726 - val_accuracy: 0.8667\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8667\n",
            "정확률= 0.8667241930961609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. DNN - 3 / 8 / X / leaky_relu"
      ],
      "metadata": {
        "id": "hjA6qib87c6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp5 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp5.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp5.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp5.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8647"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmo9SaD87mQX",
        "outputId": "34e9f07b-549d-4faf-8620-d5f69d45e8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 4s 6ms/step - loss: 0.4462 - accuracy: 0.8027 - val_loss: 0.3261 - val_accuracy: 0.8476\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3250 - accuracy: 0.8500 - val_loss: 0.3156 - val_accuracy: 0.8559\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3169 - accuracy: 0.8532 - val_loss: 0.3097 - val_accuracy: 0.8598\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3120 - accuracy: 0.8543 - val_loss: 0.3064 - val_accuracy: 0.8568\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3083 - accuracy: 0.8556 - val_loss: 0.3036 - val_accuracy: 0.8591\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3059 - accuracy: 0.8570 - val_loss: 0.3019 - val_accuracy: 0.8593\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3041 - accuracy: 0.8578 - val_loss: 0.3009 - val_accuracy: 0.8584\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3029 - accuracy: 0.8574 - val_loss: 0.2993 - val_accuracy: 0.8589\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3015 - accuracy: 0.8586 - val_loss: 0.2984 - val_accuracy: 0.8587\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3004 - accuracy: 0.8577 - val_loss: 0.2979 - val_accuracy: 0.8597\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2994 - accuracy: 0.8582 - val_loss: 0.2972 - val_accuracy: 0.8605\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2986 - accuracy: 0.8587 - val_loss: 0.2969 - val_accuracy: 0.8591\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2975 - accuracy: 0.8585 - val_loss: 0.2953 - val_accuracy: 0.8611\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2964 - accuracy: 0.8583 - val_loss: 0.2945 - val_accuracy: 0.8615\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2955 - accuracy: 0.8594 - val_loss: 0.2942 - val_accuracy: 0.8601\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2945 - accuracy: 0.8592 - val_loss: 0.2940 - val_accuracy: 0.8601\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2936 - accuracy: 0.8599 - val_loss: 0.2925 - val_accuracy: 0.8593\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2926 - accuracy: 0.8598 - val_loss: 0.2911 - val_accuracy: 0.8615\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2918 - accuracy: 0.8596 - val_loss: 0.2907 - val_accuracy: 0.8603\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2908 - accuracy: 0.8605 - val_loss: 0.2903 - val_accuracy: 0.8601\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2904 - accuracy: 0.8599 - val_loss: 0.2889 - val_accuracy: 0.8617\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2893 - accuracy: 0.8612 - val_loss: 0.2886 - val_accuracy: 0.8612\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2886 - accuracy: 0.8609 - val_loss: 0.2876 - val_accuracy: 0.8626\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2880 - accuracy: 0.8611 - val_loss: 0.2869 - val_accuracy: 0.8638\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2872 - accuracy: 0.8616 - val_loss: 0.2863 - val_accuracy: 0.8635\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2868 - accuracy: 0.8617 - val_loss: 0.2885 - val_accuracy: 0.8610\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2864 - accuracy: 0.8616 - val_loss: 0.2853 - val_accuracy: 0.8636\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.8618 - val_loss: 0.2859 - val_accuracy: 0.8637\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2852 - accuracy: 0.8626 - val_loss: 0.2847 - val_accuracy: 0.8648\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2845 - accuracy: 0.8626 - val_loss: 0.2854 - val_accuracy: 0.8635\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2841 - accuracy: 0.8628 - val_loss: 0.2845 - val_accuracy: 0.8636\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2837 - accuracy: 0.8633 - val_loss: 0.2838 - val_accuracy: 0.8636\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2833 - accuracy: 0.8634 - val_loss: 0.2834 - val_accuracy: 0.8653\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2828 - accuracy: 0.8631 - val_loss: 0.2831 - val_accuracy: 0.8656\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2824 - accuracy: 0.8630 - val_loss: 0.2828 - val_accuracy: 0.8647\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.8633 - val_loss: 0.2821 - val_accuracy: 0.8664\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2819 - accuracy: 0.8641 - val_loss: 0.2827 - val_accuracy: 0.8665\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2815 - accuracy: 0.8636 - val_loss: 0.2820 - val_accuracy: 0.8652\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2813 - accuracy: 0.8637 - val_loss: 0.2830 - val_accuracy: 0.8634\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2810 - accuracy: 0.8642 - val_loss: 0.2815 - val_accuracy: 0.8641\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2806 - accuracy: 0.8646 - val_loss: 0.2805 - val_accuracy: 0.8651\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.8637 - val_loss: 0.2809 - val_accuracy: 0.8660\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2803 - accuracy: 0.8641 - val_loss: 0.2811 - val_accuracy: 0.8650\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.8638 - val_loss: 0.2803 - val_accuracy: 0.8663\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2800 - accuracy: 0.8641 - val_loss: 0.2798 - val_accuracy: 0.8661\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2798 - accuracy: 0.8644 - val_loss: 0.2795 - val_accuracy: 0.8654\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2793 - accuracy: 0.8643 - val_loss: 0.2794 - val_accuracy: 0.8661\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2794 - accuracy: 0.8648 - val_loss: 0.2795 - val_accuracy: 0.8655\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2790 - accuracy: 0.8636 - val_loss: 0.2794 - val_accuracy: 0.8660\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2789 - accuracy: 0.8642 - val_loss: 0.2798 - val_accuracy: 0.8647\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2798 - accuracy: 0.8647\n",
            "정확률= 0.8646754622459412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. DNN - 3 / 16 / X / leaky_relu"
      ],
      "metadata": {
        "id": "XBU65r2A7rpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp6 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp6.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp6.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp6.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8697"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJzMXl0u7urZ",
        "outputId": "10757600-2cf9-4803-f4ae-796c71ba07c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 2s 3ms/step - loss: 0.3826 - accuracy: 0.8290 - val_loss: 0.3134 - val_accuracy: 0.8564\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3125 - accuracy: 0.8529 - val_loss: 0.3038 - val_accuracy: 0.8559\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3059 - accuracy: 0.8548 - val_loss: 0.2989 - val_accuracy: 0.8597\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3012 - accuracy: 0.8565 - val_loss: 0.2949 - val_accuracy: 0.8622\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2977 - accuracy: 0.8581 - val_loss: 0.2912 - val_accuracy: 0.8625\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2946 - accuracy: 0.8593 - val_loss: 0.2898 - val_accuracy: 0.8639\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2919 - accuracy: 0.8610 - val_loss: 0.2891 - val_accuracy: 0.8654\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2896 - accuracy: 0.8613 - val_loss: 0.2865 - val_accuracy: 0.8618\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2877 - accuracy: 0.8632 - val_loss: 0.2841 - val_accuracy: 0.8636\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2853 - accuracy: 0.8621 - val_loss: 0.2834 - val_accuracy: 0.8631\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.8639 - val_loss: 0.2822 - val_accuracy: 0.8649\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2826 - accuracy: 0.8638 - val_loss: 0.2826 - val_accuracy: 0.8649\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2814 - accuracy: 0.8642 - val_loss: 0.2815 - val_accuracy: 0.8648\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2806 - accuracy: 0.8640 - val_loss: 0.2796 - val_accuracy: 0.8644\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2797 - accuracy: 0.8651 - val_loss: 0.2793 - val_accuracy: 0.8649\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.8660 - val_loss: 0.2785 - val_accuracy: 0.8656\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2780 - accuracy: 0.8665 - val_loss: 0.2768 - val_accuracy: 0.8651\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.8661 - val_loss: 0.2774 - val_accuracy: 0.8666\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2760 - accuracy: 0.8668 - val_loss: 0.2764 - val_accuracy: 0.8661\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2755 - accuracy: 0.8666 - val_loss: 0.2776 - val_accuracy: 0.8646\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2745 - accuracy: 0.8667 - val_loss: 0.2749 - val_accuracy: 0.8644\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2741 - accuracy: 0.8669 - val_loss: 0.2751 - val_accuracy: 0.8672\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2731 - accuracy: 0.8677 - val_loss: 0.2771 - val_accuracy: 0.8641\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2729 - accuracy: 0.8676 - val_loss: 0.2748 - val_accuracy: 0.8653\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2722 - accuracy: 0.8681 - val_loss: 0.2760 - val_accuracy: 0.8666\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2715 - accuracy: 0.8684 - val_loss: 0.2742 - val_accuracy: 0.8665\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2708 - accuracy: 0.8683 - val_loss: 0.2717 - val_accuracy: 0.8667\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2701 - accuracy: 0.8691 - val_loss: 0.2772 - val_accuracy: 0.8660\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2697 - accuracy: 0.8689 - val_loss: 0.2725 - val_accuracy: 0.8667\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2699 - accuracy: 0.8679 - val_loss: 0.2710 - val_accuracy: 0.8674\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2692 - accuracy: 0.8694 - val_loss: 0.2727 - val_accuracy: 0.8680\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2686 - accuracy: 0.8694 - val_loss: 0.2708 - val_accuracy: 0.8675\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.8689 - val_loss: 0.2712 - val_accuracy: 0.8672\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2683 - accuracy: 0.8690 - val_loss: 0.2717 - val_accuracy: 0.8652\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2680 - accuracy: 0.8700 - val_loss: 0.2702 - val_accuracy: 0.8680\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2674 - accuracy: 0.8695 - val_loss: 0.2703 - val_accuracy: 0.8678\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.8698 - val_loss: 0.2702 - val_accuracy: 0.8681\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2671 - accuracy: 0.8688 - val_loss: 0.2696 - val_accuracy: 0.8691\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2672 - accuracy: 0.8700 - val_loss: 0.2734 - val_accuracy: 0.8654\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2667 - accuracy: 0.8694 - val_loss: 0.2735 - val_accuracy: 0.8650\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2668 - accuracy: 0.8692 - val_loss: 0.2693 - val_accuracy: 0.8693\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2663 - accuracy: 0.8697 - val_loss: 0.2691 - val_accuracy: 0.8700\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2656 - accuracy: 0.8701 - val_loss: 0.2689 - val_accuracy: 0.8659\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2658 - accuracy: 0.8697 - val_loss: 0.2679 - val_accuracy: 0.8680\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2656 - accuracy: 0.8691 - val_loss: 0.2685 - val_accuracy: 0.8693\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.8704 - val_loss: 0.2674 - val_accuracy: 0.8694\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2651 - accuracy: 0.8693 - val_loss: 0.2675 - val_accuracy: 0.8714\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2649 - accuracy: 0.8709 - val_loss: 0.2714 - val_accuracy: 0.8639\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.8687 - val_loss: 0.2673 - val_accuracy: 0.8681\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2647 - accuracy: 0.8698 - val_loss: 0.2673 - val_accuracy: 0.8697\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8697\n",
            "정확률= 0.8697433471679688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. DNN - 4 / 8 / X / leaky_relu"
      ],
      "metadata": {
        "id": "_ITs30CM7z_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp7 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp7.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp7.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp7.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8666"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVSdfwsW7zeO",
        "outputId": "2628bfaf-be50-464b-ecbe-4786b095ff87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 5s 9ms/step - loss: 0.4011 - accuracy: 0.8110 - val_loss: 0.3187 - val_accuracy: 0.8531\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3189 - accuracy: 0.8511 - val_loss: 0.3129 - val_accuracy: 0.8543\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3145 - accuracy: 0.8524 - val_loss: 0.3089 - val_accuracy: 0.8567\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 3s 11ms/step - loss: 0.3114 - accuracy: 0.8536 - val_loss: 0.3060 - val_accuracy: 0.8586\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3085 - accuracy: 0.8550 - val_loss: 0.3050 - val_accuracy: 0.8585\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3057 - accuracy: 0.8560 - val_loss: 0.3021 - val_accuracy: 0.8584\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3036 - accuracy: 0.8566 - val_loss: 0.3015 - val_accuracy: 0.8571\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3018 - accuracy: 0.8568 - val_loss: 0.2990 - val_accuracy: 0.8583\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.2998 - accuracy: 0.8576 - val_loss: 0.2977 - val_accuracy: 0.8586\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2984 - accuracy: 0.8581 - val_loss: 0.2973 - val_accuracy: 0.8567\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2973 - accuracy: 0.8582 - val_loss: 0.2960 - val_accuracy: 0.8592\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2960 - accuracy: 0.8590 - val_loss: 0.2960 - val_accuracy: 0.8573\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2951 - accuracy: 0.8594 - val_loss: 0.2944 - val_accuracy: 0.8599\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2937 - accuracy: 0.8599 - val_loss: 0.2949 - val_accuracy: 0.8594\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2928 - accuracy: 0.8604 - val_loss: 0.2937 - val_accuracy: 0.8605\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2921 - accuracy: 0.8594 - val_loss: 0.2927 - val_accuracy: 0.8597\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2914 - accuracy: 0.8601 - val_loss: 0.2920 - val_accuracy: 0.8612\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.2906 - accuracy: 0.8610 - val_loss: 0.2916 - val_accuracy: 0.8604\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2898 - accuracy: 0.8607 - val_loss: 0.2911 - val_accuracy: 0.8618\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2892 - accuracy: 0.8607 - val_loss: 0.2916 - val_accuracy: 0.8610\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2881 - accuracy: 0.8615 - val_loss: 0.2957 - val_accuracy: 0.8582\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2879 - accuracy: 0.8611 - val_loss: 0.2901 - val_accuracy: 0.8597\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2871 - accuracy: 0.8623 - val_loss: 0.2887 - val_accuracy: 0.8617\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2862 - accuracy: 0.8616 - val_loss: 0.2893 - val_accuracy: 0.8633\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2859 - accuracy: 0.8617 - val_loss: 0.2879 - val_accuracy: 0.8633\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2857 - accuracy: 0.8620 - val_loss: 0.2880 - val_accuracy: 0.8626\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2848 - accuracy: 0.8618 - val_loss: 0.2868 - val_accuracy: 0.8634\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2849 - accuracy: 0.8616 - val_loss: 0.2870 - val_accuracy: 0.8621\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2838 - accuracy: 0.8619 - val_loss: 0.2867 - val_accuracy: 0.8622\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2838 - accuracy: 0.8622 - val_loss: 0.2858 - val_accuracy: 0.8649\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2832 - accuracy: 0.8629 - val_loss: 0.2852 - val_accuracy: 0.8644\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2827 - accuracy: 0.8629 - val_loss: 0.2856 - val_accuracy: 0.8618\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2825 - accuracy: 0.8628 - val_loss: 0.2856 - val_accuracy: 0.8615\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2818 - accuracy: 0.8633 - val_loss: 0.2836 - val_accuracy: 0.8630\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.2809 - accuracy: 0.8635 - val_loss: 0.2832 - val_accuracy: 0.8677\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.2808 - accuracy: 0.8634 - val_loss: 0.2829 - val_accuracy: 0.8658\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2800 - accuracy: 0.8642 - val_loss: 0.2825 - val_accuracy: 0.8654\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2794 - accuracy: 0.8644 - val_loss: 0.2807 - val_accuracy: 0.8658\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2790 - accuracy: 0.8645 - val_loss: 0.2818 - val_accuracy: 0.8646\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2780 - accuracy: 0.8645 - val_loss: 0.2806 - val_accuracy: 0.8679\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2777 - accuracy: 0.8644 - val_loss: 0.2808 - val_accuracy: 0.8675\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2772 - accuracy: 0.8648 - val_loss: 0.2796 - val_accuracy: 0.8653\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.2765 - accuracy: 0.8649 - val_loss: 0.2787 - val_accuracy: 0.8674\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.2764 - accuracy: 0.8654 - val_loss: 0.2799 - val_accuracy: 0.8646\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2756 - accuracy: 0.8659 - val_loss: 0.2810 - val_accuracy: 0.8639\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.2751 - accuracy: 0.8660 - val_loss: 0.2786 - val_accuracy: 0.8689\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.2745 - accuracy: 0.8659 - val_loss: 0.2780 - val_accuracy: 0.8678\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2744 - accuracy: 0.8668 - val_loss: 0.2787 - val_accuracy: 0.8675\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2734 - accuracy: 0.8673 - val_loss: 0.2822 - val_accuracy: 0.8663\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.2731 - accuracy: 0.8656 - val_loss: 0.2765 - val_accuracy: 0.8666\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2765 - accuracy: 0.8666\n",
            "정확률= 0.8666163682937622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. DNN - 4 / 16 / X / leaky_relu"
      ],
      "metadata": {
        "id": "MhVlQazS78nV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp8 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp8.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp8.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp8.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8692"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOwGzbJ98AiV",
        "outputId": "e403d650-54a3-4d99-f902-3bf4d3107ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 5ms/step - loss: 0.3970 - accuracy: 0.8198 - val_loss: 0.3090 - val_accuracy: 0.8565\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3078 - accuracy: 0.8553 - val_loss: 0.2996 - val_accuracy: 0.8604\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3014 - accuracy: 0.8582 - val_loss: 0.2951 - val_accuracy: 0.8628\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2972 - accuracy: 0.8585 - val_loss: 0.2938 - val_accuracy: 0.8612\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2932 - accuracy: 0.8608 - val_loss: 0.2929 - val_accuracy: 0.8604\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2897 - accuracy: 0.8618 - val_loss: 0.2864 - val_accuracy: 0.8635\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2864 - accuracy: 0.8621 - val_loss: 0.2857 - val_accuracy: 0.8610\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2843 - accuracy: 0.8629 - val_loss: 0.2837 - val_accuracy: 0.8617\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2826 - accuracy: 0.8636 - val_loss: 0.2828 - val_accuracy: 0.8638\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.8632 - val_loss: 0.2813 - val_accuracy: 0.8635\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.8636 - val_loss: 0.2802 - val_accuracy: 0.8642\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2781 - accuracy: 0.8640 - val_loss: 0.2792 - val_accuracy: 0.8646\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.8643 - val_loss: 0.2816 - val_accuracy: 0.8633\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.8651 - val_loss: 0.2773 - val_accuracy: 0.8636\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.8649 - val_loss: 0.2770 - val_accuracy: 0.8658\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2739 - accuracy: 0.8660 - val_loss: 0.2759 - val_accuracy: 0.8640\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2731 - accuracy: 0.8649 - val_loss: 0.2775 - val_accuracy: 0.8650\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2725 - accuracy: 0.8662 - val_loss: 0.2774 - val_accuracy: 0.8666\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2718 - accuracy: 0.8656 - val_loss: 0.2741 - val_accuracy: 0.8663\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2708 - accuracy: 0.8659 - val_loss: 0.2780 - val_accuracy: 0.8644\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2707 - accuracy: 0.8662 - val_loss: 0.2806 - val_accuracy: 0.8662\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2702 - accuracy: 0.8672 - val_loss: 0.2749 - val_accuracy: 0.8661\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2695 - accuracy: 0.8672 - val_loss: 0.2735 - val_accuracy: 0.8655\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2696 - accuracy: 0.8670 - val_loss: 0.2743 - val_accuracy: 0.8680\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2689 - accuracy: 0.8672 - val_loss: 0.2741 - val_accuracy: 0.8695\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2685 - accuracy: 0.8669 - val_loss: 0.2720 - val_accuracy: 0.8691\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2686 - accuracy: 0.8670 - val_loss: 0.2766 - val_accuracy: 0.8676\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2677 - accuracy: 0.8669 - val_loss: 0.2720 - val_accuracy: 0.8684\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2673 - accuracy: 0.8687 - val_loss: 0.2709 - val_accuracy: 0.8702\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2671 - accuracy: 0.8686 - val_loss: 0.2718 - val_accuracy: 0.8717\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2667 - accuracy: 0.8678 - val_loss: 0.2723 - val_accuracy: 0.8692\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2662 - accuracy: 0.8693 - val_loss: 0.2703 - val_accuracy: 0.8696\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2656 - accuracy: 0.8695 - val_loss: 0.2731 - val_accuracy: 0.8700\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2658 - accuracy: 0.8684 - val_loss: 0.2741 - val_accuracy: 0.8676\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2653 - accuracy: 0.8691 - val_loss: 0.2705 - val_accuracy: 0.8688\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2656 - accuracy: 0.8682 - val_loss: 0.2713 - val_accuracy: 0.8701\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2650 - accuracy: 0.8689 - val_loss: 0.2717 - val_accuracy: 0.8689\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.8690 - val_loss: 0.2711 - val_accuracy: 0.8689\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2646 - accuracy: 0.8700 - val_loss: 0.2710 - val_accuracy: 0.8701\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2642 - accuracy: 0.8695 - val_loss: 0.2729 - val_accuracy: 0.8669\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2644 - accuracy: 0.8696 - val_loss: 0.2698 - val_accuracy: 0.8696\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2644 - accuracy: 0.8692 - val_loss: 0.2719 - val_accuracy: 0.8705\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2645 - accuracy: 0.8694 - val_loss: 0.2704 - val_accuracy: 0.8689\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2638 - accuracy: 0.8695 - val_loss: 0.2741 - val_accuracy: 0.8681\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2635 - accuracy: 0.8699 - val_loss: 0.2695 - val_accuracy: 0.8695\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2637 - accuracy: 0.8693 - val_loss: 0.2703 - val_accuracy: 0.8697\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2637 - accuracy: 0.8700 - val_loss: 0.2695 - val_accuracy: 0.8699\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2629 - accuracy: 0.8699 - val_loss: 0.2702 - val_accuracy: 0.8694\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2631 - accuracy: 0.8700 - val_loss: 0.2685 - val_accuracy: 0.8704\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2630 - accuracy: 0.8709 - val_loss: 0.2688 - val_accuracy: 0.8692\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8692\n",
            "정확률= 0.8692042231559753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. DNN - 5 / 8 / X / leaky_relu"
      ],
      "metadata": {
        "id": "K6WX7wQG8E76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp9 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp9.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp9.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp9.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8669"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaYr1c_G8JPQ",
        "outputId": "d683fc20-67a2-4c2a-a1ab-4771f4010c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 2s 3ms/step - loss: 0.3922 - accuracy: 0.8338 - val_loss: 0.3232 - val_accuracy: 0.8530\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3193 - accuracy: 0.8515 - val_loss: 0.3100 - val_accuracy: 0.8551\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3104 - accuracy: 0.8531 - val_loss: 0.3065 - val_accuracy: 0.8550\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3069 - accuracy: 0.8541 - val_loss: 0.3040 - val_accuracy: 0.8535\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3037 - accuracy: 0.8544 - val_loss: 0.3015 - val_accuracy: 0.8562\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3017 - accuracy: 0.8559 - val_loss: 0.2976 - val_accuracy: 0.8591\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2994 - accuracy: 0.8569 - val_loss: 0.2971 - val_accuracy: 0.8584\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2975 - accuracy: 0.8577 - val_loss: 0.2952 - val_accuracy: 0.8584\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2955 - accuracy: 0.8580 - val_loss: 0.2943 - val_accuracy: 0.8590\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2935 - accuracy: 0.8586 - val_loss: 0.2933 - val_accuracy: 0.8590\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2921 - accuracy: 0.8591 - val_loss: 0.2912 - val_accuracy: 0.8607\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2911 - accuracy: 0.8578 - val_loss: 0.2896 - val_accuracy: 0.8603\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2897 - accuracy: 0.8598 - val_loss: 0.2894 - val_accuracy: 0.8597\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2890 - accuracy: 0.8594 - val_loss: 0.2905 - val_accuracy: 0.8622\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2880 - accuracy: 0.8600 - val_loss: 0.2872 - val_accuracy: 0.8617\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2871 - accuracy: 0.8597 - val_loss: 0.2872 - val_accuracy: 0.8614\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2862 - accuracy: 0.8598 - val_loss: 0.2863 - val_accuracy: 0.8626\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2853 - accuracy: 0.8612 - val_loss: 0.2851 - val_accuracy: 0.8641\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2849 - accuracy: 0.8604 - val_loss: 0.2845 - val_accuracy: 0.8624\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2839 - accuracy: 0.8606 - val_loss: 0.2827 - val_accuracy: 0.8634\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2835 - accuracy: 0.8615 - val_loss: 0.2870 - val_accuracy: 0.8639\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2824 - accuracy: 0.8628 - val_loss: 0.2824 - val_accuracy: 0.8637\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2819 - accuracy: 0.8623 - val_loss: 0.2816 - val_accuracy: 0.8649\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2814 - accuracy: 0.8630 - val_loss: 0.2853 - val_accuracy: 0.8658\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2805 - accuracy: 0.8634 - val_loss: 0.2808 - val_accuracy: 0.8638\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2806 - accuracy: 0.8636 - val_loss: 0.2823 - val_accuracy: 0.8659\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.8629 - val_loss: 0.2816 - val_accuracy: 0.8645\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2796 - accuracy: 0.8631 - val_loss: 0.2793 - val_accuracy: 0.8660\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2789 - accuracy: 0.8635 - val_loss: 0.2805 - val_accuracy: 0.8666\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.8637 - val_loss: 0.2792 - val_accuracy: 0.8650\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.8632 - val_loss: 0.2791 - val_accuracy: 0.8648\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.8638 - val_loss: 0.2780 - val_accuracy: 0.8653\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2777 - accuracy: 0.8637 - val_loss: 0.2819 - val_accuracy: 0.8633\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.8637 - val_loss: 0.2783 - val_accuracy: 0.8640\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2769 - accuracy: 0.8648 - val_loss: 0.2782 - val_accuracy: 0.8663\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.8646 - val_loss: 0.2771 - val_accuracy: 0.8676\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2764 - accuracy: 0.8638 - val_loss: 0.2796 - val_accuracy: 0.8669\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2760 - accuracy: 0.8655 - val_loss: 0.2791 - val_accuracy: 0.8666\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2758 - accuracy: 0.8647 - val_loss: 0.2765 - val_accuracy: 0.8659\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2754 - accuracy: 0.8651 - val_loss: 0.2761 - val_accuracy: 0.8662\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2755 - accuracy: 0.8644 - val_loss: 0.2770 - val_accuracy: 0.8663\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2753 - accuracy: 0.8644 - val_loss: 0.2752 - val_accuracy: 0.8666\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2747 - accuracy: 0.8647 - val_loss: 0.2756 - val_accuracy: 0.8665\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.8646 - val_loss: 0.2811 - val_accuracy: 0.8647\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8648 - val_loss: 0.2751 - val_accuracy: 0.8670\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2744 - accuracy: 0.8644 - val_loss: 0.2769 - val_accuracy: 0.8667\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2741 - accuracy: 0.8650 - val_loss: 0.2751 - val_accuracy: 0.8662\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2742 - accuracy: 0.8649 - val_loss: 0.2749 - val_accuracy: 0.8663\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2739 - accuracy: 0.8647 - val_loss: 0.2746 - val_accuracy: 0.8669\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2734 - accuracy: 0.8657 - val_loss: 0.2749 - val_accuracy: 0.8669\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8669\n",
            "정확률= 0.8669398427009583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. DNN - 5 / 16 / X / leaky_relu"
      ],
      "metadata": {
        "id": "-DSnMLrF8MNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp10 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp10.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp10.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp10.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8711"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQxip0148OSL",
        "outputId": "f8980902-1f46-41b7-e66a-7f565f30d930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 2s 4ms/step - loss: 0.3880 - accuracy: 0.8153 - val_loss: 0.3095 - val_accuracy: 0.8518\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3080 - accuracy: 0.8519 - val_loss: 0.2965 - val_accuracy: 0.8595\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2964 - accuracy: 0.8560 - val_loss: 0.2903 - val_accuracy: 0.8622\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2905 - accuracy: 0.8589 - val_loss: 0.2861 - val_accuracy: 0.8633\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2858 - accuracy: 0.8604 - val_loss: 0.2843 - val_accuracy: 0.8647\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2831 - accuracy: 0.8599 - val_loss: 0.2823 - val_accuracy: 0.8652\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2801 - accuracy: 0.8618 - val_loss: 0.2794 - val_accuracy: 0.8659\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2783 - accuracy: 0.8629 - val_loss: 0.2788 - val_accuracy: 0.8665\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2764 - accuracy: 0.8651 - val_loss: 0.2755 - val_accuracy: 0.8688\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2745 - accuracy: 0.8641 - val_loss: 0.2769 - val_accuracy: 0.8688\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2734 - accuracy: 0.8656 - val_loss: 0.2750 - val_accuracy: 0.8700\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2717 - accuracy: 0.8663 - val_loss: 0.2738 - val_accuracy: 0.8690\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2712 - accuracy: 0.8667 - val_loss: 0.2725 - val_accuracy: 0.8692\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2701 - accuracy: 0.8678 - val_loss: 0.2719 - val_accuracy: 0.8697\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2696 - accuracy: 0.8687 - val_loss: 0.2731 - val_accuracy: 0.8687\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2686 - accuracy: 0.8674 - val_loss: 0.2705 - val_accuracy: 0.8706\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.8669 - val_loss: 0.2707 - val_accuracy: 0.8697\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2674 - accuracy: 0.8683 - val_loss: 0.2704 - val_accuracy: 0.8693\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2671 - accuracy: 0.8684 - val_loss: 0.2711 - val_accuracy: 0.8696\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2669 - accuracy: 0.8697 - val_loss: 0.2723 - val_accuracy: 0.8690\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.8697 - val_loss: 0.2703 - val_accuracy: 0.8699\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2659 - accuracy: 0.8683 - val_loss: 0.2693 - val_accuracy: 0.8728\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2654 - accuracy: 0.8695 - val_loss: 0.2688 - val_accuracy: 0.8700\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2651 - accuracy: 0.8693 - val_loss: 0.2690 - val_accuracy: 0.8697\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2650 - accuracy: 0.8692 - val_loss: 0.2687 - val_accuracy: 0.8704\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.8694 - val_loss: 0.2712 - val_accuracy: 0.8691\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2644 - accuracy: 0.8690 - val_loss: 0.2695 - val_accuracy: 0.8713\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.8697 - val_loss: 0.2695 - val_accuracy: 0.8706\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2636 - accuracy: 0.8696 - val_loss: 0.2705 - val_accuracy: 0.8707\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2635 - accuracy: 0.8698 - val_loss: 0.2688 - val_accuracy: 0.8710\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2637 - accuracy: 0.8695 - val_loss: 0.2713 - val_accuracy: 0.8695\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2630 - accuracy: 0.8691 - val_loss: 0.2688 - val_accuracy: 0.8701\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2629 - accuracy: 0.8702 - val_loss: 0.2674 - val_accuracy: 0.8717\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2626 - accuracy: 0.8701 - val_loss: 0.2730 - val_accuracy: 0.8668\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2624 - accuracy: 0.8702 - val_loss: 0.2670 - val_accuracy: 0.8705\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2624 - accuracy: 0.8701 - val_loss: 0.2682 - val_accuracy: 0.8703\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2625 - accuracy: 0.8693 - val_loss: 0.2660 - val_accuracy: 0.8707\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2618 - accuracy: 0.8706 - val_loss: 0.2682 - val_accuracy: 0.8695\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2626 - accuracy: 0.8695 - val_loss: 0.2682 - val_accuracy: 0.8690\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2617 - accuracy: 0.8708 - val_loss: 0.2678 - val_accuracy: 0.8710\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2615 - accuracy: 0.8702 - val_loss: 0.2716 - val_accuracy: 0.8701\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2617 - accuracy: 0.8710 - val_loss: 0.2689 - val_accuracy: 0.8718\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2612 - accuracy: 0.8713 - val_loss: 0.2665 - val_accuracy: 0.8708\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2608 - accuracy: 0.8712 - val_loss: 0.2671 - val_accuracy: 0.8705\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2615 - accuracy: 0.8709 - val_loss: 0.2663 - val_accuracy: 0.8708\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2611 - accuracy: 0.8696 - val_loss: 0.2670 - val_accuracy: 0.8703\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2606 - accuracy: 0.8708 - val_loss: 0.2672 - val_accuracy: 0.8722\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2609 - accuracy: 0.8703 - val_loss: 0.2702 - val_accuracy: 0.8705\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2607 - accuracy: 0.8699 - val_loss: 0.2655 - val_accuracy: 0.8716\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2609 - accuracy: 0.8694 - val_loss: 0.2655 - val_accuracy: 0.8711\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2655 - accuracy: 0.8711\n",
            "정확률= 0.8711451292037964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. DNN - 1 / 8 / O / leaky_relu"
      ],
      "metadata": {
        "id": "HCE-wrjf8d4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp11 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp11.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp11.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp11.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8571"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMsA687f-gxR",
        "outputId": "97d0d553-e92a-435e-cd32-e25d9cb50c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "290/290 [==============================] - 3s 5ms/step - loss: 0.5053 - accuracy: 0.7439 - val_loss: 0.3702 - val_accuracy: 0.8393\n",
            "Epoch 2/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3992 - accuracy: 0.8217 - val_loss: 0.3253 - val_accuracy: 0.8511\n",
            "Epoch 3/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3677 - accuracy: 0.8366 - val_loss: 0.3168 - val_accuracy: 0.8528\n",
            "Epoch 4/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3553 - accuracy: 0.8408 - val_loss: 0.3136 - val_accuracy: 0.8528\n",
            "Epoch 5/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3499 - accuracy: 0.8436 - val_loss: 0.3116 - val_accuracy: 0.8531\n",
            "Epoch 6/100\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3444 - accuracy: 0.8442 - val_loss: 0.3108 - val_accuracy: 0.8553\n",
            "Epoch 7/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3394 - accuracy: 0.8445 - val_loss: 0.3100 - val_accuracy: 0.8554\n",
            "Epoch 8/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3401 - accuracy: 0.8447 - val_loss: 0.3097 - val_accuracy: 0.8550\n",
            "Epoch 9/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3371 - accuracy: 0.8444 - val_loss: 0.3090 - val_accuracy: 0.8549\n",
            "Epoch 10/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3368 - accuracy: 0.8451 - val_loss: 0.3087 - val_accuracy: 0.8564\n",
            "Epoch 11/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3339 - accuracy: 0.8464 - val_loss: 0.3079 - val_accuracy: 0.8563\n",
            "Epoch 12/100\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3316 - accuracy: 0.8470 - val_loss: 0.3079 - val_accuracy: 0.8559\n",
            "Epoch 13/100\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.3317 - accuracy: 0.8474 - val_loss: 0.3075 - val_accuracy: 0.8565\n",
            "Epoch 14/100\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3321 - accuracy: 0.8450 - val_loss: 0.3076 - val_accuracy: 0.8563\n",
            "Epoch 15/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3331 - accuracy: 0.8454 - val_loss: 0.3075 - val_accuracy: 0.8567\n",
            "Epoch 16/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3329 - accuracy: 0.8448 - val_loss: 0.3078 - val_accuracy: 0.8562\n",
            "Epoch 17/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3315 - accuracy: 0.8452 - val_loss: 0.3072 - val_accuracy: 0.8571\n",
            "Epoch 18/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3309 - accuracy: 0.8457 - val_loss: 0.3074 - val_accuracy: 0.8564\n",
            "Epoch 19/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3319 - accuracy: 0.8461 - val_loss: 0.3074 - val_accuracy: 0.8565\n",
            "Epoch 20/100\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3303 - accuracy: 0.8450 - val_loss: 0.3073 - val_accuracy: 0.8560\n",
            "Epoch 21/100\n",
            "290/290 [==============================] - 3s 10ms/step - loss: 0.3311 - accuracy: 0.8452 - val_loss: 0.3073 - val_accuracy: 0.8566\n",
            "Epoch 22/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3302 - accuracy: 0.8457 - val_loss: 0.3071 - val_accuracy: 0.8564\n",
            "Epoch 23/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3333 - accuracy: 0.8451 - val_loss: 0.3070 - val_accuracy: 0.8568\n",
            "Epoch 24/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3308 - accuracy: 0.8455 - val_loss: 0.3072 - val_accuracy: 0.8558\n",
            "Epoch 25/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3309 - accuracy: 0.8441 - val_loss: 0.3070 - val_accuracy: 0.8563\n",
            "Epoch 26/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3298 - accuracy: 0.8449 - val_loss: 0.3070 - val_accuracy: 0.8558\n",
            "Epoch 27/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3320 - accuracy: 0.8451 - val_loss: 0.3071 - val_accuracy: 0.8562\n",
            "Epoch 28/100\n",
            "290/290 [==============================] - 3s 10ms/step - loss: 0.3317 - accuracy: 0.8461 - val_loss: 0.3071 - val_accuracy: 0.8558\n",
            "Epoch 29/100\n",
            "290/290 [==============================] - 3s 10ms/step - loss: 0.3303 - accuracy: 0.8459 - val_loss: 0.3067 - val_accuracy: 0.8562\n",
            "Epoch 30/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3300 - accuracy: 0.8449 - val_loss: 0.3069 - val_accuracy: 0.8565\n",
            "Epoch 31/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3320 - accuracy: 0.8450 - val_loss: 0.3068 - val_accuracy: 0.8562\n",
            "Epoch 32/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3295 - accuracy: 0.8456 - val_loss: 0.3065 - val_accuracy: 0.8565\n",
            "Epoch 33/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3320 - accuracy: 0.8454 - val_loss: 0.3064 - val_accuracy: 0.8570\n",
            "Epoch 34/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3308 - accuracy: 0.8469 - val_loss: 0.3064 - val_accuracy: 0.8565\n",
            "Epoch 35/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3310 - accuracy: 0.8462 - val_loss: 0.3063 - val_accuracy: 0.8567\n",
            "Epoch 36/100\n",
            "290/290 [==============================] - 3s 10ms/step - loss: 0.3303 - accuracy: 0.8455 - val_loss: 0.3062 - val_accuracy: 0.8570\n",
            "Epoch 37/100\n",
            "290/290 [==============================] - 3s 11ms/step - loss: 0.3303 - accuracy: 0.8450 - val_loss: 0.3062 - val_accuracy: 0.8570\n",
            "Epoch 38/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3302 - accuracy: 0.8457 - val_loss: 0.3061 - val_accuracy: 0.8570\n",
            "Epoch 39/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3296 - accuracy: 0.8463 - val_loss: 0.3058 - val_accuracy: 0.8581\n",
            "Epoch 40/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3296 - accuracy: 0.8464 - val_loss: 0.3058 - val_accuracy: 0.8568\n",
            "Epoch 41/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3305 - accuracy: 0.8447 - val_loss: 0.3058 - val_accuracy: 0.8573\n",
            "Epoch 42/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3296 - accuracy: 0.8466 - val_loss: 0.3057 - val_accuracy: 0.8576\n",
            "Epoch 43/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3315 - accuracy: 0.8456 - val_loss: 0.3057 - val_accuracy: 0.8578\n",
            "Epoch 44/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3281 - accuracy: 0.8460 - val_loss: 0.3060 - val_accuracy: 0.8575\n",
            "Epoch 45/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3298 - accuracy: 0.8446 - val_loss: 0.3059 - val_accuracy: 0.8577\n",
            "Epoch 46/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3312 - accuracy: 0.8464 - val_loss: 0.3059 - val_accuracy: 0.8573\n",
            "Epoch 47/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3297 - accuracy: 0.8442 - val_loss: 0.3055 - val_accuracy: 0.8571\n",
            "Epoch 48/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3301 - accuracy: 0.8481 - val_loss: 0.3056 - val_accuracy: 0.8568\n",
            "Epoch 49/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3312 - accuracy: 0.8452 - val_loss: 0.3058 - val_accuracy: 0.8571\n",
            "Epoch 50/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3309 - accuracy: 0.8441 - val_loss: 0.3054 - val_accuracy: 0.8568\n",
            "Epoch 51/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3324 - accuracy: 0.8438 - val_loss: 0.3055 - val_accuracy: 0.8572\n",
            "Epoch 52/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3297 - accuracy: 0.8472 - val_loss: 0.3056 - val_accuracy: 0.8576\n",
            "Epoch 53/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3312 - accuracy: 0.8456 - val_loss: 0.3056 - val_accuracy: 0.8571\n",
            "Epoch 54/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3316 - accuracy: 0.8437 - val_loss: 0.3055 - val_accuracy: 0.8573\n",
            "Epoch 55/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3296 - accuracy: 0.8457 - val_loss: 0.3055 - val_accuracy: 0.8573\n",
            "Epoch 56/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3306 - accuracy: 0.8453 - val_loss: 0.3056 - val_accuracy: 0.8576\n",
            "Epoch 57/100\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3321 - accuracy: 0.8432 - val_loss: 0.3058 - val_accuracy: 0.8567\n",
            "Epoch 58/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3317 - accuracy: 0.8448 - val_loss: 0.3060 - val_accuracy: 0.8571\n",
            "Epoch 59/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3293 - accuracy: 0.8450 - val_loss: 0.3059 - val_accuracy: 0.8572\n",
            "Epoch 60/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.8454 - val_loss: 0.3056 - val_accuracy: 0.8576\n",
            "Epoch 61/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.8446 - val_loss: 0.3059 - val_accuracy: 0.8572\n",
            "Epoch 62/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8453 - val_loss: 0.3058 - val_accuracy: 0.8572\n",
            "Epoch 63/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.8450 - val_loss: 0.3060 - val_accuracy: 0.8575\n",
            "Epoch 64/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3297 - accuracy: 0.8445 - val_loss: 0.3061 - val_accuracy: 0.8570\n",
            "Epoch 65/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8452 - val_loss: 0.3060 - val_accuracy: 0.8570\n",
            "Epoch 66/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3313 - accuracy: 0.8459 - val_loss: 0.3060 - val_accuracy: 0.8572\n",
            "Epoch 67/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3306 - accuracy: 0.8459 - val_loss: 0.3057 - val_accuracy: 0.8572\n",
            "Epoch 68/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.8458 - val_loss: 0.3059 - val_accuracy: 0.8568\n",
            "Epoch 69/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.8468 - val_loss: 0.3058 - val_accuracy: 0.8568\n",
            "Epoch 70/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8422 - val_loss: 0.3059 - val_accuracy: 0.8564\n",
            "Epoch 71/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3295 - accuracy: 0.8466 - val_loss: 0.3058 - val_accuracy: 0.8570\n",
            "Epoch 72/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3307 - accuracy: 0.8458 - val_loss: 0.3059 - val_accuracy: 0.8573\n",
            "Epoch 73/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3305 - accuracy: 0.8456 - val_loss: 0.3057 - val_accuracy: 0.8569\n",
            "Epoch 74/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3299 - accuracy: 0.8475 - val_loss: 0.3058 - val_accuracy: 0.8573\n",
            "Epoch 75/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8450 - val_loss: 0.3059 - val_accuracy: 0.8569\n",
            "Epoch 76/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8458 - val_loss: 0.3057 - val_accuracy: 0.8569\n",
            "Epoch 77/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8470 - val_loss: 0.3054 - val_accuracy: 0.8569\n",
            "Epoch 78/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3323 - accuracy: 0.8440 - val_loss: 0.3056 - val_accuracy: 0.8566\n",
            "Epoch 79/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.8449 - val_loss: 0.3056 - val_accuracy: 0.8573\n",
            "Epoch 80/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8449 - val_loss: 0.3055 - val_accuracy: 0.8569\n",
            "Epoch 81/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8457 - val_loss: 0.3056 - val_accuracy: 0.8572\n",
            "Epoch 82/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3306 - accuracy: 0.8454 - val_loss: 0.3057 - val_accuracy: 0.8570\n",
            "Epoch 83/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8441 - val_loss: 0.3058 - val_accuracy: 0.8576\n",
            "Epoch 84/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8438 - val_loss: 0.3056 - val_accuracy: 0.8575\n",
            "Epoch 85/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8453 - val_loss: 0.3055 - val_accuracy: 0.8572\n",
            "Epoch 86/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3290 - accuracy: 0.8453 - val_loss: 0.3054 - val_accuracy: 0.8569\n",
            "Epoch 87/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8461 - val_loss: 0.3056 - val_accuracy: 0.8570\n",
            "Epoch 88/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3311 - accuracy: 0.8444 - val_loss: 0.3056 - val_accuracy: 0.8572\n",
            "Epoch 89/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3311 - accuracy: 0.8451 - val_loss: 0.3054 - val_accuracy: 0.8568\n",
            "Epoch 90/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3305 - accuracy: 0.8453 - val_loss: 0.3056 - val_accuracy: 0.8571\n",
            "Epoch 91/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3303 - accuracy: 0.8444 - val_loss: 0.3057 - val_accuracy: 0.8569\n",
            "Epoch 92/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.8463 - val_loss: 0.3061 - val_accuracy: 0.8571\n",
            "Epoch 93/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3313 - accuracy: 0.8443 - val_loss: 0.3061 - val_accuracy: 0.8565\n",
            "Epoch 94/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3298 - accuracy: 0.8448 - val_loss: 0.3059 - val_accuracy: 0.8568\n",
            "Epoch 95/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8457 - val_loss: 0.3059 - val_accuracy: 0.8566\n",
            "Epoch 96/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8450 - val_loss: 0.3057 - val_accuracy: 0.8573\n",
            "Epoch 97/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3300 - accuracy: 0.8451 - val_loss: 0.3056 - val_accuracy: 0.8570\n",
            "Epoch 98/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8449 - val_loss: 0.3055 - val_accuracy: 0.8575\n",
            "Epoch 99/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3290 - accuracy: 0.8457 - val_loss: 0.3054 - val_accuracy: 0.8569\n",
            "Epoch 100/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8468 - val_loss: 0.3054 - val_accuracy: 0.8571\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8571\n",
            "정확률= 0.8571274280548096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. DNN - 1 / 16 / O / leaky_relu"
      ],
      "metadata": {
        "id": "udIcdD5o8yR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp12 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp12.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp12.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp12.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8596"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PTa0AZf-nbC",
        "outputId": "8664de54-bf3c-4c65-e70a-a4b9cf4e4c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "290/290 [==============================] - 2s 3ms/step - loss: 0.4153 - accuracy: 0.8090 - val_loss: 0.3193 - val_accuracy: 0.8528\n",
            "Epoch 2/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3466 - accuracy: 0.8418 - val_loss: 0.3103 - val_accuracy: 0.8539\n",
            "Epoch 3/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.8460 - val_loss: 0.3079 - val_accuracy: 0.8560\n",
            "Epoch 4/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3307 - accuracy: 0.8489 - val_loss: 0.3066 - val_accuracy: 0.8560\n",
            "Epoch 5/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3256 - accuracy: 0.8491 - val_loss: 0.3053 - val_accuracy: 0.8569\n",
            "Epoch 6/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3257 - accuracy: 0.8498 - val_loss: 0.3047 - val_accuracy: 0.8567\n",
            "Epoch 7/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3229 - accuracy: 0.8506 - val_loss: 0.3037 - val_accuracy: 0.8568\n",
            "Epoch 8/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3230 - accuracy: 0.8500 - val_loss: 0.3033 - val_accuracy: 0.8571\n",
            "Epoch 9/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3194 - accuracy: 0.8507 - val_loss: 0.3029 - val_accuracy: 0.8580\n",
            "Epoch 10/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8513 - val_loss: 0.3022 - val_accuracy: 0.8581\n",
            "Epoch 11/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3180 - accuracy: 0.8506 - val_loss: 0.3019 - val_accuracy: 0.8580\n",
            "Epoch 12/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3182 - accuracy: 0.8506 - val_loss: 0.3013 - val_accuracy: 0.8582\n",
            "Epoch 13/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.8518 - val_loss: 0.3011 - val_accuracy: 0.8585\n",
            "Epoch 14/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3168 - accuracy: 0.8507 - val_loss: 0.3008 - val_accuracy: 0.8585\n",
            "Epoch 15/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3187 - accuracy: 0.8499 - val_loss: 0.3007 - val_accuracy: 0.8570\n",
            "Epoch 16/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3175 - accuracy: 0.8506 - val_loss: 0.3002 - val_accuracy: 0.8577\n",
            "Epoch 17/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3170 - accuracy: 0.8487 - val_loss: 0.3000 - val_accuracy: 0.8584\n",
            "Epoch 18/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3169 - accuracy: 0.8516 - val_loss: 0.3000 - val_accuracy: 0.8581\n",
            "Epoch 19/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3169 - accuracy: 0.8504 - val_loss: 0.2996 - val_accuracy: 0.8581\n",
            "Epoch 20/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3178 - accuracy: 0.8522 - val_loss: 0.2996 - val_accuracy: 0.8584\n",
            "Epoch 21/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3158 - accuracy: 0.8513 - val_loss: 0.2993 - val_accuracy: 0.8584\n",
            "Epoch 22/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3164 - accuracy: 0.8507 - val_loss: 0.2994 - val_accuracy: 0.8589\n",
            "Epoch 23/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3170 - accuracy: 0.8508 - val_loss: 0.2994 - val_accuracy: 0.8577\n",
            "Epoch 24/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3142 - accuracy: 0.8522 - val_loss: 0.2989 - val_accuracy: 0.8591\n",
            "Epoch 25/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3162 - accuracy: 0.8511 - val_loss: 0.2989 - val_accuracy: 0.8594\n",
            "Epoch 26/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3169 - accuracy: 0.8503 - val_loss: 0.2988 - val_accuracy: 0.8589\n",
            "Epoch 27/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3165 - accuracy: 0.8503 - val_loss: 0.2986 - val_accuracy: 0.8595\n",
            "Epoch 28/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3162 - accuracy: 0.8507 - val_loss: 0.2986 - val_accuracy: 0.8590\n",
            "Epoch 29/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3148 - accuracy: 0.8514 - val_loss: 0.2984 - val_accuracy: 0.8590\n",
            "Epoch 30/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3149 - accuracy: 0.8512 - val_loss: 0.2984 - val_accuracy: 0.8595\n",
            "Epoch 31/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.8503 - val_loss: 0.2982 - val_accuracy: 0.8595\n",
            "Epoch 32/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3158 - accuracy: 0.8512 - val_loss: 0.2983 - val_accuracy: 0.8590\n",
            "Epoch 33/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.8497 - val_loss: 0.2985 - val_accuracy: 0.8598\n",
            "Epoch 34/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3152 - accuracy: 0.8521 - val_loss: 0.2980 - val_accuracy: 0.8598\n",
            "Epoch 35/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3151 - accuracy: 0.8514 - val_loss: 0.2982 - val_accuracy: 0.8593\n",
            "Epoch 36/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3153 - accuracy: 0.8520 - val_loss: 0.2980 - val_accuracy: 0.8592\n",
            "Epoch 37/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3160 - accuracy: 0.8513 - val_loss: 0.2979 - val_accuracy: 0.8600\n",
            "Epoch 38/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3164 - accuracy: 0.8513 - val_loss: 0.2980 - val_accuracy: 0.8587\n",
            "Epoch 39/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3156 - accuracy: 0.8515 - val_loss: 0.2982 - val_accuracy: 0.8604\n",
            "Epoch 40/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3155 - accuracy: 0.8530 - val_loss: 0.2982 - val_accuracy: 0.8591\n",
            "Epoch 41/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3164 - accuracy: 0.8519 - val_loss: 0.2981 - val_accuracy: 0.8601\n",
            "Epoch 42/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3152 - accuracy: 0.8519 - val_loss: 0.2980 - val_accuracy: 0.8603\n",
            "Epoch 43/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3161 - accuracy: 0.8511 - val_loss: 0.2982 - val_accuracy: 0.8599\n",
            "Epoch 44/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3143 - accuracy: 0.8514 - val_loss: 0.2981 - val_accuracy: 0.8598\n",
            "Epoch 45/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3144 - accuracy: 0.8518 - val_loss: 0.2980 - val_accuracy: 0.8595\n",
            "Epoch 46/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3161 - accuracy: 0.8508 - val_loss: 0.2981 - val_accuracy: 0.8606\n",
            "Epoch 47/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3145 - accuracy: 0.8520 - val_loss: 0.2980 - val_accuracy: 0.8604\n",
            "Epoch 48/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3160 - accuracy: 0.8509 - val_loss: 0.2979 - val_accuracy: 0.8605\n",
            "Epoch 49/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3144 - accuracy: 0.8517 - val_loss: 0.2978 - val_accuracy: 0.8597\n",
            "Epoch 50/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3149 - accuracy: 0.8505 - val_loss: 0.2978 - val_accuracy: 0.8587\n",
            "Epoch 51/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3178 - accuracy: 0.8501 - val_loss: 0.2980 - val_accuracy: 0.8589\n",
            "Epoch 52/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3168 - accuracy: 0.8515 - val_loss: 0.2979 - val_accuracy: 0.8600\n",
            "Epoch 53/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3154 - accuracy: 0.8509 - val_loss: 0.2979 - val_accuracy: 0.8601\n",
            "Epoch 54/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3150 - accuracy: 0.8532 - val_loss: 0.2975 - val_accuracy: 0.8600\n",
            "Epoch 55/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3144 - accuracy: 0.8523 - val_loss: 0.2976 - val_accuracy: 0.8596\n",
            "Epoch 56/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3152 - accuracy: 0.8515 - val_loss: 0.2974 - val_accuracy: 0.8608\n",
            "Epoch 57/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.8520 - val_loss: 0.2976 - val_accuracy: 0.8594\n",
            "Epoch 58/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3148 - accuracy: 0.8530 - val_loss: 0.2974 - val_accuracy: 0.8597\n",
            "Epoch 59/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3154 - accuracy: 0.8520 - val_loss: 0.2975 - val_accuracy: 0.8604\n",
            "Epoch 60/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3152 - accuracy: 0.8505 - val_loss: 0.2976 - val_accuracy: 0.8595\n",
            "Epoch 61/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.8509 - val_loss: 0.2975 - val_accuracy: 0.8599\n",
            "Epoch 62/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3149 - accuracy: 0.8509 - val_loss: 0.2978 - val_accuracy: 0.8600\n",
            "Epoch 63/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3151 - accuracy: 0.8496 - val_loss: 0.2976 - val_accuracy: 0.8600\n",
            "Epoch 64/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3166 - accuracy: 0.8510 - val_loss: 0.2977 - val_accuracy: 0.8592\n",
            "Epoch 65/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3150 - accuracy: 0.8503 - val_loss: 0.2974 - val_accuracy: 0.8605\n",
            "Epoch 66/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3158 - accuracy: 0.8514 - val_loss: 0.2974 - val_accuracy: 0.8598\n",
            "Epoch 67/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3172 - accuracy: 0.8508 - val_loss: 0.2979 - val_accuracy: 0.8589\n",
            "Epoch 68/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3154 - accuracy: 0.8505 - val_loss: 0.2976 - val_accuracy: 0.8597\n",
            "Epoch 69/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3157 - accuracy: 0.8501 - val_loss: 0.2975 - val_accuracy: 0.8595\n",
            "Epoch 70/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3143 - accuracy: 0.8522 - val_loss: 0.2975 - val_accuracy: 0.8594\n",
            "Epoch 71/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3151 - accuracy: 0.8506 - val_loss: 0.2976 - val_accuracy: 0.8598\n",
            "Epoch 72/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3157 - accuracy: 0.8509 - val_loss: 0.2975 - val_accuracy: 0.8605\n",
            "Epoch 73/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3166 - accuracy: 0.8506 - val_loss: 0.2978 - val_accuracy: 0.8601\n",
            "Epoch 74/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3147 - accuracy: 0.8517 - val_loss: 0.2980 - val_accuracy: 0.8595\n",
            "Epoch 75/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3148 - accuracy: 0.8527 - val_loss: 0.2977 - val_accuracy: 0.8592\n",
            "Epoch 76/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3157 - accuracy: 0.8515 - val_loss: 0.2973 - val_accuracy: 0.8598\n",
            "Epoch 77/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3155 - accuracy: 0.8519 - val_loss: 0.2973 - val_accuracy: 0.8596\n",
            "Epoch 78/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.8521 - val_loss: 0.2975 - val_accuracy: 0.8604\n",
            "Epoch 79/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3157 - accuracy: 0.8512 - val_loss: 0.2977 - val_accuracy: 0.8593\n",
            "Epoch 80/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3140 - accuracy: 0.8520 - val_loss: 0.2974 - val_accuracy: 0.8603\n",
            "Epoch 81/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3153 - accuracy: 0.8513 - val_loss: 0.2977 - val_accuracy: 0.8594\n",
            "Epoch 82/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3151 - accuracy: 0.8512 - val_loss: 0.2973 - val_accuracy: 0.8595\n",
            "Epoch 83/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3153 - accuracy: 0.8525 - val_loss: 0.2975 - val_accuracy: 0.8594\n",
            "Epoch 84/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3153 - accuracy: 0.8525 - val_loss: 0.2975 - val_accuracy: 0.8598\n",
            "Epoch 85/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.8528 - val_loss: 0.2974 - val_accuracy: 0.8595\n",
            "Epoch 86/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3151 - accuracy: 0.8519 - val_loss: 0.2972 - val_accuracy: 0.8598\n",
            "Epoch 87/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3162 - accuracy: 0.8503 - val_loss: 0.2974 - val_accuracy: 0.8593\n",
            "Epoch 88/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.8529 - val_loss: 0.2973 - val_accuracy: 0.8603\n",
            "Epoch 89/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3154 - accuracy: 0.8509 - val_loss: 0.2971 - val_accuracy: 0.8594\n",
            "Epoch 90/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.8522 - val_loss: 0.2971 - val_accuracy: 0.8600\n",
            "Epoch 91/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3143 - accuracy: 0.8514 - val_loss: 0.2970 - val_accuracy: 0.8597\n",
            "Epoch 92/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3149 - accuracy: 0.8503 - val_loss: 0.2971 - val_accuracy: 0.8601\n",
            "Epoch 93/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.8509 - val_loss: 0.2971 - val_accuracy: 0.8603\n",
            "Epoch 94/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3145 - accuracy: 0.8508 - val_loss: 0.2971 - val_accuracy: 0.8594\n",
            "Epoch 95/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3166 - accuracy: 0.8506 - val_loss: 0.2973 - val_accuracy: 0.8593\n",
            "Epoch 96/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3157 - accuracy: 0.8511 - val_loss: 0.2974 - val_accuracy: 0.8596\n",
            "Epoch 97/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3155 - accuracy: 0.8512 - val_loss: 0.2972 - val_accuracy: 0.8601\n",
            "Epoch 98/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3159 - accuracy: 0.8514 - val_loss: 0.2972 - val_accuracy: 0.8603\n",
            "Epoch 99/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3163 - accuracy: 0.8495 - val_loss: 0.2972 - val_accuracy: 0.8599\n",
            "Epoch 100/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.8507 - val_loss: 0.2972 - val_accuracy: 0.8596\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2972 - accuracy: 0.8596\n",
            "정확률= 0.8596075177192688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. DNN - 2 / 8 / O / leaky_relu"
      ],
      "metadata": {
        "id": "PEX_ELKZ83cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp13 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp13.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp13.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp13.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8567"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB_VRtPh-s-V",
        "outputId": "2ea8cc08-43e5-47e2-be6f-f2cd37eafa5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "290/290 [==============================] - 2s 3ms/step - loss: 0.6574 - accuracy: 0.6251 - val_loss: 0.4371 - val_accuracy: 0.8128\n",
            "Epoch 2/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.4565 - accuracy: 0.7833 - val_loss: 0.3329 - val_accuracy: 0.8543\n",
            "Epoch 3/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3938 - accuracy: 0.8182 - val_loss: 0.3147 - val_accuracy: 0.8563\n",
            "Epoch 4/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3760 - accuracy: 0.8306 - val_loss: 0.3113 - val_accuracy: 0.8577\n",
            "Epoch 5/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3676 - accuracy: 0.8341 - val_loss: 0.3097 - val_accuracy: 0.8577\n",
            "Epoch 6/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3633 - accuracy: 0.8352 - val_loss: 0.3087 - val_accuracy: 0.8575\n",
            "Epoch 7/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3602 - accuracy: 0.8382 - val_loss: 0.3084 - val_accuracy: 0.8580\n",
            "Epoch 8/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3630 - accuracy: 0.8391 - val_loss: 0.3082 - val_accuracy: 0.8581\n",
            "Epoch 9/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3545 - accuracy: 0.8405 - val_loss: 0.3080 - val_accuracy: 0.8564\n",
            "Epoch 10/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3578 - accuracy: 0.8395 - val_loss: 0.3081 - val_accuracy: 0.8557\n",
            "Epoch 11/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3543 - accuracy: 0.8395 - val_loss: 0.3075 - val_accuracy: 0.8567\n",
            "Epoch 12/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3552 - accuracy: 0.8425 - val_loss: 0.3073 - val_accuracy: 0.8564\n",
            "Epoch 13/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3520 - accuracy: 0.8423 - val_loss: 0.3076 - val_accuracy: 0.8559\n",
            "Epoch 14/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3506 - accuracy: 0.8430 - val_loss: 0.3072 - val_accuracy: 0.8555\n",
            "Epoch 15/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3528 - accuracy: 0.8416 - val_loss: 0.3072 - val_accuracy: 0.8553\n",
            "Epoch 16/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8434 - val_loss: 0.3072 - val_accuracy: 0.8562\n",
            "Epoch 17/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3489 - accuracy: 0.8413 - val_loss: 0.3068 - val_accuracy: 0.8578\n",
            "Epoch 18/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.8426 - val_loss: 0.3066 - val_accuracy: 0.8579\n",
            "Epoch 19/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3510 - accuracy: 0.8418 - val_loss: 0.3065 - val_accuracy: 0.8565\n",
            "Epoch 20/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3509 - accuracy: 0.8420 - val_loss: 0.3070 - val_accuracy: 0.8560\n",
            "Epoch 21/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8421 - val_loss: 0.3073 - val_accuracy: 0.8567\n",
            "Epoch 22/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3506 - accuracy: 0.8410 - val_loss: 0.3066 - val_accuracy: 0.8562\n",
            "Epoch 23/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3485 - accuracy: 0.8423 - val_loss: 0.3070 - val_accuracy: 0.8567\n",
            "Epoch 24/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3498 - accuracy: 0.8398 - val_loss: 0.3065 - val_accuracy: 0.8560\n",
            "Epoch 25/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3478 - accuracy: 0.8441 - val_loss: 0.3065 - val_accuracy: 0.8564\n",
            "Epoch 26/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3486 - accuracy: 0.8417 - val_loss: 0.3061 - val_accuracy: 0.8571\n",
            "Epoch 27/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3510 - accuracy: 0.8406 - val_loss: 0.3062 - val_accuracy: 0.8570\n",
            "Epoch 28/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3478 - accuracy: 0.8409 - val_loss: 0.3060 - val_accuracy: 0.8568\n",
            "Epoch 29/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3481 - accuracy: 0.8425 - val_loss: 0.3057 - val_accuracy: 0.8575\n",
            "Epoch 30/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3488 - accuracy: 0.8418 - val_loss: 0.3059 - val_accuracy: 0.8572\n",
            "Epoch 31/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3476 - accuracy: 0.8424 - val_loss: 0.3058 - val_accuracy: 0.8571\n",
            "Epoch 32/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3485 - accuracy: 0.8419 - val_loss: 0.3056 - val_accuracy: 0.8559\n",
            "Epoch 33/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.8418 - val_loss: 0.3054 - val_accuracy: 0.8558\n",
            "Epoch 34/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3513 - accuracy: 0.8400 - val_loss: 0.3063 - val_accuracy: 0.8555\n",
            "Epoch 35/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3495 - accuracy: 0.8410 - val_loss: 0.3060 - val_accuracy: 0.8564\n",
            "Epoch 36/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3500 - accuracy: 0.8393 - val_loss: 0.3061 - val_accuracy: 0.8564\n",
            "Epoch 37/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3480 - accuracy: 0.8404 - val_loss: 0.3057 - val_accuracy: 0.8555\n",
            "Epoch 38/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8427 - val_loss: 0.3059 - val_accuracy: 0.8567\n",
            "Epoch 39/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3473 - accuracy: 0.8415 - val_loss: 0.3053 - val_accuracy: 0.8563\n",
            "Epoch 40/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3495 - accuracy: 0.8420 - val_loss: 0.3054 - val_accuracy: 0.8565\n",
            "Epoch 41/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3465 - accuracy: 0.8422 - val_loss: 0.3052 - val_accuracy: 0.8564\n",
            "Epoch 42/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3482 - accuracy: 0.8427 - val_loss: 0.3051 - val_accuracy: 0.8564\n",
            "Epoch 43/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.8419 - val_loss: 0.3051 - val_accuracy: 0.8575\n",
            "Epoch 44/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8415 - val_loss: 0.3048 - val_accuracy: 0.8559\n",
            "Epoch 45/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3496 - accuracy: 0.8404 - val_loss: 0.3046 - val_accuracy: 0.8575\n",
            "Epoch 46/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3483 - accuracy: 0.8426 - val_loss: 0.3043 - val_accuracy: 0.8565\n",
            "Epoch 47/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3469 - accuracy: 0.8418 - val_loss: 0.3044 - val_accuracy: 0.8579\n",
            "Epoch 48/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3487 - accuracy: 0.8405 - val_loss: 0.3037 - val_accuracy: 0.8568\n",
            "Epoch 49/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8418 - val_loss: 0.3040 - val_accuracy: 0.8563\n",
            "Epoch 50/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3471 - accuracy: 0.8424 - val_loss: 0.3038 - val_accuracy: 0.8565\n",
            "Epoch 51/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3507 - accuracy: 0.8403 - val_loss: 0.3043 - val_accuracy: 0.8568\n",
            "Epoch 52/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.8410 - val_loss: 0.3039 - val_accuracy: 0.8569\n",
            "Epoch 53/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.8410 - val_loss: 0.3042 - val_accuracy: 0.8567\n",
            "Epoch 54/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3475 - accuracy: 0.8413 - val_loss: 0.3040 - val_accuracy: 0.8562\n",
            "Epoch 55/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3483 - accuracy: 0.8410 - val_loss: 0.3043 - val_accuracy: 0.8566\n",
            "Epoch 56/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8417 - val_loss: 0.3039 - val_accuracy: 0.8562\n",
            "Epoch 57/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3475 - accuracy: 0.8419 - val_loss: 0.3037 - val_accuracy: 0.8567\n",
            "Epoch 58/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3490 - accuracy: 0.8416 - val_loss: 0.3047 - val_accuracy: 0.8566\n",
            "Epoch 59/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3469 - accuracy: 0.8400 - val_loss: 0.3033 - val_accuracy: 0.8558\n",
            "Epoch 60/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3454 - accuracy: 0.8401 - val_loss: 0.3035 - val_accuracy: 0.8567\n",
            "Epoch 61/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8410 - val_loss: 0.3032 - val_accuracy: 0.8567\n",
            "Epoch 62/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3453 - accuracy: 0.8433 - val_loss: 0.3033 - val_accuracy: 0.8563\n",
            "Epoch 63/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3465 - accuracy: 0.8413 - val_loss: 0.3038 - val_accuracy: 0.8565\n",
            "Epoch 64/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3472 - accuracy: 0.8413 - val_loss: 0.3034 - val_accuracy: 0.8559\n",
            "Epoch 65/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3497 - accuracy: 0.8413 - val_loss: 0.3036 - val_accuracy: 0.8560\n",
            "Epoch 66/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3436 - accuracy: 0.8419 - val_loss: 0.3028 - val_accuracy: 0.8579\n",
            "Epoch 67/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8399 - val_loss: 0.3034 - val_accuracy: 0.8562\n",
            "Epoch 68/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3459 - accuracy: 0.8403 - val_loss: 0.3029 - val_accuracy: 0.8567\n",
            "Epoch 69/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3481 - accuracy: 0.8391 - val_loss: 0.3030 - val_accuracy: 0.8567\n",
            "Epoch 70/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3453 - accuracy: 0.8403 - val_loss: 0.3027 - val_accuracy: 0.8578\n",
            "Epoch 71/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3476 - accuracy: 0.8418 - val_loss: 0.3033 - val_accuracy: 0.8570\n",
            "Epoch 72/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3450 - accuracy: 0.8404 - val_loss: 0.3031 - val_accuracy: 0.8571\n",
            "Epoch 73/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3441 - accuracy: 0.8406 - val_loss: 0.3028 - val_accuracy: 0.8558\n",
            "Epoch 74/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3484 - accuracy: 0.8415 - val_loss: 0.3030 - val_accuracy: 0.8564\n",
            "Epoch 75/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8405 - val_loss: 0.3035 - val_accuracy: 0.8557\n",
            "Epoch 76/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3502 - accuracy: 0.8391 - val_loss: 0.3032 - val_accuracy: 0.8566\n",
            "Epoch 77/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3459 - accuracy: 0.8399 - val_loss: 0.3027 - val_accuracy: 0.8564\n",
            "Epoch 78/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3453 - accuracy: 0.8416 - val_loss: 0.3029 - val_accuracy: 0.8563\n",
            "Epoch 79/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3449 - accuracy: 0.8412 - val_loss: 0.3034 - val_accuracy: 0.8562\n",
            "Epoch 80/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3484 - accuracy: 0.8401 - val_loss: 0.3026 - val_accuracy: 0.8564\n",
            "Epoch 81/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3466 - accuracy: 0.8415 - val_loss: 0.3030 - val_accuracy: 0.8568\n",
            "Epoch 82/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3487 - accuracy: 0.8385 - val_loss: 0.3030 - val_accuracy: 0.8567\n",
            "Epoch 83/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3468 - accuracy: 0.8384 - val_loss: 0.3031 - val_accuracy: 0.8556\n",
            "Epoch 84/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8405 - val_loss: 0.3028 - val_accuracy: 0.8571\n",
            "Epoch 85/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3462 - accuracy: 0.8427 - val_loss: 0.3029 - val_accuracy: 0.8570\n",
            "Epoch 86/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8413 - val_loss: 0.3029 - val_accuracy: 0.8567\n",
            "Epoch 87/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8410 - val_loss: 0.3024 - val_accuracy: 0.8562\n",
            "Epoch 88/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3496 - accuracy: 0.8402 - val_loss: 0.3031 - val_accuracy: 0.8566\n",
            "Epoch 89/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3472 - accuracy: 0.8393 - val_loss: 0.3033 - val_accuracy: 0.8560\n",
            "Epoch 90/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3450 - accuracy: 0.8404 - val_loss: 0.3028 - val_accuracy: 0.8565\n",
            "Epoch 91/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8413 - val_loss: 0.3028 - val_accuracy: 0.8566\n",
            "Epoch 92/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3458 - accuracy: 0.8435 - val_loss: 0.3033 - val_accuracy: 0.8568\n",
            "Epoch 93/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.8408 - val_loss: 0.3034 - val_accuracy: 0.8554\n",
            "Epoch 94/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3445 - accuracy: 0.8403 - val_loss: 0.3028 - val_accuracy: 0.8563\n",
            "Epoch 95/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8404 - val_loss: 0.3034 - val_accuracy: 0.8569\n",
            "Epoch 96/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3476 - accuracy: 0.8398 - val_loss: 0.3039 - val_accuracy: 0.8568\n",
            "Epoch 97/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3480 - accuracy: 0.8395 - val_loss: 0.3028 - val_accuracy: 0.8573\n",
            "Epoch 98/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3476 - accuracy: 0.8396 - val_loss: 0.3027 - val_accuracy: 0.8566\n",
            "Epoch 99/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3488 - accuracy: 0.8398 - val_loss: 0.3022 - val_accuracy: 0.8570\n",
            "Epoch 100/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3458 - accuracy: 0.8402 - val_loss: 0.3028 - val_accuracy: 0.8567\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3028 - accuracy: 0.8567\n",
            "정확률= 0.8566961288452148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. DNN - 2 / 16 / O / leaky_relu"
      ],
      "metadata": {
        "id": "PADwEn4u86pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp14 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp14.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp14.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp14.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8594"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP2aMSMS-wmT",
        "outputId": "3f1a8a48-dd8a-4cf7-c0be-75133021905b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "290/290 [==============================] - 2s 3ms/step - loss: 0.4821 - accuracy: 0.7676 - val_loss: 0.3225 - val_accuracy: 0.8529\n",
            "Epoch 2/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3685 - accuracy: 0.8364 - val_loss: 0.3135 - val_accuracy: 0.8554\n",
            "Epoch 3/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3493 - accuracy: 0.8426 - val_loss: 0.3097 - val_accuracy: 0.8577\n",
            "Epoch 4/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3429 - accuracy: 0.8445 - val_loss: 0.3089 - val_accuracy: 0.8567\n",
            "Epoch 5/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3390 - accuracy: 0.8460 - val_loss: 0.3076 - val_accuracy: 0.8560\n",
            "Epoch 6/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3375 - accuracy: 0.8461 - val_loss: 0.3062 - val_accuracy: 0.8580\n",
            "Epoch 7/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3344 - accuracy: 0.8469 - val_loss: 0.3054 - val_accuracy: 0.8566\n",
            "Epoch 8/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3345 - accuracy: 0.8469 - val_loss: 0.3060 - val_accuracy: 0.8559\n",
            "Epoch 9/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3329 - accuracy: 0.8467 - val_loss: 0.3044 - val_accuracy: 0.8580\n",
            "Epoch 10/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3313 - accuracy: 0.8485 - val_loss: 0.3043 - val_accuracy: 0.8558\n",
            "Epoch 11/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8475 - val_loss: 0.3035 - val_accuracy: 0.8564\n",
            "Epoch 12/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8486 - val_loss: 0.3026 - val_accuracy: 0.8577\n",
            "Epoch 13/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3289 - accuracy: 0.8495 - val_loss: 0.3020 - val_accuracy: 0.8570\n",
            "Epoch 14/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8488 - val_loss: 0.3012 - val_accuracy: 0.8595\n",
            "Epoch 15/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.8479 - val_loss: 0.3011 - val_accuracy: 0.8583\n",
            "Epoch 16/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8488 - val_loss: 0.3006 - val_accuracy: 0.8580\n",
            "Epoch 17/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3282 - accuracy: 0.8490 - val_loss: 0.3005 - val_accuracy: 0.8583\n",
            "Epoch 18/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3274 - accuracy: 0.8487 - val_loss: 0.3009 - val_accuracy: 0.8576\n",
            "Epoch 19/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8492 - val_loss: 0.3000 - val_accuracy: 0.8576\n",
            "Epoch 20/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8493 - val_loss: 0.2998 - val_accuracy: 0.8586\n",
            "Epoch 21/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3251 - accuracy: 0.8482 - val_loss: 0.2996 - val_accuracy: 0.8569\n",
            "Epoch 22/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3272 - accuracy: 0.8481 - val_loss: 0.2994 - val_accuracy: 0.8568\n",
            "Epoch 23/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3263 - accuracy: 0.8498 - val_loss: 0.2990 - val_accuracy: 0.8578\n",
            "Epoch 24/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3268 - accuracy: 0.8487 - val_loss: 0.2992 - val_accuracy: 0.8567\n",
            "Epoch 25/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8484 - val_loss: 0.2986 - val_accuracy: 0.8568\n",
            "Epoch 26/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8491 - val_loss: 0.2983 - val_accuracy: 0.8569\n",
            "Epoch 27/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3248 - accuracy: 0.8497 - val_loss: 0.2985 - val_accuracy: 0.8565\n",
            "Epoch 28/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3221 - accuracy: 0.8493 - val_loss: 0.2984 - val_accuracy: 0.8560\n",
            "Epoch 29/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8492 - val_loss: 0.2976 - val_accuracy: 0.8579\n",
            "Epoch 30/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.8482 - val_loss: 0.2995 - val_accuracy: 0.8572\n",
            "Epoch 31/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8487 - val_loss: 0.2984 - val_accuracy: 0.8565\n",
            "Epoch 32/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8503 - val_loss: 0.2984 - val_accuracy: 0.8572\n",
            "Epoch 33/100\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8489 - val_loss: 0.2977 - val_accuracy: 0.8586\n",
            "Epoch 34/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8495 - val_loss: 0.2983 - val_accuracy: 0.8565\n",
            "Epoch 35/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.8493 - val_loss: 0.2965 - val_accuracy: 0.8585\n",
            "Epoch 36/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3227 - accuracy: 0.8495 - val_loss: 0.2968 - val_accuracy: 0.8576\n",
            "Epoch 37/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3208 - accuracy: 0.8486 - val_loss: 0.2965 - val_accuracy: 0.8582\n",
            "Epoch 38/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3234 - accuracy: 0.8495 - val_loss: 0.2969 - val_accuracy: 0.8570\n",
            "Epoch 39/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3218 - accuracy: 0.8511 - val_loss: 0.2959 - val_accuracy: 0.8585\n",
            "Epoch 40/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3243 - accuracy: 0.8486 - val_loss: 0.2959 - val_accuracy: 0.8592\n",
            "Epoch 41/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3225 - accuracy: 0.8492 - val_loss: 0.2959 - val_accuracy: 0.8582\n",
            "Epoch 42/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.8495 - val_loss: 0.2958 - val_accuracy: 0.8585\n",
            "Epoch 43/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8485 - val_loss: 0.2955 - val_accuracy: 0.8585\n",
            "Epoch 44/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3223 - accuracy: 0.8484 - val_loss: 0.2964 - val_accuracy: 0.8576\n",
            "Epoch 45/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3228 - accuracy: 0.8498 - val_loss: 0.2954 - val_accuracy: 0.8581\n",
            "Epoch 46/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3226 - accuracy: 0.8496 - val_loss: 0.2956 - val_accuracy: 0.8571\n",
            "Epoch 47/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3211 - accuracy: 0.8497 - val_loss: 0.2951 - val_accuracy: 0.8576\n",
            "Epoch 48/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3207 - accuracy: 0.8486 - val_loss: 0.2946 - val_accuracy: 0.8581\n",
            "Epoch 49/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3217 - accuracy: 0.8495 - val_loss: 0.2950 - val_accuracy: 0.8575\n",
            "Epoch 50/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3216 - accuracy: 0.8496 - val_loss: 0.2955 - val_accuracy: 0.8570\n",
            "Epoch 51/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3230 - accuracy: 0.8492 - val_loss: 0.2953 - val_accuracy: 0.8580\n",
            "Epoch 52/100\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3203 - accuracy: 0.8482 - val_loss: 0.2944 - val_accuracy: 0.8579\n",
            "Epoch 53/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3205 - accuracy: 0.8498 - val_loss: 0.2940 - val_accuracy: 0.8575\n",
            "Epoch 54/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3219 - accuracy: 0.8489 - val_loss: 0.2938 - val_accuracy: 0.8580\n",
            "Epoch 55/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3222 - accuracy: 0.8483 - val_loss: 0.2940 - val_accuracy: 0.8571\n",
            "Epoch 56/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3211 - accuracy: 0.8481 - val_loss: 0.2940 - val_accuracy: 0.8571\n",
            "Epoch 57/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3228 - accuracy: 0.8477 - val_loss: 0.2935 - val_accuracy: 0.8592\n",
            "Epoch 58/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3213 - accuracy: 0.8474 - val_loss: 0.2936 - val_accuracy: 0.8589\n",
            "Epoch 59/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3213 - accuracy: 0.8492 - val_loss: 0.2937 - val_accuracy: 0.8586\n",
            "Epoch 60/100\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3219 - accuracy: 0.8499 - val_loss: 0.2938 - val_accuracy: 0.8581\n",
            "Epoch 61/100\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3213 - accuracy: 0.8502 - val_loss: 0.2931 - val_accuracy: 0.8581\n",
            "Epoch 62/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3212 - accuracy: 0.8479 - val_loss: 0.2939 - val_accuracy: 0.8576\n",
            "Epoch 63/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3219 - accuracy: 0.8476 - val_loss: 0.2936 - val_accuracy: 0.8583\n",
            "Epoch 64/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3215 - accuracy: 0.8500 - val_loss: 0.2939 - val_accuracy: 0.8584\n",
            "Epoch 65/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3212 - accuracy: 0.8478 - val_loss: 0.2930 - val_accuracy: 0.8599\n",
            "Epoch 66/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3209 - accuracy: 0.8498 - val_loss: 0.2942 - val_accuracy: 0.8577\n",
            "Epoch 67/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3201 - accuracy: 0.8506 - val_loss: 0.2928 - val_accuracy: 0.8595\n",
            "Epoch 68/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3217 - accuracy: 0.8494 - val_loss: 0.2937 - val_accuracy: 0.8567\n",
            "Epoch 69/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3201 - accuracy: 0.8501 - val_loss: 0.2925 - val_accuracy: 0.8571\n",
            "Epoch 70/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3211 - accuracy: 0.8468 - val_loss: 0.2929 - val_accuracy: 0.8578\n",
            "Epoch 71/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3215 - accuracy: 0.8483 - val_loss: 0.2933 - val_accuracy: 0.8583\n",
            "Epoch 72/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3211 - accuracy: 0.8482 - val_loss: 0.2927 - val_accuracy: 0.8590\n",
            "Epoch 73/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3216 - accuracy: 0.8486 - val_loss: 0.2929 - val_accuracy: 0.8580\n",
            "Epoch 74/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3197 - accuracy: 0.8485 - val_loss: 0.2926 - val_accuracy: 0.8581\n",
            "Epoch 75/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3224 - accuracy: 0.8475 - val_loss: 0.2926 - val_accuracy: 0.8587\n",
            "Epoch 76/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3229 - accuracy: 0.8485 - val_loss: 0.2921 - val_accuracy: 0.8585\n",
            "Epoch 77/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3210 - accuracy: 0.8502 - val_loss: 0.2922 - val_accuracy: 0.8595\n",
            "Epoch 78/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3202 - accuracy: 0.8499 - val_loss: 0.2925 - val_accuracy: 0.8576\n",
            "Epoch 79/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3202 - accuracy: 0.8499 - val_loss: 0.2917 - val_accuracy: 0.8585\n",
            "Epoch 80/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3195 - accuracy: 0.8503 - val_loss: 0.2921 - val_accuracy: 0.8577\n",
            "Epoch 81/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3212 - accuracy: 0.8494 - val_loss: 0.2926 - val_accuracy: 0.8578\n",
            "Epoch 82/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3210 - accuracy: 0.8484 - val_loss: 0.2927 - val_accuracy: 0.8589\n",
            "Epoch 83/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3192 - accuracy: 0.8486 - val_loss: 0.2919 - val_accuracy: 0.8604\n",
            "Epoch 84/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3206 - accuracy: 0.8494 - val_loss: 0.2918 - val_accuracy: 0.8597\n",
            "Epoch 85/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3207 - accuracy: 0.8503 - val_loss: 0.2926 - val_accuracy: 0.8584\n",
            "Epoch 86/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3211 - accuracy: 0.8481 - val_loss: 0.2921 - val_accuracy: 0.8591\n",
            "Epoch 87/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3214 - accuracy: 0.8482 - val_loss: 0.2929 - val_accuracy: 0.8587\n",
            "Epoch 88/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3219 - accuracy: 0.8492 - val_loss: 0.2918 - val_accuracy: 0.8591\n",
            "Epoch 89/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3203 - accuracy: 0.8489 - val_loss: 0.2910 - val_accuracy: 0.8587\n",
            "Epoch 90/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3197 - accuracy: 0.8498 - val_loss: 0.2917 - val_accuracy: 0.8586\n",
            "Epoch 91/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3190 - accuracy: 0.8498 - val_loss: 0.2917 - val_accuracy: 0.8598\n",
            "Epoch 92/100\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3197 - accuracy: 0.8495 - val_loss: 0.2923 - val_accuracy: 0.8592\n",
            "Epoch 93/100\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3224 - accuracy: 0.8480 - val_loss: 0.2922 - val_accuracy: 0.8595\n",
            "Epoch 94/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3195 - accuracy: 0.8501 - val_loss: 0.2918 - val_accuracy: 0.8594\n",
            "Epoch 95/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3195 - accuracy: 0.8496 - val_loss: 0.2925 - val_accuracy: 0.8593\n",
            "Epoch 96/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3214 - accuracy: 0.8478 - val_loss: 0.2921 - val_accuracy: 0.8591\n",
            "Epoch 97/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3205 - accuracy: 0.8492 - val_loss: 0.2920 - val_accuracy: 0.8594\n",
            "Epoch 98/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3169 - accuracy: 0.8514 - val_loss: 0.2918 - val_accuracy: 0.8585\n",
            "Epoch 99/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3201 - accuracy: 0.8489 - val_loss: 0.2921 - val_accuracy: 0.8584\n",
            "Epoch 100/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3188 - accuracy: 0.8502 - val_loss: 0.2923 - val_accuracy: 0.8594\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.8594\n",
            "정확률= 0.8593918681144714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. DNN - 3 / 8 / O / leaky_relu"
      ],
      "metadata": {
        "id": "Koo5IXa18-ME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp15 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp15.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp15.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp15.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8564"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPNMgk7o-07s",
        "outputId": "8bc56ad3-fd99-4cb6-fd08-18d96c1d92be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "290/290 [==============================] - 2s 4ms/step - loss: 0.6107 - accuracy: 0.6717 - val_loss: 0.3978 - val_accuracy: 0.8330\n",
            "Epoch 2/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4569 - accuracy: 0.7853 - val_loss: 0.3251 - val_accuracy: 0.8527\n",
            "Epoch 3/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4117 - accuracy: 0.8125 - val_loss: 0.3126 - val_accuracy: 0.8543\n",
            "Epoch 4/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3927 - accuracy: 0.8242 - val_loss: 0.3098 - val_accuracy: 0.8551\n",
            "Epoch 5/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3792 - accuracy: 0.8291 - val_loss: 0.3089 - val_accuracy: 0.8554\n",
            "Epoch 6/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8322 - val_loss: 0.3087 - val_accuracy: 0.8560\n",
            "Epoch 7/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3705 - accuracy: 0.8353 - val_loss: 0.3093 - val_accuracy: 0.8548\n",
            "Epoch 8/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3699 - accuracy: 0.8346 - val_loss: 0.3075 - val_accuracy: 0.8557\n",
            "Epoch 9/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3693 - accuracy: 0.8360 - val_loss: 0.3076 - val_accuracy: 0.8558\n",
            "Epoch 10/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3660 - accuracy: 0.8372 - val_loss: 0.3076 - val_accuracy: 0.8556\n",
            "Epoch 11/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3648 - accuracy: 0.8381 - val_loss: 0.3081 - val_accuracy: 0.8551\n",
            "Epoch 12/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3632 - accuracy: 0.8393 - val_loss: 0.3073 - val_accuracy: 0.8557\n",
            "Epoch 13/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3607 - accuracy: 0.8385 - val_loss: 0.3070 - val_accuracy: 0.8555\n",
            "Epoch 14/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3635 - accuracy: 0.8368 - val_loss: 0.3067 - val_accuracy: 0.8560\n",
            "Epoch 15/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3635 - accuracy: 0.8370 - val_loss: 0.3067 - val_accuracy: 0.8560\n",
            "Epoch 16/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3624 - accuracy: 0.8377 - val_loss: 0.3070 - val_accuracy: 0.8558\n",
            "Epoch 17/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3638 - accuracy: 0.8378 - val_loss: 0.3072 - val_accuracy: 0.8553\n",
            "Epoch 18/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3648 - accuracy: 0.8372 - val_loss: 0.3076 - val_accuracy: 0.8554\n",
            "Epoch 19/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3624 - accuracy: 0.8379 - val_loss: 0.3069 - val_accuracy: 0.8558\n",
            "Epoch 20/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3616 - accuracy: 0.8397 - val_loss: 0.3071 - val_accuracy: 0.8557\n",
            "Epoch 21/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3630 - accuracy: 0.8386 - val_loss: 0.3070 - val_accuracy: 0.8555\n",
            "Epoch 22/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3648 - accuracy: 0.8365 - val_loss: 0.3068 - val_accuracy: 0.8558\n",
            "Epoch 23/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3600 - accuracy: 0.8386 - val_loss: 0.3063 - val_accuracy: 0.8565\n",
            "Epoch 24/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3602 - accuracy: 0.8409 - val_loss: 0.3056 - val_accuracy: 0.8566\n",
            "Epoch 25/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3601 - accuracy: 0.8379 - val_loss: 0.3057 - val_accuracy: 0.8569\n",
            "Epoch 26/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3604 - accuracy: 0.8390 - val_loss: 0.3058 - val_accuracy: 0.8575\n",
            "Epoch 27/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3588 - accuracy: 0.8423 - val_loss: 0.3062 - val_accuracy: 0.8567\n",
            "Epoch 28/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3615 - accuracy: 0.8361 - val_loss: 0.3062 - val_accuracy: 0.8565\n",
            "Epoch 29/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3581 - accuracy: 0.8388 - val_loss: 0.3062 - val_accuracy: 0.8571\n",
            "Epoch 30/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3592 - accuracy: 0.8377 - val_loss: 0.3063 - val_accuracy: 0.8558\n",
            "Epoch 31/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3620 - accuracy: 0.8380 - val_loss: 0.3064 - val_accuracy: 0.8571\n",
            "Epoch 32/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3579 - accuracy: 0.8406 - val_loss: 0.3060 - val_accuracy: 0.8573\n",
            "Epoch 33/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3553 - accuracy: 0.8375 - val_loss: 0.3059 - val_accuracy: 0.8570\n",
            "Epoch 34/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3572 - accuracy: 0.8364 - val_loss: 0.3057 - val_accuracy: 0.8580\n",
            "Epoch 35/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3615 - accuracy: 0.8367 - val_loss: 0.3059 - val_accuracy: 0.8562\n",
            "Epoch 36/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3584 - accuracy: 0.8366 - val_loss: 0.3057 - val_accuracy: 0.8571\n",
            "Epoch 37/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3628 - accuracy: 0.8377 - val_loss: 0.3057 - val_accuracy: 0.8568\n",
            "Epoch 38/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3604 - accuracy: 0.8379 - val_loss: 0.3057 - val_accuracy: 0.8568\n",
            "Epoch 39/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3584 - accuracy: 0.8370 - val_loss: 0.3058 - val_accuracy: 0.8568\n",
            "Epoch 40/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3584 - accuracy: 0.8373 - val_loss: 0.3060 - val_accuracy: 0.8567\n",
            "Epoch 41/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3587 - accuracy: 0.8378 - val_loss: 0.3059 - val_accuracy: 0.8580\n",
            "Epoch 42/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3574 - accuracy: 0.8384 - val_loss: 0.3060 - val_accuracy: 0.8572\n",
            "Epoch 43/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3605 - accuracy: 0.8363 - val_loss: 0.3058 - val_accuracy: 0.8567\n",
            "Epoch 44/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3625 - accuracy: 0.8368 - val_loss: 0.3055 - val_accuracy: 0.8566\n",
            "Epoch 45/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3607 - accuracy: 0.8369 - val_loss: 0.3053 - val_accuracy: 0.8571\n",
            "Epoch 46/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3587 - accuracy: 0.8367 - val_loss: 0.3054 - val_accuracy: 0.8566\n",
            "Epoch 47/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3585 - accuracy: 0.8398 - val_loss: 0.3055 - val_accuracy: 0.8568\n",
            "Epoch 48/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3613 - accuracy: 0.8376 - val_loss: 0.3055 - val_accuracy: 0.8573\n",
            "Epoch 49/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3607 - accuracy: 0.8379 - val_loss: 0.3054 - val_accuracy: 0.8572\n",
            "Epoch 50/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3621 - accuracy: 0.8363 - val_loss: 0.3065 - val_accuracy: 0.8554\n",
            "Epoch 51/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3594 - accuracy: 0.8391 - val_loss: 0.3058 - val_accuracy: 0.8563\n",
            "Epoch 52/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3579 - accuracy: 0.8373 - val_loss: 0.3059 - val_accuracy: 0.8569\n",
            "Epoch 53/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3589 - accuracy: 0.8401 - val_loss: 0.3055 - val_accuracy: 0.8572\n",
            "Epoch 54/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3585 - accuracy: 0.8385 - val_loss: 0.3056 - val_accuracy: 0.8571\n",
            "Epoch 55/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3600 - accuracy: 0.8375 - val_loss: 0.3056 - val_accuracy: 0.8570\n",
            "Epoch 56/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3599 - accuracy: 0.8375 - val_loss: 0.3056 - val_accuracy: 0.8573\n",
            "Epoch 57/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3610 - accuracy: 0.8354 - val_loss: 0.3055 - val_accuracy: 0.8572\n",
            "Epoch 58/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3574 - accuracy: 0.8393 - val_loss: 0.3057 - val_accuracy: 0.8567\n",
            "Epoch 59/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3581 - accuracy: 0.8391 - val_loss: 0.3056 - val_accuracy: 0.8580\n",
            "Epoch 60/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3581 - accuracy: 0.8373 - val_loss: 0.3050 - val_accuracy: 0.8578\n",
            "Epoch 61/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3571 - accuracy: 0.8390 - val_loss: 0.3052 - val_accuracy: 0.8573\n",
            "Epoch 62/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3602 - accuracy: 0.8379 - val_loss: 0.3051 - val_accuracy: 0.8573\n",
            "Epoch 63/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3591 - accuracy: 0.8368 - val_loss: 0.3057 - val_accuracy: 0.8579\n",
            "Epoch 64/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3581 - accuracy: 0.8392 - val_loss: 0.3052 - val_accuracy: 0.8584\n",
            "Epoch 65/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3611 - accuracy: 0.8370 - val_loss: 0.3052 - val_accuracy: 0.8577\n",
            "Epoch 66/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3599 - accuracy: 0.8388 - val_loss: 0.3057 - val_accuracy: 0.8557\n",
            "Epoch 67/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3584 - accuracy: 0.8381 - val_loss: 0.3056 - val_accuracy: 0.8565\n",
            "Epoch 68/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3616 - accuracy: 0.8382 - val_loss: 0.3057 - val_accuracy: 0.8560\n",
            "Epoch 69/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3595 - accuracy: 0.8373 - val_loss: 0.3055 - val_accuracy: 0.8576\n",
            "Epoch 70/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3603 - accuracy: 0.8353 - val_loss: 0.3058 - val_accuracy: 0.8571\n",
            "Epoch 71/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3622 - accuracy: 0.8369 - val_loss: 0.3052 - val_accuracy: 0.8576\n",
            "Epoch 72/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3599 - accuracy: 0.8375 - val_loss: 0.3052 - val_accuracy: 0.8573\n",
            "Epoch 73/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3595 - accuracy: 0.8372 - val_loss: 0.3050 - val_accuracy: 0.8582\n",
            "Epoch 74/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3584 - accuracy: 0.8398 - val_loss: 0.3054 - val_accuracy: 0.8563\n",
            "Epoch 75/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3582 - accuracy: 0.8386 - val_loss: 0.3054 - val_accuracy: 0.8563\n",
            "Epoch 76/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3598 - accuracy: 0.8398 - val_loss: 0.3055 - val_accuracy: 0.8572\n",
            "Epoch 77/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3610 - accuracy: 0.8376 - val_loss: 0.3053 - val_accuracy: 0.8577\n",
            "Epoch 78/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3591 - accuracy: 0.8368 - val_loss: 0.3055 - val_accuracy: 0.8571\n",
            "Epoch 79/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3590 - accuracy: 0.8379 - val_loss: 0.3057 - val_accuracy: 0.8581\n",
            "Epoch 80/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3599 - accuracy: 0.8379 - val_loss: 0.3051 - val_accuracy: 0.8572\n",
            "Epoch 81/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3599 - accuracy: 0.8380 - val_loss: 0.3052 - val_accuracy: 0.8571\n",
            "Epoch 82/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3575 - accuracy: 0.8388 - val_loss: 0.3051 - val_accuracy: 0.8579\n",
            "Epoch 83/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3632 - accuracy: 0.8389 - val_loss: 0.3057 - val_accuracy: 0.8571\n",
            "Epoch 84/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3602 - accuracy: 0.8402 - val_loss: 0.3052 - val_accuracy: 0.8582\n",
            "Epoch 85/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3621 - accuracy: 0.8378 - val_loss: 0.3051 - val_accuracy: 0.8572\n",
            "Epoch 86/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3565 - accuracy: 0.8380 - val_loss: 0.3052 - val_accuracy: 0.8581\n",
            "Epoch 87/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3596 - accuracy: 0.8368 - val_loss: 0.3052 - val_accuracy: 0.8571\n",
            "Epoch 88/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3603 - accuracy: 0.8371 - val_loss: 0.3053 - val_accuracy: 0.8569\n",
            "Epoch 89/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3614 - accuracy: 0.8385 - val_loss: 0.3053 - val_accuracy: 0.8573\n",
            "Epoch 90/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3603 - accuracy: 0.8375 - val_loss: 0.3050 - val_accuracy: 0.8576\n",
            "Epoch 91/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3591 - accuracy: 0.8388 - val_loss: 0.3053 - val_accuracy: 0.8579\n",
            "Epoch 92/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3573 - accuracy: 0.8391 - val_loss: 0.3054 - val_accuracy: 0.8577\n",
            "Epoch 93/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3598 - accuracy: 0.8386 - val_loss: 0.3053 - val_accuracy: 0.8575\n",
            "Epoch 94/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3613 - accuracy: 0.8379 - val_loss: 0.3057 - val_accuracy: 0.8573\n",
            "Epoch 95/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3616 - accuracy: 0.8353 - val_loss: 0.3056 - val_accuracy: 0.8569\n",
            "Epoch 96/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3599 - accuracy: 0.8360 - val_loss: 0.3057 - val_accuracy: 0.8568\n",
            "Epoch 97/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3603 - accuracy: 0.8354 - val_loss: 0.3055 - val_accuracy: 0.8570\n",
            "Epoch 98/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3573 - accuracy: 0.8375 - val_loss: 0.3054 - val_accuracy: 0.8580\n",
            "Epoch 99/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3580 - accuracy: 0.8390 - val_loss: 0.3057 - val_accuracy: 0.8577\n",
            "Epoch 100/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3609 - accuracy: 0.8364 - val_loss: 0.3057 - val_accuracy: 0.8564\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8564\n",
            "정확률= 0.8563726544380188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. DNN - 3 / 16 / O / leaky_relu"
      ],
      "metadata": {
        "id": "NZTV3rVe9BSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp16 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp16.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp16.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp16.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8600"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmMFSMH9-6Ms",
        "outputId": "0ba3e78a-3a04-4dc9-fef5-50d6fa90bb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "290/290 [==============================] - 2s 4ms/step - loss: 0.5148 - accuracy: 0.7426 - val_loss: 0.3297 - val_accuracy: 0.8514\n",
            "Epoch 2/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3900 - accuracy: 0.8243 - val_loss: 0.3143 - val_accuracy: 0.8541\n",
            "Epoch 3/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3622 - accuracy: 0.8387 - val_loss: 0.3093 - val_accuracy: 0.8553\n",
            "Epoch 4/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3534 - accuracy: 0.8424 - val_loss: 0.3079 - val_accuracy: 0.8566\n",
            "Epoch 5/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3474 - accuracy: 0.8429 - val_loss: 0.3071 - val_accuracy: 0.8560\n",
            "Epoch 6/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3452 - accuracy: 0.8438 - val_loss: 0.3063 - val_accuracy: 0.8557\n",
            "Epoch 7/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3442 - accuracy: 0.8448 - val_loss: 0.3064 - val_accuracy: 0.8549\n",
            "Epoch 8/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3407 - accuracy: 0.8450 - val_loss: 0.3061 - val_accuracy: 0.8556\n",
            "Epoch 9/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3385 - accuracy: 0.8461 - val_loss: 0.3050 - val_accuracy: 0.8576\n",
            "Epoch 10/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3388 - accuracy: 0.8477 - val_loss: 0.3045 - val_accuracy: 0.8562\n",
            "Epoch 11/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3352 - accuracy: 0.8482 - val_loss: 0.3040 - val_accuracy: 0.8577\n",
            "Epoch 12/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3359 - accuracy: 0.8470 - val_loss: 0.3033 - val_accuracy: 0.8587\n",
            "Epoch 13/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3357 - accuracy: 0.8508 - val_loss: 0.3033 - val_accuracy: 0.8582\n",
            "Epoch 14/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3361 - accuracy: 0.8479 - val_loss: 0.3027 - val_accuracy: 0.8581\n",
            "Epoch 15/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8503 - val_loss: 0.3026 - val_accuracy: 0.8592\n",
            "Epoch 16/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3323 - accuracy: 0.8501 - val_loss: 0.3016 - val_accuracy: 0.8585\n",
            "Epoch 17/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3332 - accuracy: 0.8496 - val_loss: 0.3013 - val_accuracy: 0.8598\n",
            "Epoch 18/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3329 - accuracy: 0.8494 - val_loss: 0.3016 - val_accuracy: 0.8606\n",
            "Epoch 19/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.8477 - val_loss: 0.3014 - val_accuracy: 0.8592\n",
            "Epoch 20/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3321 - accuracy: 0.8502 - val_loss: 0.3005 - val_accuracy: 0.8605\n",
            "Epoch 21/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8494 - val_loss: 0.3011 - val_accuracy: 0.8570\n",
            "Epoch 22/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3325 - accuracy: 0.8484 - val_loss: 0.3007 - val_accuracy: 0.8585\n",
            "Epoch 23/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3321 - accuracy: 0.8496 - val_loss: 0.3005 - val_accuracy: 0.8607\n",
            "Epoch 24/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8492 - val_loss: 0.3001 - val_accuracy: 0.8605\n",
            "Epoch 25/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3318 - accuracy: 0.8505 - val_loss: 0.3000 - val_accuracy: 0.8587\n",
            "Epoch 26/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3312 - accuracy: 0.8499 - val_loss: 0.3001 - val_accuracy: 0.8589\n",
            "Epoch 27/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3304 - accuracy: 0.8494 - val_loss: 0.2991 - val_accuracy: 0.8607\n",
            "Epoch 28/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3301 - accuracy: 0.8483 - val_loss: 0.2991 - val_accuracy: 0.8599\n",
            "Epoch 29/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3278 - accuracy: 0.8492 - val_loss: 0.2990 - val_accuracy: 0.8597\n",
            "Epoch 30/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3279 - accuracy: 0.8508 - val_loss: 0.2987 - val_accuracy: 0.8606\n",
            "Epoch 31/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8471 - val_loss: 0.2990 - val_accuracy: 0.8594\n",
            "Epoch 32/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3279 - accuracy: 0.8496 - val_loss: 0.2985 - val_accuracy: 0.8575\n",
            "Epoch 33/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8488 - val_loss: 0.2985 - val_accuracy: 0.8615\n",
            "Epoch 34/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.8516 - val_loss: 0.2991 - val_accuracy: 0.8590\n",
            "Epoch 35/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3288 - accuracy: 0.8485 - val_loss: 0.2981 - val_accuracy: 0.8592\n",
            "Epoch 36/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.8472 - val_loss: 0.2979 - val_accuracy: 0.8603\n",
            "Epoch 37/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8490 - val_loss: 0.2979 - val_accuracy: 0.8606\n",
            "Epoch 38/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3272 - accuracy: 0.8501 - val_loss: 0.2978 - val_accuracy: 0.8609\n",
            "Epoch 39/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8492 - val_loss: 0.2976 - val_accuracy: 0.8601\n",
            "Epoch 40/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3272 - accuracy: 0.8493 - val_loss: 0.2971 - val_accuracy: 0.8615\n",
            "Epoch 41/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3295 - accuracy: 0.8488 - val_loss: 0.2971 - val_accuracy: 0.8615\n",
            "Epoch 42/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3268 - accuracy: 0.8474 - val_loss: 0.2971 - val_accuracy: 0.8593\n",
            "Epoch 43/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3279 - accuracy: 0.8482 - val_loss: 0.2967 - val_accuracy: 0.8609\n",
            "Epoch 44/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3257 - accuracy: 0.8488 - val_loss: 0.2975 - val_accuracy: 0.8583\n",
            "Epoch 45/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8489 - val_loss: 0.2966 - val_accuracy: 0.8578\n",
            "Epoch 46/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3268 - accuracy: 0.8489 - val_loss: 0.2969 - val_accuracy: 0.8620\n",
            "Epoch 47/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3261 - accuracy: 0.8484 - val_loss: 0.2964 - val_accuracy: 0.8587\n",
            "Epoch 48/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3266 - accuracy: 0.8488 - val_loss: 0.2957 - val_accuracy: 0.8600\n",
            "Epoch 49/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3248 - accuracy: 0.8489 - val_loss: 0.2961 - val_accuracy: 0.8592\n",
            "Epoch 50/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3274 - accuracy: 0.8481 - val_loss: 0.2953 - val_accuracy: 0.8615\n",
            "Epoch 51/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3257 - accuracy: 0.8490 - val_loss: 0.2961 - val_accuracy: 0.8578\n",
            "Epoch 52/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3297 - accuracy: 0.8482 - val_loss: 0.2961 - val_accuracy: 0.8593\n",
            "Epoch 53/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3265 - accuracy: 0.8480 - val_loss: 0.2958 - val_accuracy: 0.8584\n",
            "Epoch 54/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3278 - accuracy: 0.8476 - val_loss: 0.2950 - val_accuracy: 0.8594\n",
            "Epoch 55/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3265 - accuracy: 0.8475 - val_loss: 0.2953 - val_accuracy: 0.8591\n",
            "Epoch 56/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3277 - accuracy: 0.8478 - val_loss: 0.2944 - val_accuracy: 0.8608\n",
            "Epoch 57/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3278 - accuracy: 0.8497 - val_loss: 0.2956 - val_accuracy: 0.8584\n",
            "Epoch 58/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3240 - accuracy: 0.8500 - val_loss: 0.2956 - val_accuracy: 0.8579\n",
            "Epoch 59/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3250 - accuracy: 0.8489 - val_loss: 0.2946 - val_accuracy: 0.8595\n",
            "Epoch 60/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8472 - val_loss: 0.2953 - val_accuracy: 0.8617\n",
            "Epoch 61/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8474 - val_loss: 0.2948 - val_accuracy: 0.8594\n",
            "Epoch 62/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8457 - val_loss: 0.2942 - val_accuracy: 0.8611\n",
            "Epoch 63/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8482 - val_loss: 0.2947 - val_accuracy: 0.8594\n",
            "Epoch 64/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3261 - accuracy: 0.8462 - val_loss: 0.2962 - val_accuracy: 0.8571\n",
            "Epoch 65/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8476 - val_loss: 0.2947 - val_accuracy: 0.8582\n",
            "Epoch 66/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3265 - accuracy: 0.8476 - val_loss: 0.2943 - val_accuracy: 0.8604\n",
            "Epoch 67/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3273 - accuracy: 0.8486 - val_loss: 0.2934 - val_accuracy: 0.8600\n",
            "Epoch 68/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3259 - accuracy: 0.8480 - val_loss: 0.2941 - val_accuracy: 0.8583\n",
            "Epoch 69/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8470 - val_loss: 0.2933 - val_accuracy: 0.8586\n",
            "Epoch 70/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3263 - accuracy: 0.8468 - val_loss: 0.2940 - val_accuracy: 0.8606\n",
            "Epoch 71/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.8479 - val_loss: 0.2938 - val_accuracy: 0.8594\n",
            "Epoch 72/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8478 - val_loss: 0.2946 - val_accuracy: 0.8591\n",
            "Epoch 73/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3280 - accuracy: 0.8460 - val_loss: 0.2956 - val_accuracy: 0.8583\n",
            "Epoch 74/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3273 - accuracy: 0.8465 - val_loss: 0.2934 - val_accuracy: 0.8603\n",
            "Epoch 75/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3250 - accuracy: 0.8487 - val_loss: 0.2929 - val_accuracy: 0.8594\n",
            "Epoch 76/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3265 - accuracy: 0.8475 - val_loss: 0.2940 - val_accuracy: 0.8591\n",
            "Epoch 77/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3251 - accuracy: 0.8474 - val_loss: 0.2937 - val_accuracy: 0.8608\n",
            "Epoch 78/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8485 - val_loss: 0.2937 - val_accuracy: 0.8585\n",
            "Epoch 79/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3229 - accuracy: 0.8471 - val_loss: 0.2933 - val_accuracy: 0.8600\n",
            "Epoch 80/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8495 - val_loss: 0.2934 - val_accuracy: 0.8619\n",
            "Epoch 81/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3255 - accuracy: 0.8477 - val_loss: 0.2935 - val_accuracy: 0.8604\n",
            "Epoch 82/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8493 - val_loss: 0.2938 - val_accuracy: 0.8579\n",
            "Epoch 83/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8469 - val_loss: 0.2926 - val_accuracy: 0.8591\n",
            "Epoch 84/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8468 - val_loss: 0.2944 - val_accuracy: 0.8582\n",
            "Epoch 85/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8464 - val_loss: 0.2927 - val_accuracy: 0.8581\n",
            "Epoch 86/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3246 - accuracy: 0.8478 - val_loss: 0.2925 - val_accuracy: 0.8597\n",
            "Epoch 87/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3237 - accuracy: 0.8466 - val_loss: 0.2931 - val_accuracy: 0.8579\n",
            "Epoch 88/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3215 - accuracy: 0.8467 - val_loss: 0.2926 - val_accuracy: 0.8595\n",
            "Epoch 89/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3261 - accuracy: 0.8476 - val_loss: 0.2926 - val_accuracy: 0.8587\n",
            "Epoch 90/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.8474 - val_loss: 0.2927 - val_accuracy: 0.8589\n",
            "Epoch 91/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3261 - accuracy: 0.8460 - val_loss: 0.2923 - val_accuracy: 0.8593\n",
            "Epoch 92/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3256 - accuracy: 0.8474 - val_loss: 0.2924 - val_accuracy: 0.8608\n",
            "Epoch 93/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3261 - accuracy: 0.8484 - val_loss: 0.2936 - val_accuracy: 0.8576\n",
            "Epoch 94/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8490 - val_loss: 0.2921 - val_accuracy: 0.8604\n",
            "Epoch 95/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3246 - accuracy: 0.8487 - val_loss: 0.2927 - val_accuracy: 0.8589\n",
            "Epoch 96/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.8478 - val_loss: 0.2925 - val_accuracy: 0.8578\n",
            "Epoch 97/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8454 - val_loss: 0.2919 - val_accuracy: 0.8606\n",
            "Epoch 98/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8462 - val_loss: 0.2932 - val_accuracy: 0.8583\n",
            "Epoch 99/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3235 - accuracy: 0.8485 - val_loss: 0.2918 - val_accuracy: 0.8593\n",
            "Epoch 100/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8483 - val_loss: 0.2925 - val_accuracy: 0.8600\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8600\n",
            "정확률= 0.8600388169288635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. DNN - 4 / 8 / O / leaky_relu"
      ],
      "metadata": {
        "id": "ivuSCbdT9C1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp17 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp17.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp17.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp17.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8570"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc334zMy-_fv",
        "outputId": "b1964c33-b604-4eec-87fa-e53e9b30ed82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "290/290 [==============================] - 3s 5ms/step - loss: 0.6107 - accuracy: 0.6673 - val_loss: 0.4219 - val_accuracy: 0.8191\n",
            "Epoch 2/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.5062 - accuracy: 0.7439 - val_loss: 0.3377 - val_accuracy: 0.8443\n",
            "Epoch 3/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4522 - accuracy: 0.7861 - val_loss: 0.3213 - val_accuracy: 0.8512\n",
            "Epoch 4/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4182 - accuracy: 0.8056 - val_loss: 0.3162 - val_accuracy: 0.8527\n",
            "Epoch 5/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4150 - accuracy: 0.8118 - val_loss: 0.3145 - val_accuracy: 0.8539\n",
            "Epoch 6/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4042 - accuracy: 0.8171 - val_loss: 0.3142 - val_accuracy: 0.8543\n",
            "Epoch 7/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3971 - accuracy: 0.8192 - val_loss: 0.3126 - val_accuracy: 0.8557\n",
            "Epoch 8/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3917 - accuracy: 0.8213 - val_loss: 0.3110 - val_accuracy: 0.8569\n",
            "Epoch 9/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3894 - accuracy: 0.8231 - val_loss: 0.3118 - val_accuracy: 0.8562\n",
            "Epoch 10/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3883 - accuracy: 0.8245 - val_loss: 0.3113 - val_accuracy: 0.8563\n",
            "Epoch 11/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3861 - accuracy: 0.8264 - val_loss: 0.3104 - val_accuracy: 0.8564\n",
            "Epoch 12/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3849 - accuracy: 0.8269 - val_loss: 0.3099 - val_accuracy: 0.8563\n",
            "Epoch 13/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3808 - accuracy: 0.8264 - val_loss: 0.3103 - val_accuracy: 0.8563\n",
            "Epoch 14/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3844 - accuracy: 0.8266 - val_loss: 0.3102 - val_accuracy: 0.8567\n",
            "Epoch 15/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3804 - accuracy: 0.8287 - val_loss: 0.3106 - val_accuracy: 0.8564\n",
            "Epoch 16/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3777 - accuracy: 0.8302 - val_loss: 0.3095 - val_accuracy: 0.8552\n",
            "Epoch 17/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3760 - accuracy: 0.8297 - val_loss: 0.3092 - val_accuracy: 0.8558\n",
            "Epoch 18/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3780 - accuracy: 0.8264 - val_loss: 0.3099 - val_accuracy: 0.8549\n",
            "Epoch 19/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3825 - accuracy: 0.8292 - val_loss: 0.3101 - val_accuracy: 0.8558\n",
            "Epoch 20/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3761 - accuracy: 0.8287 - val_loss: 0.3093 - val_accuracy: 0.8569\n",
            "Epoch 21/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8296 - val_loss: 0.3105 - val_accuracy: 0.8557\n",
            "Epoch 22/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3774 - accuracy: 0.8296 - val_loss: 0.3094 - val_accuracy: 0.8563\n",
            "Epoch 23/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8307 - val_loss: 0.3088 - val_accuracy: 0.8565\n",
            "Epoch 24/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3781 - accuracy: 0.8298 - val_loss: 0.3089 - val_accuracy: 0.8565\n",
            "Epoch 25/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3771 - accuracy: 0.8314 - val_loss: 0.3079 - val_accuracy: 0.8560\n",
            "Epoch 26/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3708 - accuracy: 0.8303 - val_loss: 0.3079 - val_accuracy: 0.8559\n",
            "Epoch 27/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8289 - val_loss: 0.3081 - val_accuracy: 0.8563\n",
            "Epoch 28/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3765 - accuracy: 0.8286 - val_loss: 0.3080 - val_accuracy: 0.8560\n",
            "Epoch 29/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3769 - accuracy: 0.8305 - val_loss: 0.3078 - val_accuracy: 0.8568\n",
            "Epoch 30/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3759 - accuracy: 0.8324 - val_loss: 0.3080 - val_accuracy: 0.8555\n",
            "Epoch 31/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3780 - accuracy: 0.8293 - val_loss: 0.3082 - val_accuracy: 0.8555\n",
            "Epoch 32/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8287 - val_loss: 0.3093 - val_accuracy: 0.8557\n",
            "Epoch 33/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3761 - accuracy: 0.8334 - val_loss: 0.3087 - val_accuracy: 0.8549\n",
            "Epoch 34/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3756 - accuracy: 0.8296 - val_loss: 0.3079 - val_accuracy: 0.8565\n",
            "Epoch 35/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3743 - accuracy: 0.8307 - val_loss: 0.3079 - val_accuracy: 0.8538\n",
            "Epoch 36/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3775 - accuracy: 0.8286 - val_loss: 0.3073 - val_accuracy: 0.8559\n",
            "Epoch 37/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3756 - accuracy: 0.8302 - val_loss: 0.3080 - val_accuracy: 0.8565\n",
            "Epoch 38/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3735 - accuracy: 0.8299 - val_loss: 0.3081 - val_accuracy: 0.8554\n",
            "Epoch 39/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3743 - accuracy: 0.8324 - val_loss: 0.3081 - val_accuracy: 0.8564\n",
            "Epoch 40/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3765 - accuracy: 0.8308 - val_loss: 0.3078 - val_accuracy: 0.8556\n",
            "Epoch 41/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3718 - accuracy: 0.8305 - val_loss: 0.3080 - val_accuracy: 0.8534\n",
            "Epoch 42/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3785 - accuracy: 0.8285 - val_loss: 0.3073 - val_accuracy: 0.8551\n",
            "Epoch 43/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3729 - accuracy: 0.8324 - val_loss: 0.3072 - val_accuracy: 0.8562\n",
            "Epoch 44/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3749 - accuracy: 0.8270 - val_loss: 0.3078 - val_accuracy: 0.8544\n",
            "Epoch 45/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3751 - accuracy: 0.8309 - val_loss: 0.3075 - val_accuracy: 0.8551\n",
            "Epoch 46/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3721 - accuracy: 0.8307 - val_loss: 0.3074 - val_accuracy: 0.8552\n",
            "Epoch 47/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3730 - accuracy: 0.8297 - val_loss: 0.3080 - val_accuracy: 0.8562\n",
            "Epoch 48/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3730 - accuracy: 0.8316 - val_loss: 0.3070 - val_accuracy: 0.8541\n",
            "Epoch 49/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3748 - accuracy: 0.8313 - val_loss: 0.3076 - val_accuracy: 0.8530\n",
            "Epoch 50/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8293 - val_loss: 0.3074 - val_accuracy: 0.8552\n",
            "Epoch 51/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8303 - val_loss: 0.3072 - val_accuracy: 0.8546\n",
            "Epoch 52/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8297 - val_loss: 0.3077 - val_accuracy: 0.8550\n",
            "Epoch 53/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3704 - accuracy: 0.8305 - val_loss: 0.3079 - val_accuracy: 0.8549\n",
            "Epoch 54/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3756 - accuracy: 0.8309 - val_loss: 0.3070 - val_accuracy: 0.8560\n",
            "Epoch 55/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3713 - accuracy: 0.8299 - val_loss: 0.3069 - val_accuracy: 0.8556\n",
            "Epoch 56/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3740 - accuracy: 0.8258 - val_loss: 0.3084 - val_accuracy: 0.8562\n",
            "Epoch 57/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3765 - accuracy: 0.8291 - val_loss: 0.3076 - val_accuracy: 0.8565\n",
            "Epoch 58/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3710 - accuracy: 0.8327 - val_loss: 0.3082 - val_accuracy: 0.8566\n",
            "Epoch 59/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3697 - accuracy: 0.8330 - val_loss: 0.3075 - val_accuracy: 0.8551\n",
            "Epoch 60/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3765 - accuracy: 0.8286 - val_loss: 0.3070 - val_accuracy: 0.8557\n",
            "Epoch 61/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3774 - accuracy: 0.8302 - val_loss: 0.3075 - val_accuracy: 0.8565\n",
            "Epoch 62/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3742 - accuracy: 0.8317 - val_loss: 0.3073 - val_accuracy: 0.8557\n",
            "Epoch 63/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8295 - val_loss: 0.3074 - val_accuracy: 0.8548\n",
            "Epoch 64/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3735 - accuracy: 0.8302 - val_loss: 0.3078 - val_accuracy: 0.8566\n",
            "Epoch 65/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3743 - accuracy: 0.8287 - val_loss: 0.3075 - val_accuracy: 0.8548\n",
            "Epoch 66/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3729 - accuracy: 0.8310 - val_loss: 0.3070 - val_accuracy: 0.8564\n",
            "Epoch 67/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3739 - accuracy: 0.8275 - val_loss: 0.3084 - val_accuracy: 0.8551\n",
            "Epoch 68/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3779 - accuracy: 0.8304 - val_loss: 0.3075 - val_accuracy: 0.8550\n",
            "Epoch 69/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8306 - val_loss: 0.3072 - val_accuracy: 0.8553\n",
            "Epoch 70/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3739 - accuracy: 0.8300 - val_loss: 0.3072 - val_accuracy: 0.8541\n",
            "Epoch 71/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3745 - accuracy: 0.8294 - val_loss: 0.3071 - val_accuracy: 0.8550\n",
            "Epoch 72/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3720 - accuracy: 0.8313 - val_loss: 0.3072 - val_accuracy: 0.8557\n",
            "Epoch 73/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3739 - accuracy: 0.8288 - val_loss: 0.3070 - val_accuracy: 0.8556\n",
            "Epoch 74/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3738 - accuracy: 0.8299 - val_loss: 0.3078 - val_accuracy: 0.8548\n",
            "Epoch 75/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3725 - accuracy: 0.8310 - val_loss: 0.3074 - val_accuracy: 0.8542\n",
            "Epoch 76/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3733 - accuracy: 0.8305 - val_loss: 0.3072 - val_accuracy: 0.8545\n",
            "Epoch 77/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3746 - accuracy: 0.8294 - val_loss: 0.3074 - val_accuracy: 0.8553\n",
            "Epoch 78/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3721 - accuracy: 0.8309 - val_loss: 0.3077 - val_accuracy: 0.8565\n",
            "Epoch 79/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8326 - val_loss: 0.3072 - val_accuracy: 0.8552\n",
            "Epoch 80/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8302 - val_loss: 0.3073 - val_accuracy: 0.8552\n",
            "Epoch 81/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3724 - accuracy: 0.8295 - val_loss: 0.3068 - val_accuracy: 0.8546\n",
            "Epoch 82/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3717 - accuracy: 0.8293 - val_loss: 0.3079 - val_accuracy: 0.8554\n",
            "Epoch 83/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3732 - accuracy: 0.8302 - val_loss: 0.3070 - val_accuracy: 0.8551\n",
            "Epoch 84/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3736 - accuracy: 0.8310 - val_loss: 0.3068 - val_accuracy: 0.8546\n",
            "Epoch 85/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3727 - accuracy: 0.8300 - val_loss: 0.3072 - val_accuracy: 0.8548\n",
            "Epoch 86/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3743 - accuracy: 0.8266 - val_loss: 0.3077 - val_accuracy: 0.8551\n",
            "Epoch 87/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3708 - accuracy: 0.8311 - val_loss: 0.3095 - val_accuracy: 0.8558\n",
            "Epoch 88/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3763 - accuracy: 0.8284 - val_loss: 0.3075 - val_accuracy: 0.8557\n",
            "Epoch 89/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8303 - val_loss: 0.3076 - val_accuracy: 0.8538\n",
            "Epoch 90/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3740 - accuracy: 0.8291 - val_loss: 0.3073 - val_accuracy: 0.8555\n",
            "Epoch 91/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3733 - accuracy: 0.8301 - val_loss: 0.3069 - val_accuracy: 0.8531\n",
            "Epoch 92/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3745 - accuracy: 0.8318 - val_loss: 0.3082 - val_accuracy: 0.8568\n",
            "Epoch 93/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3748 - accuracy: 0.8306 - val_loss: 0.3073 - val_accuracy: 0.8536\n",
            "Epoch 94/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3725 - accuracy: 0.8284 - val_loss: 0.3074 - val_accuracy: 0.8553\n",
            "Epoch 95/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3726 - accuracy: 0.8294 - val_loss: 0.3086 - val_accuracy: 0.8562\n",
            "Epoch 96/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8307 - val_loss: 0.3081 - val_accuracy: 0.8545\n",
            "Epoch 97/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3725 - accuracy: 0.8321 - val_loss: 0.3082 - val_accuracy: 0.8542\n",
            "Epoch 98/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3745 - accuracy: 0.8306 - val_loss: 0.3077 - val_accuracy: 0.8551\n",
            "Epoch 99/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3721 - accuracy: 0.8316 - val_loss: 0.3073 - val_accuracy: 0.8548\n",
            "Epoch 100/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3727 - accuracy: 0.8324 - val_loss: 0.3077 - val_accuracy: 0.8562\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8562\n",
            "정확률= 0.8561570048332214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. DNN - 4 / 16 / O / leaky_relu"
      ],
      "metadata": {
        "id": "xeK5sG-k9Gqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp18 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp18.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp18.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp18.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8593"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdPrDzw6_Dna",
        "outputId": "54f00537-b26d-45ee-c3fb-3f3858b725fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "290/290 [==============================] - 3s 4ms/step - loss: 0.5672 - accuracy: 0.7004 - val_loss: 0.3384 - val_accuracy: 0.8524\n",
            "Epoch 2/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.4124 - accuracy: 0.8158 - val_loss: 0.3150 - val_accuracy: 0.8551\n",
            "Epoch 3/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3777 - accuracy: 0.8346 - val_loss: 0.3122 - val_accuracy: 0.8554\n",
            "Epoch 4/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3662 - accuracy: 0.8347 - val_loss: 0.3091 - val_accuracy: 0.8571\n",
            "Epoch 5/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3613 - accuracy: 0.8413 - val_loss: 0.3110 - val_accuracy: 0.8556\n",
            "Epoch 6/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3561 - accuracy: 0.8410 - val_loss: 0.3090 - val_accuracy: 0.8550\n",
            "Epoch 7/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3496 - accuracy: 0.8448 - val_loss: 0.3057 - val_accuracy: 0.8577\n",
            "Epoch 8/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3471 - accuracy: 0.8448 - val_loss: 0.3067 - val_accuracy: 0.8567\n",
            "Epoch 9/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3455 - accuracy: 0.8445 - val_loss: 0.3049 - val_accuracy: 0.8562\n",
            "Epoch 10/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3463 - accuracy: 0.8456 - val_loss: 0.3038 - val_accuracy: 0.8587\n",
            "Epoch 11/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3432 - accuracy: 0.8467 - val_loss: 0.3037 - val_accuracy: 0.8566\n",
            "Epoch 12/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3443 - accuracy: 0.8468 - val_loss: 0.3025 - val_accuracy: 0.8601\n",
            "Epoch 13/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3402 - accuracy: 0.8481 - val_loss: 0.3024 - val_accuracy: 0.8604\n",
            "Epoch 14/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3404 - accuracy: 0.8453 - val_loss: 0.3012 - val_accuracy: 0.8584\n",
            "Epoch 15/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3431 - accuracy: 0.8463 - val_loss: 0.3014 - val_accuracy: 0.8589\n",
            "Epoch 16/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3422 - accuracy: 0.8462 - val_loss: 0.3012 - val_accuracy: 0.8596\n",
            "Epoch 17/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3390 - accuracy: 0.8468 - val_loss: 0.3010 - val_accuracy: 0.8591\n",
            "Epoch 18/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3382 - accuracy: 0.8464 - val_loss: 0.3002 - val_accuracy: 0.8594\n",
            "Epoch 19/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3401 - accuracy: 0.8476 - val_loss: 0.2998 - val_accuracy: 0.8590\n",
            "Epoch 20/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3382 - accuracy: 0.8477 - val_loss: 0.3000 - val_accuracy: 0.8578\n",
            "Epoch 21/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8464 - val_loss: 0.3002 - val_accuracy: 0.8577\n",
            "Epoch 22/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8463 - val_loss: 0.2994 - val_accuracy: 0.8577\n",
            "Epoch 23/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3350 - accuracy: 0.8472 - val_loss: 0.2989 - val_accuracy: 0.8583\n",
            "Epoch 24/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8451 - val_loss: 0.2988 - val_accuracy: 0.8600\n",
            "Epoch 25/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3369 - accuracy: 0.8468 - val_loss: 0.2989 - val_accuracy: 0.8564\n",
            "Epoch 26/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3353 - accuracy: 0.8460 - val_loss: 0.3000 - val_accuracy: 0.8560\n",
            "Epoch 27/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3360 - accuracy: 0.8479 - val_loss: 0.2978 - val_accuracy: 0.8584\n",
            "Epoch 28/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3332 - accuracy: 0.8466 - val_loss: 0.2980 - val_accuracy: 0.8591\n",
            "Epoch 29/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8444 - val_loss: 0.2982 - val_accuracy: 0.8577\n",
            "Epoch 30/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.8473 - val_loss: 0.2980 - val_accuracy: 0.8583\n",
            "Epoch 31/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3356 - accuracy: 0.8469 - val_loss: 0.2972 - val_accuracy: 0.8584\n",
            "Epoch 32/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8451 - val_loss: 0.2974 - val_accuracy: 0.8599\n",
            "Epoch 33/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3347 - accuracy: 0.8452 - val_loss: 0.2973 - val_accuracy: 0.8583\n",
            "Epoch 34/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.8469 - val_loss: 0.2973 - val_accuracy: 0.8586\n",
            "Epoch 35/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3337 - accuracy: 0.8462 - val_loss: 0.2973 - val_accuracy: 0.8584\n",
            "Epoch 36/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8448 - val_loss: 0.2972 - val_accuracy: 0.8585\n",
            "Epoch 37/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3332 - accuracy: 0.8451 - val_loss: 0.2974 - val_accuracy: 0.8599\n",
            "Epoch 38/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8465 - val_loss: 0.2978 - val_accuracy: 0.8585\n",
            "Epoch 39/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3312 - accuracy: 0.8454 - val_loss: 0.2975 - val_accuracy: 0.8601\n",
            "Epoch 40/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3339 - accuracy: 0.8453 - val_loss: 0.2973 - val_accuracy: 0.8572\n",
            "Epoch 41/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3330 - accuracy: 0.8458 - val_loss: 0.2973 - val_accuracy: 0.8589\n",
            "Epoch 42/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3328 - accuracy: 0.8464 - val_loss: 0.2981 - val_accuracy: 0.8577\n",
            "Epoch 43/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3322 - accuracy: 0.8472 - val_loss: 0.2967 - val_accuracy: 0.8592\n",
            "Epoch 44/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3337 - accuracy: 0.8457 - val_loss: 0.2966 - val_accuracy: 0.8597\n",
            "Epoch 45/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8463 - val_loss: 0.2964 - val_accuracy: 0.8592\n",
            "Epoch 46/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8458 - val_loss: 0.2962 - val_accuracy: 0.8594\n",
            "Epoch 47/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8458 - val_loss: 0.2960 - val_accuracy: 0.8571\n",
            "Epoch 48/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8461 - val_loss: 0.2964 - val_accuracy: 0.8587\n",
            "Epoch 49/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3329 - accuracy: 0.8438 - val_loss: 0.2963 - val_accuracy: 0.8585\n",
            "Epoch 50/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8448 - val_loss: 0.2959 - val_accuracy: 0.8596\n",
            "Epoch 51/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3321 - accuracy: 0.8446 - val_loss: 0.2963 - val_accuracy: 0.8583\n",
            "Epoch 52/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.8441 - val_loss: 0.2956 - val_accuracy: 0.8593\n",
            "Epoch 53/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8454 - val_loss: 0.2957 - val_accuracy: 0.8600\n",
            "Epoch 54/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3308 - accuracy: 0.8464 - val_loss: 0.2949 - val_accuracy: 0.8608\n",
            "Epoch 55/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3324 - accuracy: 0.8445 - val_loss: 0.2965 - val_accuracy: 0.8576\n",
            "Epoch 56/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3344 - accuracy: 0.8468 - val_loss: 0.2958 - val_accuracy: 0.8599\n",
            "Epoch 57/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3320 - accuracy: 0.8446 - val_loss: 0.2955 - val_accuracy: 0.8592\n",
            "Epoch 58/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.8466 - val_loss: 0.2950 - val_accuracy: 0.8586\n",
            "Epoch 59/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3310 - accuracy: 0.8453 - val_loss: 0.2958 - val_accuracy: 0.8575\n",
            "Epoch 60/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8451 - val_loss: 0.2950 - val_accuracy: 0.8591\n",
            "Epoch 61/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3333 - accuracy: 0.8456 - val_loss: 0.2958 - val_accuracy: 0.8594\n",
            "Epoch 62/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3323 - accuracy: 0.8449 - val_loss: 0.2958 - val_accuracy: 0.8560\n",
            "Epoch 63/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.8444 - val_loss: 0.2948 - val_accuracy: 0.8592\n",
            "Epoch 64/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8449 - val_loss: 0.2949 - val_accuracy: 0.8587\n",
            "Epoch 65/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8461 - val_loss: 0.2952 - val_accuracy: 0.8572\n",
            "Epoch 66/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3328 - accuracy: 0.8457 - val_loss: 0.2949 - val_accuracy: 0.8586\n",
            "Epoch 67/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8445 - val_loss: 0.2950 - val_accuracy: 0.8566\n",
            "Epoch 68/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3291 - accuracy: 0.8471 - val_loss: 0.2952 - val_accuracy: 0.8586\n",
            "Epoch 69/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3302 - accuracy: 0.8452 - val_loss: 0.2947 - val_accuracy: 0.8570\n",
            "Epoch 70/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3313 - accuracy: 0.8456 - val_loss: 0.2942 - val_accuracy: 0.8592\n",
            "Epoch 71/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3322 - accuracy: 0.8437 - val_loss: 0.2941 - val_accuracy: 0.8594\n",
            "Epoch 72/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8462 - val_loss: 0.2946 - val_accuracy: 0.8579\n",
            "Epoch 73/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8465 - val_loss: 0.2937 - val_accuracy: 0.8587\n",
            "Epoch 74/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8478 - val_loss: 0.2938 - val_accuracy: 0.8580\n",
            "Epoch 75/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3327 - accuracy: 0.8435 - val_loss: 0.2944 - val_accuracy: 0.8581\n",
            "Epoch 76/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8462 - val_loss: 0.2940 - val_accuracy: 0.8596\n",
            "Epoch 77/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8471 - val_loss: 0.2935 - val_accuracy: 0.8593\n",
            "Epoch 78/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3312 - accuracy: 0.8469 - val_loss: 0.2937 - val_accuracy: 0.8582\n",
            "Epoch 79/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3301 - accuracy: 0.8453 - val_loss: 0.2933 - val_accuracy: 0.8604\n",
            "Epoch 80/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3319 - accuracy: 0.8440 - val_loss: 0.2940 - val_accuracy: 0.8594\n",
            "Epoch 81/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3290 - accuracy: 0.8466 - val_loss: 0.2941 - val_accuracy: 0.8600\n",
            "Epoch 82/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3301 - accuracy: 0.8457 - val_loss: 0.2942 - val_accuracy: 0.8570\n",
            "Epoch 83/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3323 - accuracy: 0.8453 - val_loss: 0.2933 - val_accuracy: 0.8585\n",
            "Epoch 84/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3297 - accuracy: 0.8445 - val_loss: 0.2932 - val_accuracy: 0.8611\n",
            "Epoch 85/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3307 - accuracy: 0.8462 - val_loss: 0.2934 - val_accuracy: 0.8596\n",
            "Epoch 86/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8466 - val_loss: 0.2937 - val_accuracy: 0.8605\n",
            "Epoch 87/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8460 - val_loss: 0.2936 - val_accuracy: 0.8589\n",
            "Epoch 88/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3287 - accuracy: 0.8473 - val_loss: 0.2939 - val_accuracy: 0.8570\n",
            "Epoch 89/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3306 - accuracy: 0.8458 - val_loss: 0.2932 - val_accuracy: 0.8595\n",
            "Epoch 90/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8449 - val_loss: 0.2932 - val_accuracy: 0.8605\n",
            "Epoch 91/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8448 - val_loss: 0.2927 - val_accuracy: 0.8575\n",
            "Epoch 92/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3289 - accuracy: 0.8469 - val_loss: 0.2938 - val_accuracy: 0.8557\n",
            "Epoch 93/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3312 - accuracy: 0.8441 - val_loss: 0.2923 - val_accuracy: 0.8599\n",
            "Epoch 94/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3284 - accuracy: 0.8451 - val_loss: 0.2927 - val_accuracy: 0.8599\n",
            "Epoch 95/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3287 - accuracy: 0.8458 - val_loss: 0.2923 - val_accuracy: 0.8601\n",
            "Epoch 96/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3298 - accuracy: 0.8450 - val_loss: 0.2929 - val_accuracy: 0.8568\n",
            "Epoch 97/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3307 - accuracy: 0.8447 - val_loss: 0.2926 - val_accuracy: 0.8583\n",
            "Epoch 98/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3287 - accuracy: 0.8476 - val_loss: 0.2919 - val_accuracy: 0.8590\n",
            "Epoch 99/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3288 - accuracy: 0.8477 - val_loss: 0.2930 - val_accuracy: 0.8584\n",
            "Epoch 100/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3310 - accuracy: 0.8461 - val_loss: 0.2922 - val_accuracy: 0.8591\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.8591\n",
            "정확률= 0.8590683341026306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. DNN - 5 / 8 / O / leaky_relu"
      ],
      "metadata": {
        "id": "2iM0SD3w9IKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp19 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp19.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp19.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp19.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8606"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSnvKpbX_EFx",
        "outputId": "324ee25d-c4c5-4752-c200-9c00a1d0efd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "290/290 [==============================] - 4s 4ms/step - loss: 0.6248 - accuracy: 0.6573 - val_loss: 0.4049 - val_accuracy: 0.8357\n",
            "Epoch 2/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4423 - accuracy: 0.7932 - val_loss: 0.3240 - val_accuracy: 0.8509\n",
            "Epoch 3/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3906 - accuracy: 0.8256 - val_loss: 0.3143 - val_accuracy: 0.8541\n",
            "Epoch 4/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3802 - accuracy: 0.8327 - val_loss: 0.3116 - val_accuracy: 0.8556\n",
            "Epoch 5/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3677 - accuracy: 0.8366 - val_loss: 0.3136 - val_accuracy: 0.8569\n",
            "Epoch 6/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3643 - accuracy: 0.8406 - val_loss: 0.3101 - val_accuracy: 0.8569\n",
            "Epoch 7/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3593 - accuracy: 0.8418 - val_loss: 0.3093 - val_accuracy: 0.8569\n",
            "Epoch 8/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3555 - accuracy: 0.8437 - val_loss: 0.3094 - val_accuracy: 0.8578\n",
            "Epoch 9/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3540 - accuracy: 0.8443 - val_loss: 0.3073 - val_accuracy: 0.8576\n",
            "Epoch 10/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3540 - accuracy: 0.8444 - val_loss: 0.3073 - val_accuracy: 0.8583\n",
            "Epoch 11/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3526 - accuracy: 0.8461 - val_loss: 0.3059 - val_accuracy: 0.8581\n",
            "Epoch 12/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3484 - accuracy: 0.8457 - val_loss: 0.3049 - val_accuracy: 0.8585\n",
            "Epoch 13/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3492 - accuracy: 0.8463 - val_loss: 0.3046 - val_accuracy: 0.8608\n",
            "Epoch 14/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3468 - accuracy: 0.8456 - val_loss: 0.3034 - val_accuracy: 0.8582\n",
            "Epoch 15/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3475 - accuracy: 0.8437 - val_loss: 0.3041 - val_accuracy: 0.8589\n",
            "Epoch 16/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3448 - accuracy: 0.8457 - val_loss: 0.3030 - val_accuracy: 0.8599\n",
            "Epoch 17/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3485 - accuracy: 0.8463 - val_loss: 0.3023 - val_accuracy: 0.8601\n",
            "Epoch 18/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3436 - accuracy: 0.8458 - val_loss: 0.3016 - val_accuracy: 0.8591\n",
            "Epoch 19/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3437 - accuracy: 0.8463 - val_loss: 0.3011 - val_accuracy: 0.8579\n",
            "Epoch 20/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3424 - accuracy: 0.8467 - val_loss: 0.2997 - val_accuracy: 0.8583\n",
            "Epoch 21/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3445 - accuracy: 0.8457 - val_loss: 0.3004 - val_accuracy: 0.8583\n",
            "Epoch 22/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3423 - accuracy: 0.8461 - val_loss: 0.2987 - val_accuracy: 0.8604\n",
            "Epoch 23/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3398 - accuracy: 0.8460 - val_loss: 0.2993 - val_accuracy: 0.8606\n",
            "Epoch 24/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3416 - accuracy: 0.8439 - val_loss: 0.2992 - val_accuracy: 0.8568\n",
            "Epoch 25/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3408 - accuracy: 0.8478 - val_loss: 0.2978 - val_accuracy: 0.8586\n",
            "Epoch 26/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3412 - accuracy: 0.8481 - val_loss: 0.2997 - val_accuracy: 0.8600\n",
            "Epoch 27/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3407 - accuracy: 0.8471 - val_loss: 0.2985 - val_accuracy: 0.8604\n",
            "Epoch 28/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3419 - accuracy: 0.8475 - val_loss: 0.2989 - val_accuracy: 0.8613\n",
            "Epoch 29/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3402 - accuracy: 0.8481 - val_loss: 0.2976 - val_accuracy: 0.8599\n",
            "Epoch 30/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3384 - accuracy: 0.8460 - val_loss: 0.2980 - val_accuracy: 0.8600\n",
            "Epoch 31/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3420 - accuracy: 0.8441 - val_loss: 0.2977 - val_accuracy: 0.8577\n",
            "Epoch 32/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3391 - accuracy: 0.8465 - val_loss: 0.2986 - val_accuracy: 0.8611\n",
            "Epoch 33/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3378 - accuracy: 0.8447 - val_loss: 0.2979 - val_accuracy: 0.8583\n",
            "Epoch 34/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3373 - accuracy: 0.8460 - val_loss: 0.2971 - val_accuracy: 0.8566\n",
            "Epoch 35/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3365 - accuracy: 0.8474 - val_loss: 0.2968 - val_accuracy: 0.8622\n",
            "Epoch 36/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3394 - accuracy: 0.8457 - val_loss: 0.2967 - val_accuracy: 0.8606\n",
            "Epoch 37/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3392 - accuracy: 0.8477 - val_loss: 0.2979 - val_accuracy: 0.8607\n",
            "Epoch 38/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3379 - accuracy: 0.8459 - val_loss: 0.2962 - val_accuracy: 0.8585\n",
            "Epoch 39/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3380 - accuracy: 0.8451 - val_loss: 0.2954 - val_accuracy: 0.8582\n",
            "Epoch 40/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3391 - accuracy: 0.8460 - val_loss: 0.2962 - val_accuracy: 0.8582\n",
            "Epoch 41/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3390 - accuracy: 0.8452 - val_loss: 0.2957 - val_accuracy: 0.8607\n",
            "Epoch 42/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3397 - accuracy: 0.8456 - val_loss: 0.2958 - val_accuracy: 0.8598\n",
            "Epoch 43/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3372 - accuracy: 0.8444 - val_loss: 0.2946 - val_accuracy: 0.8573\n",
            "Epoch 44/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3370 - accuracy: 0.8462 - val_loss: 0.2949 - val_accuracy: 0.8614\n",
            "Epoch 45/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3362 - accuracy: 0.8458 - val_loss: 0.2943 - val_accuracy: 0.8612\n",
            "Epoch 46/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8444 - val_loss: 0.2943 - val_accuracy: 0.8620\n",
            "Epoch 47/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3370 - accuracy: 0.8461 - val_loss: 0.2946 - val_accuracy: 0.8614\n",
            "Epoch 48/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3378 - accuracy: 0.8449 - val_loss: 0.2946 - val_accuracy: 0.8605\n",
            "Epoch 49/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3379 - accuracy: 0.8479 - val_loss: 0.2951 - val_accuracy: 0.8607\n",
            "Epoch 50/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3363 - accuracy: 0.8459 - val_loss: 0.2935 - val_accuracy: 0.8601\n",
            "Epoch 51/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8443 - val_loss: 0.2943 - val_accuracy: 0.8598\n",
            "Epoch 52/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3379 - accuracy: 0.8459 - val_loss: 0.2940 - val_accuracy: 0.8587\n",
            "Epoch 53/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.8470 - val_loss: 0.2942 - val_accuracy: 0.8585\n",
            "Epoch 54/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3361 - accuracy: 0.8460 - val_loss: 0.2937 - val_accuracy: 0.8624\n",
            "Epoch 55/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3377 - accuracy: 0.8452 - val_loss: 0.2921 - val_accuracy: 0.8621\n",
            "Epoch 56/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3372 - accuracy: 0.8453 - val_loss: 0.2924 - val_accuracy: 0.8614\n",
            "Epoch 57/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3378 - accuracy: 0.8462 - val_loss: 0.2920 - val_accuracy: 0.8626\n",
            "Epoch 58/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3340 - accuracy: 0.8452 - val_loss: 0.2951 - val_accuracy: 0.8612\n",
            "Epoch 59/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3366 - accuracy: 0.8444 - val_loss: 0.2935 - val_accuracy: 0.8597\n",
            "Epoch 60/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3343 - accuracy: 0.8446 - val_loss: 0.2937 - val_accuracy: 0.8619\n",
            "Epoch 61/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3328 - accuracy: 0.8445 - val_loss: 0.2941 - val_accuracy: 0.8614\n",
            "Epoch 62/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3325 - accuracy: 0.8457 - val_loss: 0.2932 - val_accuracy: 0.8628\n",
            "Epoch 63/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3349 - accuracy: 0.8473 - val_loss: 0.2929 - val_accuracy: 0.8631\n",
            "Epoch 64/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3343 - accuracy: 0.8456 - val_loss: 0.2925 - val_accuracy: 0.8613\n",
            "Epoch 65/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3342 - accuracy: 0.8447 - val_loss: 0.2921 - val_accuracy: 0.8624\n",
            "Epoch 66/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3346 - accuracy: 0.8460 - val_loss: 0.2925 - val_accuracy: 0.8608\n",
            "Epoch 67/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3334 - accuracy: 0.8473 - val_loss: 0.2914 - val_accuracy: 0.8623\n",
            "Epoch 68/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3373 - accuracy: 0.8454 - val_loss: 0.2926 - val_accuracy: 0.8587\n",
            "Epoch 69/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3364 - accuracy: 0.8456 - val_loss: 0.2922 - val_accuracy: 0.8622\n",
            "Epoch 70/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3349 - accuracy: 0.8439 - val_loss: 0.2925 - val_accuracy: 0.8615\n",
            "Epoch 71/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3307 - accuracy: 0.8456 - val_loss: 0.2931 - val_accuracy: 0.8618\n",
            "Epoch 72/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3329 - accuracy: 0.8452 - val_loss: 0.2941 - val_accuracy: 0.8604\n",
            "Epoch 73/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8454 - val_loss: 0.2930 - val_accuracy: 0.8610\n",
            "Epoch 74/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8437 - val_loss: 0.2921 - val_accuracy: 0.8605\n",
            "Epoch 75/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3345 - accuracy: 0.8449 - val_loss: 0.2931 - val_accuracy: 0.8610\n",
            "Epoch 76/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8449 - val_loss: 0.2913 - val_accuracy: 0.8606\n",
            "Epoch 77/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3338 - accuracy: 0.8450 - val_loss: 0.2924 - val_accuracy: 0.8610\n",
            "Epoch 78/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3325 - accuracy: 0.8452 - val_loss: 0.2918 - val_accuracy: 0.8613\n",
            "Epoch 79/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3344 - accuracy: 0.8454 - val_loss: 0.2916 - val_accuracy: 0.8626\n",
            "Epoch 80/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3320 - accuracy: 0.8454 - val_loss: 0.2927 - val_accuracy: 0.8604\n",
            "Epoch 81/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3338 - accuracy: 0.8455 - val_loss: 0.2923 - val_accuracy: 0.8618\n",
            "Epoch 82/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3352 - accuracy: 0.8453 - val_loss: 0.2922 - val_accuracy: 0.8617\n",
            "Epoch 83/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3332 - accuracy: 0.8441 - val_loss: 0.2923 - val_accuracy: 0.8623\n",
            "Epoch 84/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3321 - accuracy: 0.8443 - val_loss: 0.2920 - val_accuracy: 0.8618\n",
            "Epoch 85/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3352 - accuracy: 0.8447 - val_loss: 0.2935 - val_accuracy: 0.8612\n",
            "Epoch 86/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3317 - accuracy: 0.8461 - val_loss: 0.2912 - val_accuracy: 0.8621\n",
            "Epoch 87/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3359 - accuracy: 0.8444 - val_loss: 0.2915 - val_accuracy: 0.8619\n",
            "Epoch 88/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8443 - val_loss: 0.2908 - val_accuracy: 0.8605\n",
            "Epoch 89/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3365 - accuracy: 0.8447 - val_loss: 0.2910 - val_accuracy: 0.8615\n",
            "Epoch 90/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3361 - accuracy: 0.8446 - val_loss: 0.2921 - val_accuracy: 0.8619\n",
            "Epoch 91/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3341 - accuracy: 0.8458 - val_loss: 0.2920 - val_accuracy: 0.8627\n",
            "Epoch 92/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3326 - accuracy: 0.8452 - val_loss: 0.2910 - val_accuracy: 0.8625\n",
            "Epoch 93/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3332 - accuracy: 0.8454 - val_loss: 0.2922 - val_accuracy: 0.8618\n",
            "Epoch 94/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3350 - accuracy: 0.8432 - val_loss: 0.2914 - val_accuracy: 0.8630\n",
            "Epoch 95/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3353 - accuracy: 0.8440 - val_loss: 0.2913 - val_accuracy: 0.8620\n",
            "Epoch 96/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3335 - accuracy: 0.8435 - val_loss: 0.2922 - val_accuracy: 0.8620\n",
            "Epoch 97/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3361 - accuracy: 0.8436 - val_loss: 0.2923 - val_accuracy: 0.8635\n",
            "Epoch 98/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3353 - accuracy: 0.8420 - val_loss: 0.2920 - val_accuracy: 0.8609\n",
            "Epoch 99/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3332 - accuracy: 0.8433 - val_loss: 0.2920 - val_accuracy: 0.8615\n",
            "Epoch 100/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3327 - accuracy: 0.8459 - val_loss: 0.2911 - val_accuracy: 0.8606\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2911 - accuracy: 0.8606\n",
            "정확률= 0.8605779409408569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. DNN - 5 / 16 / O / leaky_relu"
      ],
      "metadata": {
        "id": "bGP8RmL99KmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp20 = Sequential([\n",
        "    keras.layers.Input(shape=(8,)),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "mlp20.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = mlp20.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = mlp20.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8604"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRt605qA_EyS",
        "outputId": "111ec894-ae75-4a2f-ef1f-75a9e4d8418c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "290/290 [==============================] - 3s 6ms/step - loss: 0.6121 - accuracy: 0.6609 - val_loss: 0.3662 - val_accuracy: 0.8427\n",
            "Epoch 2/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.4417 - accuracy: 0.7998 - val_loss: 0.3223 - val_accuracy: 0.8514\n",
            "Epoch 3/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3982 - accuracy: 0.8236 - val_loss: 0.3144 - val_accuracy: 0.8521\n",
            "Epoch 4/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3776 - accuracy: 0.8326 - val_loss: 0.3119 - val_accuracy: 0.8521\n",
            "Epoch 5/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3711 - accuracy: 0.8362 - val_loss: 0.3106 - val_accuracy: 0.8563\n",
            "Epoch 6/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3650 - accuracy: 0.8384 - val_loss: 0.3107 - val_accuracy: 0.8563\n",
            "Epoch 7/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3620 - accuracy: 0.8418 - val_loss: 0.3081 - val_accuracy: 0.8580\n",
            "Epoch 8/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3585 - accuracy: 0.8420 - val_loss: 0.3080 - val_accuracy: 0.8579\n",
            "Epoch 9/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3569 - accuracy: 0.8446 - val_loss: 0.3065 - val_accuracy: 0.8571\n",
            "Epoch 10/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3539 - accuracy: 0.8430 - val_loss: 0.3078 - val_accuracy: 0.8589\n",
            "Epoch 11/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3474 - accuracy: 0.8449 - val_loss: 0.3058 - val_accuracy: 0.8578\n",
            "Epoch 12/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3513 - accuracy: 0.8480 - val_loss: 0.3053 - val_accuracy: 0.8562\n",
            "Epoch 13/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3484 - accuracy: 0.8433 - val_loss: 0.3042 - val_accuracy: 0.8596\n",
            "Epoch 14/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3476 - accuracy: 0.8461 - val_loss: 0.3043 - val_accuracy: 0.8570\n",
            "Epoch 15/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3497 - accuracy: 0.8445 - val_loss: 0.3040 - val_accuracy: 0.8582\n",
            "Epoch 16/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3493 - accuracy: 0.8468 - val_loss: 0.3036 - val_accuracy: 0.8586\n",
            "Epoch 17/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3468 - accuracy: 0.8457 - val_loss: 0.3031 - val_accuracy: 0.8581\n",
            "Epoch 18/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3460 - accuracy: 0.8467 - val_loss: 0.3021 - val_accuracy: 0.8597\n",
            "Epoch 19/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3444 - accuracy: 0.8451 - val_loss: 0.3026 - val_accuracy: 0.8603\n",
            "Epoch 20/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3473 - accuracy: 0.8440 - val_loss: 0.3021 - val_accuracy: 0.8578\n",
            "Epoch 21/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3435 - accuracy: 0.8475 - val_loss: 0.3015 - val_accuracy: 0.8592\n",
            "Epoch 22/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3445 - accuracy: 0.8467 - val_loss: 0.3018 - val_accuracy: 0.8585\n",
            "Epoch 23/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3470 - accuracy: 0.8442 - val_loss: 0.3029 - val_accuracy: 0.8595\n",
            "Epoch 24/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3446 - accuracy: 0.8455 - val_loss: 0.3026 - val_accuracy: 0.8581\n",
            "Epoch 25/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3422 - accuracy: 0.8464 - val_loss: 0.3007 - val_accuracy: 0.8586\n",
            "Epoch 26/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3441 - accuracy: 0.8457 - val_loss: 0.3009 - val_accuracy: 0.8596\n",
            "Epoch 27/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3440 - accuracy: 0.8456 - val_loss: 0.3008 - val_accuracy: 0.8600\n",
            "Epoch 28/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3425 - accuracy: 0.8467 - val_loss: 0.3011 - val_accuracy: 0.8583\n",
            "Epoch 29/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3441 - accuracy: 0.8462 - val_loss: 0.3007 - val_accuracy: 0.8578\n",
            "Epoch 30/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3427 - accuracy: 0.8439 - val_loss: 0.3005 - val_accuracy: 0.8582\n",
            "Epoch 31/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3436 - accuracy: 0.8466 - val_loss: 0.3010 - val_accuracy: 0.8551\n",
            "Epoch 32/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.8468 - val_loss: 0.3002 - val_accuracy: 0.8579\n",
            "Epoch 33/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3441 - accuracy: 0.8450 - val_loss: 0.2996 - val_accuracy: 0.8586\n",
            "Epoch 34/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3395 - accuracy: 0.8475 - val_loss: 0.2998 - val_accuracy: 0.8590\n",
            "Epoch 35/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3422 - accuracy: 0.8460 - val_loss: 0.2991 - val_accuracy: 0.8598\n",
            "Epoch 36/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3394 - accuracy: 0.8461 - val_loss: 0.2995 - val_accuracy: 0.8572\n",
            "Epoch 37/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3416 - accuracy: 0.8458 - val_loss: 0.2987 - val_accuracy: 0.8582\n",
            "Epoch 38/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3396 - accuracy: 0.8451 - val_loss: 0.3006 - val_accuracy: 0.8565\n",
            "Epoch 39/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3398 - accuracy: 0.8440 - val_loss: 0.2984 - val_accuracy: 0.8597\n",
            "Epoch 40/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3405 - accuracy: 0.8457 - val_loss: 0.2994 - val_accuracy: 0.8587\n",
            "Epoch 41/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3383 - accuracy: 0.8464 - val_loss: 0.2987 - val_accuracy: 0.8605\n",
            "Epoch 42/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3376 - accuracy: 0.8475 - val_loss: 0.2983 - val_accuracy: 0.8576\n",
            "Epoch 43/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3411 - accuracy: 0.8470 - val_loss: 0.2973 - val_accuracy: 0.8575\n",
            "Epoch 44/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3395 - accuracy: 0.8448 - val_loss: 0.2974 - val_accuracy: 0.8592\n",
            "Epoch 45/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.8463 - val_loss: 0.2980 - val_accuracy: 0.8586\n",
            "Epoch 46/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3387 - accuracy: 0.8474 - val_loss: 0.2965 - val_accuracy: 0.8606\n",
            "Epoch 47/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3410 - accuracy: 0.8458 - val_loss: 0.2975 - val_accuracy: 0.8618\n",
            "Epoch 48/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3403 - accuracy: 0.8471 - val_loss: 0.2983 - val_accuracy: 0.8603\n",
            "Epoch 49/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3387 - accuracy: 0.8464 - val_loss: 0.2971 - val_accuracy: 0.8609\n",
            "Epoch 50/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3419 - accuracy: 0.8458 - val_loss: 0.2964 - val_accuracy: 0.8627\n",
            "Epoch 51/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3393 - accuracy: 0.8450 - val_loss: 0.2963 - val_accuracy: 0.8618\n",
            "Epoch 52/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3418 - accuracy: 0.8447 - val_loss: 0.2962 - val_accuracy: 0.8576\n",
            "Epoch 53/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3385 - accuracy: 0.8449 - val_loss: 0.2969 - val_accuracy: 0.8618\n",
            "Epoch 54/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3405 - accuracy: 0.8453 - val_loss: 0.2969 - val_accuracy: 0.8606\n",
            "Epoch 55/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3399 - accuracy: 0.8456 - val_loss: 0.2960 - val_accuracy: 0.8587\n",
            "Epoch 56/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.8454 - val_loss: 0.2970 - val_accuracy: 0.8580\n",
            "Epoch 57/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3411 - accuracy: 0.8447 - val_loss: 0.2959 - val_accuracy: 0.8618\n",
            "Epoch 58/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3380 - accuracy: 0.8463 - val_loss: 0.2960 - val_accuracy: 0.8603\n",
            "Epoch 59/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3392 - accuracy: 0.8457 - val_loss: 0.2962 - val_accuracy: 0.8617\n",
            "Epoch 60/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.8443 - val_loss: 0.2962 - val_accuracy: 0.8605\n",
            "Epoch 61/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3388 - accuracy: 0.8441 - val_loss: 0.2961 - val_accuracy: 0.8594\n",
            "Epoch 62/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3404 - accuracy: 0.8442 - val_loss: 0.2967 - val_accuracy: 0.8597\n",
            "Epoch 63/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3403 - accuracy: 0.8464 - val_loss: 0.2971 - val_accuracy: 0.8573\n",
            "Epoch 64/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3395 - accuracy: 0.8433 - val_loss: 0.2955 - val_accuracy: 0.8599\n",
            "Epoch 65/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3380 - accuracy: 0.8458 - val_loss: 0.2962 - val_accuracy: 0.8598\n",
            "Epoch 66/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3378 - accuracy: 0.8458 - val_loss: 0.2965 - val_accuracy: 0.8563\n",
            "Epoch 67/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3397 - accuracy: 0.8443 - val_loss: 0.2954 - val_accuracy: 0.8591\n",
            "Epoch 68/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3379 - accuracy: 0.8453 - val_loss: 0.2952 - val_accuracy: 0.8596\n",
            "Epoch 69/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3399 - accuracy: 0.8449 - val_loss: 0.2965 - val_accuracy: 0.8611\n",
            "Epoch 70/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.8429 - val_loss: 0.2955 - val_accuracy: 0.8587\n",
            "Epoch 71/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3401 - accuracy: 0.8448 - val_loss: 0.2952 - val_accuracy: 0.8597\n",
            "Epoch 72/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3367 - accuracy: 0.8440 - val_loss: 0.2949 - val_accuracy: 0.8604\n",
            "Epoch 73/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3334 - accuracy: 0.8460 - val_loss: 0.2948 - val_accuracy: 0.8612\n",
            "Epoch 74/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3408 - accuracy: 0.8440 - val_loss: 0.2956 - val_accuracy: 0.8610\n",
            "Epoch 75/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3396 - accuracy: 0.8459 - val_loss: 0.2954 - val_accuracy: 0.8592\n",
            "Epoch 76/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3374 - accuracy: 0.8456 - val_loss: 0.2951 - val_accuracy: 0.8609\n",
            "Epoch 77/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3386 - accuracy: 0.8471 - val_loss: 0.2950 - val_accuracy: 0.8591\n",
            "Epoch 78/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3383 - accuracy: 0.8439 - val_loss: 0.2944 - val_accuracy: 0.8595\n",
            "Epoch 79/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3370 - accuracy: 0.8458 - val_loss: 0.2953 - val_accuracy: 0.8583\n",
            "Epoch 80/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3410 - accuracy: 0.8430 - val_loss: 0.2950 - val_accuracy: 0.8604\n",
            "Epoch 81/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3403 - accuracy: 0.8436 - val_loss: 0.2952 - val_accuracy: 0.8603\n",
            "Epoch 82/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3369 - accuracy: 0.8433 - val_loss: 0.2949 - val_accuracy: 0.8595\n",
            "Epoch 83/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8455 - val_loss: 0.2951 - val_accuracy: 0.8599\n",
            "Epoch 84/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3389 - accuracy: 0.8454 - val_loss: 0.2950 - val_accuracy: 0.8598\n",
            "Epoch 85/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8434 - val_loss: 0.2943 - val_accuracy: 0.8610\n",
            "Epoch 86/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3370 - accuracy: 0.8468 - val_loss: 0.2941 - val_accuracy: 0.8606\n",
            "Epoch 87/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8433 - val_loss: 0.2952 - val_accuracy: 0.8593\n",
            "Epoch 88/100\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3388 - accuracy: 0.8443 - val_loss: 0.2943 - val_accuracy: 0.8605\n",
            "Epoch 89/100\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3383 - accuracy: 0.8449 - val_loss: 0.2941 - val_accuracy: 0.8592\n",
            "Epoch 90/100\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3375 - accuracy: 0.8442 - val_loss: 0.2945 - val_accuracy: 0.8622\n",
            "Epoch 91/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3387 - accuracy: 0.8432 - val_loss: 0.2963 - val_accuracy: 0.8614\n",
            "Epoch 92/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.8450 - val_loss: 0.2945 - val_accuracy: 0.8600\n",
            "Epoch 93/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.8439 - val_loss: 0.2946 - val_accuracy: 0.8608\n",
            "Epoch 94/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3372 - accuracy: 0.8437 - val_loss: 0.2945 - val_accuracy: 0.8599\n",
            "Epoch 95/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3367 - accuracy: 0.8450 - val_loss: 0.2936 - val_accuracy: 0.8609\n",
            "Epoch 96/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.8448 - val_loss: 0.2934 - val_accuracy: 0.8586\n",
            "Epoch 97/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3392 - accuracy: 0.8434 - val_loss: 0.2935 - val_accuracy: 0.8568\n",
            "Epoch 98/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3392 - accuracy: 0.8450 - val_loss: 0.2939 - val_accuracy: 0.8604\n",
            "Epoch 99/100\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8453 - val_loss: 0.2947 - val_accuracy: 0.8605\n",
            "Epoch 100/100\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3352 - accuracy: 0.8440 - val_loss: 0.2944 - val_accuracy: 0.8604\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2944 - accuracy: 0.8604\n",
            "정확률= 0.8603622913360596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN 모델 개선 이전과 비교"
      ],
      "metadata": {
        "id": "AXT0CCOq_e5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![성능_표.JPG](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "g6dqRkUdXbJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![성능_그래프.JPG](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "G3Bp2SwgP8r4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전과 비교하여 확실히 성능이 개선되었으며, 최고 성능은 10번째 모델로 0.8711의 정확도를 보여줬습니다. 평균적으로 10%p 정도 개선되었습니다."
      ],
      "metadata": {
        "id": "wLbSIw6NP_3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN 모델"
      ],
      "metadata": {
        "id": "LYwvRtdwSN02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN - conv1d 이후에 은닉층에서 노드 수를 선정하기 위해 은닉층 노드 수에 따라 비교를 수행했습니다. 결과적으로 대부분의 경우에서 16개로 설정한 경우가 성능이 더 뛰어났기에 16개로 설정하기로 했습니다."
      ],
      "metadata": {
        "id": "vyOTSJ3DTlI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![노드 수.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAeAB4AAD/4QLcRXhpZgAATU0AKgAAAAgABAE7AAIAAAAKAAABSodpAAQAAAABAAABVJydAAEAAAAIAAACzOocAAcAAAEMAAAAPgAAAAAc6gAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6rmA7ZiB66+8AAAFkAMAAgAAABQAAAKikAQAAgAAABQAAAK2kpEAAgAAAAMwOAAAkpIAAgAAAAMwOAAA6hwABwAAAQwAAAGWAAAAABzqAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDI0OjA1OjI2IDIzOjM0OjMxADIwMjQ6MDU6MjYgMjM6MzQ6MzEAAABArgHW/LsAAP/hBBxodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0n77u/JyBpZD0nVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkJz8+DQo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIj48cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIi8+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iPjx4bXA6Q3JlYXRlRGF0ZT4yMDI0LTA1LTI2VDIzOjM0OjMxLjA3NzwveG1wOkNyZWF0ZURhdGU+PC9yZGY6RGVzY3JpcHRpb24+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iPjxkYzpjcmVhdG9yPjxyZGY6U2VxIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpsaT7quYDtmIHrr7w8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIDw/eHBhY2tldCBlbmQ9J3cnPz7/2wBDAAcFBQYFBAcGBQYIBwcIChELCgkJChUPEAwRGBUaGRgVGBcbHichGx0lHRcYIi4iJSgpKywrGiAvMy8qMicqKyr/2wBDAQcICAoJChQLCxQqHBgcKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKir/wAARCAFwAl0DASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3exgvb+KadtXu4v8ASZ41SNIdqqkrKAMxk9FHU1Z/sy7/AOg5f/8AfFv/APGqND/5B8v/AF+XX/pRJWjQBnf2Zd/9By//AO+Lf/41R/Zl3/0HL/8A74t//jVaNFAGd/Zl3/0HL/8A74t//jVH9mXf/Qcv/wDvi3/+NVo0UAZ39mXf/Qcv/wDvi3/+NUf2Zd/9By//AO+Lf/41WjRQBnf2Zd/9By//AO+Lf/41R/Zl3/0HL/8A74t//jVaNFAGd/Zl3/0HL/8A74t//jVH9mXf/Qcv/wDvi3/+NVo0UAZp0q5Lh/7bv9wBAOyDof8Atl7Uv9mXf/Qcv/8Avi3/APjVaNFAGd/Zl3/0HL//AL4t/wD41R/Zl3/0HL//AL4t/wD41WjRQBnf2Zd/9By//wC+Lf8A+NUf2Zd/9By//wC+Lf8A+NVo0UAZ39mXf/Qcv/8Avi3/APjVH9mXf/Qcv/8Avi3/APjVaNFAGd/Zl3/0HL//AL4t/wD41R/Zl3/0HL//AL4t/wD41WjRQBnf2Zd/9By//wC+Lf8A+NUf2Zd/9By//wC+Lf8A+NVo0UAZr6VcujI2t35VhgjZB0/79Uv9mXf/AEHL/wD74t//AI1WgzKilnIUDqScYpaAM7+zLv8A6Dl//wB8W/8A8ao/sy7/AOg5f/8AfFv/APGq0N679m4bsZ255x60tAGd/Zl3/wBBy/8A++Lf/wCNUf2Zd/8AQcv/APvi3/8AjVaNFAGd/Zl3/wBBy/8A++Lf/wCNUf2Zd/8AQcv/APvi3/8AjVaNFAGd/Zl3/wBBy/8A++Lf/wCNUf2Zd/8AQcv/APvi3/8AjVaNFAGd/Zl3/wBBy/8A++Lf/wCNUf2Zd/8AQcv/APvi3/8AjVaNFAGd/Zl3/wBBy/8A++Lf/wCNUf2Zd/8AQcv/APvi3/8AjVaNNaREIDuqkgkZOOB1oAof2Zd/9By//wC+Lf8A+NUf2Zd/9By//wC+Lf8A+NVoAhlBUggjII70tAGd/Zl3/wBBy/8A++Lf/wCNUf2Zd/8AQcv/APvi3/8AjVaDMqKWchVAySTgCl69KAM7+zLv/oOX/wD3xb//ABqkfSrl0ZG1u/KsMEbIOn/fqtKigDO/sy7/AOg5f/8AfFv/APGqP7Mu/wDoOX//AHxb/wDxqtGigDO/sy7/AOg5f/8AfFv/APGqP7Mu/wDoOX//AHxb/wDxqtAMpYgEEr1APSloAzv7Mu/+g5f/APfFv/8AGqP7Mu/+g5f/APfFv/8AGq0aKAM7+zLv/oOX/wD3xb//ABqj+zLv/oOX/wD3xb//ABqtGkZ1XG5gNxwMnqfSgDP/ALMu/wDoOX//AHxb/wDxqj+zLv8A6Dl//wB8W/8A8arRooAzv7Mu/wDoOX//AHxb/wDxqj+zLv8A6Dl//wB8W/8A8arRooAzv7Mu/wDoOX//AHxb/wDxqj+zLv8A6Dl//wB8W/8A8arRooAzv7Mu/wDoOX//AHxb/wDxqj+zLv8A6Dl//wB8W/8A8arRooAzRpVyHL/23f7iACdkHQf9svel/sy7/wCg5f8A/fFv/wDGq0aKAM7+zLv/AKDl/wD98W//AMao/sy7/wCg5f8A/fFv/wDGq0aKAM7+zLv/AKDl/wD98W//AMao/sy7/wCg5f8A/fFv/wDGq0aKAM7+zLv/AKDl/wD98W//AMao/sy7/wCg5f8A/fFv/wDGq0aKAM7+zLv/AKDl/wD98W//AMao/sy7/wCg5f8A/fFv/wDGq0aKAM7+zLv/AKDl/wD98W//AMao/sy7/wCg5f8A/fFv/wDGq0aKAM7+zLv/AKDl/wD98W//AMao/sy7/wCg5f8A/fFv/wDGq0aKAM1dKuUGF1u/AyT9yDqTn/nlT9Flmm04m5maaRLieLzGABYJK6jO0AZwB0FX6ztD/wCQfL/1+XX/AKUSUAGh/wDIPl/6/Lr/ANKJK0azdBGNNkBJP+mXXJ7/AL+StKgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArzd7iyfxNrS/EDUNQsjHdkabGbqa2tGtti7WRoyqu5O7duJYHsBjPoV3A11aSQpcS2zOuBNDjenuMgjP1BrkdEtZNd/tH7N4m8QR/YL6Wyk8xrb5nTGSMRdOaADwPNctretQ2M2oXPhuNYPsE+oNI7GUhvNWN5PneMDyyGYkbiwBIGBBe+IbfRfjFdJrGpCzsH0G3MSzylYjL9on3EA8bsBc98Yrft/Dt1BcxSt4l1mZY3DGKRoNr4OdpxEDg9OCKu6pb6pcJGNI1CCyZSd5mtTNuHbHzrj9aAOS8b+JdF1nwBrdvpWqWt3MttvaOGQMQu9RnHpkj866bxHK8elhYjqayPIFU6ZGry56/wAQKgcdTge9cx41t/EVl4M1G4vtW02+t44wZLZtMZBINw4yJsitnxx/ZNj4euda1uK8li0+IsEtLqSFmyQAPldRycDLcD2GaAONXwf4yPif/hKW1HUVX7L9jGm/abf7Z5Wd+4ybPK3buPL6Y58ztXoHhyV5NLKynU2kSQqx1ONUlz1/hAUjnqMj3rkf+EW1jyRP/YNr6mD/AISq+3Af72zGf07Z710PgkaTeeH7bWtEivIotQiV9l3dSTMuCRj5nYDBzyvB9TxQBF8StVvdD+GevanpU5t7y1tGkhlABKMO+CCK6isTxTdeHRpT6b4ruLaOzv0aNoriTYJVGNw6g9x+decy3XhEfEy1iTXZv7FOkTNKRrFx5f2gTRBMt5n3thfjPTNAHsNcH4fj1TxHrPig3PiLU7WOw1l7O3htvJCpGIYXA+aMknLtzmtzRdb8NRabNFpGrQTW1mhllY3TTGNc5JZmJOPqa5lLjwhbahqF1pvjuawOo3Ju7iKC6h2GQqqkjdGSOEUde1AHaaXpM2nSSNNrGoagHAAW7MZC+42Iv61pVx+ja/4ftr4KPGz6nJNiOOG5nhI3E8YCIpz2rrLiIz20sSyyQtIhUSx43JkY3DIIyOvINAHE+JdR1HxrpNxoPgs3Nr9pHlz65JFJFFar1PlE7Wlc9Bs+UcksCMHY0nxSzzwaZ4hsptN1hhtKeU728zDqYpgNrA4JAJDAdVFc98QLPVvDXw+1rWdN8Vax9qsrVpYvM8hl3D1Hlc10sfhq6jlRz4o1pwrAlGaDDexxF0oAyJdPbxZ441u11G8vobDSoYILaGzvJbf97Ihd5SY2BY4KBc8DB45rzmXxHceIYtEOofaJLy00HX7ae5lgKLcNH5ce9WxtYny8nb0JxxXqd9oWs2fii81nwzPYg6jbxw3cF6r7VePcEmUr1O1ipU4yFX5hjniPFuix+Hbjw/pUMrTi38N64GmcANK5jhZ3IHALMSfxoA9G8H/8iNoX/YOt/wD0WtYZl1HU/itqemf2xe2ljY6baXEcFsIwrO8kwbcWQnkIo4Irc8H/APIjaF/2Drf/ANFrWZNoeuWnxAvte0pdPngvbG3tXjuZnjZDE8jEjajA58z26UAcVdS6jq/wG8T63qmsXl1LLaapD9ncRiJVSaWNcAIDkKg6n1r0e91CK28E3d6m24W2095GRJdu7bGTt3DkdOo5FcBruh694Z+CviXSbtdNmsUs9Rm+0RTyebiVpZQNhTHBcD73bPtXXX9gmi+CZZtDSw023htWuLqJdPWRZ1EeSNoZBkgYyaAOcs9FuryxguVtdNQTRrIFbxPfZGRnHT3rrPA2lXujeGVs9SvkvpxcTyeYlw8wRHkZlTe/zHapC8+lYVn4Ga9sYLqMeG1WeNZFDeG0yARn/nr710fh/RL7RS0Ul1pxsyCRb2Wmi1AckfNw5B4GOnpzxQBrXd3b2FnNd308dvbQIZJZpWCqigZJJPQAV554T8W6lJNqcN7b/ZLnWL1r3QF1SRoo7m2baAgOGKuAjP5eM4dePvEd7qWk2Gs26QaraRXcMcqzLHMu5d6nKnB4ODzXKaNf6/420/8AtW0utK0+w+0SLbW01i11KrRSMm52MiBWyudoXK/3jQBL4Oe+Pi7xc2rx20Nx9otty20rOgH2dccsqn9KWTUtT0zxfqtzFZSanYXUVuLfyr6FRGyhg/yu4xnI6dcVL4Tu2u9a8R2OqW1k2pW00KXlzZ7vKug0QKZRixRgvBTJ4wcnNYzaPa6z4s1XSNF0Tw5psGkGJJprrSknlnaSMSDYgKBUAYDcd2SGGBjNAHT6f4kuLu8WK70iSxiIJM8t5buo49EkJ/St6vPLPSbHTvGtr4d13QvDl+L+0mura5s9KWFoxEyBlkQlxg+YMMCOhGO9eh0AcB4R8WCCz1WG9t9Yu5Itb1FBJFYzTqFF3KFUOFIwBgYHTGO1c5pV1cXvw7+E1zeTyXE8urwNJLK5ZnP2a55JPJNdjo+leKfD8d9bWcGj3ME+o3d5G8t1KjBZp3lAIEZGRvx17Vz1zoE/hbw18MtDu5Y5prHXIYXkiztYi2ueRnmgD0PVrB76BQmqXemiMlmktWQFh6HerDFc34h0i+07w3ql5a+LdZ+0W1lLPGGa3PKoSDjyumRVf4r67pcPw98R6TJfQLqE2mTLFal/3jlkO0BepzXOX2t6DqvjS5hbXba2trvwm1gbwMCsUjSEY54LAHODQB6d4fluZ/DOlzXz77qSziaZuPmcoCx4465rQrN0C90280eFdHvor23tlW382Ngwyqjg474IP41pUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFZ2h/8g+X/AK/Lr/0okrRrK0WNmsZSJpFH2y64AXA/fyeooAk0P/kHy/8AX5df+lElaNZ2h/8AIPl/6/Lr/wBKJK0aACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACuffwPoLXVzcLb3EUl1M083kX08QeRurFVcDJ+ldBRQBmaZ4f0/R5nlsRch3XafOvJphjOejsQPrWnRRQBX1DT7XVLCWy1CETW0w2yRkkBh17VJPBDdW8kFzEk0MqlJI5FDK6kYIIPBBHapKKAOcPgDw0YjCdOJtiNptTcymArjG3yt2zHtjFdBDDFbQRwW8aRRRqESONQqoo4AAHQU+igAooooAKKKKACiiigCpqml2WtaVcabqkC3FncoY5omJAdT245q3RRQAVVvdNstRjZL61inDRPDl1+YI4w6g9QCAM49BVqigCK1tYbKzhtbVBHBBGscaD+FVGAPyFS0UUAVtR0601fTLnT9RhWe0uo2imiYkB0IwRx7U6ezt7nT5LGeIPbSxGF4yThkIwR+VT0UAc6ngXQo41SOO+RFACqup3IAHoP3la+m6ZbaTa/Z7ISiPcW/ezvKcn/ack/hmrdFABWHc+DdBur2a8ax8m4nbfNJazSW5mb1fy2XceOpzW5RQBT0vSNP0Sy+yaTZw2cG4uUhQKGY9WPqT3J5NVtT8M6Pq92l3fWSm6RPLW5idopQuc7fMQhsZ7ZxWrRQBmaX4d0nRZpZtOskinmULLcMS8sgHQM7EsQMngnvWnRRQAVUvtLstSks5L6BZmsrgXNuSSPLkCsoYY9nYfjVuigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACs7Q/+QfL/ANfl1/6USVo1naH/AMg+X/r8uv8A0okoATQTnTZCQR/pl1we37+StKs7Q/8AkHy/9fl1/wClElZniqEX2qeH9OneUWl1eyefFHIyeaFt5GCsVIJG4A474GaAOkornPC7m10fU7d7qTyLC9uIoZLiQyGKMHcAWY5IXOBk9AB2rkPB8OoPqukR6vZ3FpBqWkTrcyzX7y/2nJmMh9h/1Z27352sA+3HBAAPUqK84uvC51Gz8VL4WQwM0S6dag3LqjyKd0r7snHzMEzjIMbetbvhELYarqmjTWFvZ3lukFwxtZ5JUlik8wIfnGVIaOQEc9Ae+AAdVRRWc+rP9ruILbTLu5+zuI3eNogu4qrYG5wejDtQBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtH9p3f/AEA7/wD77t//AI7QBo0Vnf2nd/8AQDv/APvu3/8AjtaNABRRRQAUUUUAFZWiystjKBBIw+2XXIK4P7+T1NatZ2h/8g+X/r8uv/SiSgA0P/kHy/8AX5df+lElO1bRrXWYoVuTNHJby+bBPBKY5In2lcqw9VZgR0IJpuh/8g+X/r8uv/SiStGgDNsNBs9NtIra0MwiRpHcPKXM7Pks0hbJYkknn+XFVdK8IaZo93BPbNdyG1iaC1juLp5UtozjKorHA4UDJyQBgHBIrcooAzotDsodDbSUWRbZw24rKyyMzMWZ96kEMWJbcMHJzRpOiW2j+e8MlxcT3DAzXFzMZJHwMKMnoAOgGByT1JJ0aKACs7TP+QhrH/X4v/pPFWjWdpn/ACENY/6/F/8ASeKgDRooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArO0P8A5B8v/X5df+lElaNZ2h/8g+X/AK/Lr/0okoATQQF02QKAALy6AA7fv5K0qztD/wCQfL/1+XX/AKUSVo0AFFFFABRRRQAVnaZ/yENY/wCvxf8A0nirRrO0z/kIax/1+L/6TxUAaNFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFZWi28L2MrPDGzG8uskqCf9fJWrWdof/IPl/wCvy6/9KJKADQ/+QfL/ANfl1/6USVo1m6Dn+zZNxBP2y6yQMf8ALeStKgAorH1nXzpd7aWNrp11qd9dpJLHb2zRqRHHtDuWkZQADIg65yw4xkh8fiPT28KyeIJWkgsYbeSecyJh4VjB8wMozyu1gQM8igDVornrTxRcXT3Fu/h/ULW/jgW4is55IN00ZOMhlkKgg9QSPxqxoevzavfahaXOk3OnyWJjVzNJE4ZnUttBRmwQNpIOOHX1oA2aztM/5CGsf9fi/wDpPFWjWdpn/IQ1j/r8X/0nioA0aKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAoopks0cETSTyLHGvJd2AA/E0BuPorl9Q8eadBL5GmRy6lcnhUhU7Sfr3/AABqn9k8XeIf+Py4TR7Vv+WcX3yPwOfzI+lcksVC/LTXM/L/AD2O2ODmlzVWoLz/AMtzodU8RaXo6n7ddosgHESnc5/Af1q1p2oW+qafFeWbFoZRlcjBHOCD+IrG07wPo1ipMsBvJWHzSXB3fp0/rWf4LkfStW1Lw7cMSYJDLAT3U4/oVP4mpVWtGpFVUkpfmXKjQlSk6Lbcddeq8l5HZUUUV2nnhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABWdof/IPl/6/Lr/0okrRrK0VZjYy7JIwv2y6wChJ/wBfJ70ASaH/AMg+X/r8uv8A0okrRrO0P/kHy/8AX5df+lElaNAHM68J7DxjpOt/Y7m6s7ewvLSUWsRlkR5ZLd0OwckfuWBI6EjPHNUre11SD4b3OnQ2DLq17a3s8NvOgdEeR2dY5G5QH94Bgkg4bqAa7OigDgfCGkWuk6/Pd6NpOqWlgumJDcNqXmPM0kbZjRPMLMQFMmdp2klcZOa6bwtZ3Froazaghjv76Rru6UnJSSQ52Z77F2oD6IK2KKACsO202C81XV5JXulYXariG7liH+oi7KwGeetblZ2mf8hDWP8Ar8X/ANJ4qAD+w7T/AJ7X/wD4Mbj/AOLo/sO0/wCe1/8A+DG4/wDi60aKAM7+w7T/AJ7X/wD4Mbj/AOLo/sO0/wCe1/8A+DG4/wDi60aKAM7+w7T/AJ7X/wD4Mbj/AOLo/sO0/wCe1/8A+DG4/wDi60aKAM7+w7T/AJ7X/wD4Mbj/AOLo/sO0/wCe1/8A+DG4/wDi60aKAM7+w7T/AJ7X/wD4Mbj/AOLo/sO0/wCe1/8A+DG4/wDi60aKAM7+w7T/AJ7X/wD4Mbj/AOLo/sO0/wCe1/8A+DG4/wDi60aKAM7+w7T/AJ7X/wD4Mbj/AOLpG0WzRSzz3yqBkk6jOAB/33Uet+JNP0GHN3LumIykCcu3+A9zXOLYa74zYSamzaZpZOVgX78g9/X6nj0Fc1TEKMuSC5pdv8+x2UsK5R9pUfLHu/0XUZfa9py332XRLbVdWdQS5h1G4wPphjn69Ki/4SSwh/4/tM1639f9PnOPzcV2umaTZaPaiDT4FiT+I9WY+pPerlQqeIernZ9raf5lurhVoqd13u7/AORwkXijwvJjfPq8X+/eXH9JDV6LVvCk33NYux/v310v82rppbK1uP8AX20Mv+/GD/OqU3hjRJ/v6Xaj/cjC/wAsU+XFLaSfya/UXNg5bxkvmn+hUhHh+f8A1OsSOfQavLn8vMq4mj2Mq7o7i9ceq6lOf/Z6oTeA/D8vSzaM+qSv/U1Sf4b6Tu3W9zeQt7SKf6Zo58St4p+j/wCAHs8JLabXqv8AJm9/Ydp/z2v/APwY3H/xdZ2pvoOkKft+o3kb44jGo3DOf+Ah81QPga9jyLXxNexKeCPmOfyYVf0zwRpGnsJJojez9TJcfMM/7vT880vaYiWihbzb/wAh+ywsNZVHLySt+f8AwTnTf32tsU8MafqQizj7VcahOAP/ACJj9T9K0LTwHPdBH8SatcXpXpEJWZR/wJufyArs1UKoVQAAMAAdKWj6qpa1pc34L7hfXHDShFR89397/SxjW3hPSLLd9ihuLfd97ybyZM/k9WP7DtP+e1//AODG4/8Ai60aK64xUVZI45SlJ3k7szv7DtP+e1//AODG4/8Ai65PxdpceiahYaxbNdGISCK5P2qUuR7OW3DjI6+ld7VHWtNXV9FubJ8ZlQ7CezDlT+YFYYim6lNpb7r1RvhaqpVU5bPR+j3Ik0ayljWSOe+ZGAZSNRn5B/4HTv7DtP8Antf/APgxuP8A4usrwJqTXeg/Y7jIuLF/JdT1C/w/1H4V01XSqKrTU11Ir0nRqSpvoZ39h2n/AD2v/wDwY3H/AMXR/Ydp/wA9r/8A8GNx/wDF1o0VqYmd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAGd/Ydp/wA9r/8A8GNx/wDF0f2Haf8APa//APBjcf8AxdaNFAFCPRraKVJFlvSyMGAa/nYceoL4I9jV+iigAooooAKKKKACs7Q/+QfL/wBfl1/6USVo1naH/wAg+X/r8uv/AEokoATQTu02QjPN5dHkY/5byVpVnaH/AMg+X/r8uv8A0okrRoAKKKKACiiigArO0z/kIax/1+L/AOk8VaNZ2mf8hDWP+vxf/SeKgDRooooAKKKKACiiigAooooAKKKwdd8XWOinyEzdXp4W3iOSD/tHt9OvtWdSpCnHmm7I0pUp1ZcsFdm1PPFbQNNcSJFEgyzucAfjXIXfiq/1y5aw8I27N2e8kGFUeoz0/Hn0FMg8Pav4nnW78UzNb2wOY7KM4x9fT9T9K7C0s7awtlt7OFIYl6Kgx/k+9c16tfb3Y/i/8vzO21DDb+/P/wAlX+f5GDong2106b7ZqDm/v2O5pZeQp9ge/uf0rpKKK6adKFKPLBWOOrWqVpc03cKKKK0MgooooAKKKKACiiigAooooAKKKKACiiigDipf+Kd+I6SfdtNWXB9BJn/4rH/fVdrXOeONLOoeHZJYR+/sz5yEdcD736c/gK0fD+pjWNCtrzI3umJAOzjg/rXHR/d1ZUuj1X6/id9f97QhW6r3X8tvw/I0qKKK7DgCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKytFnVLGVSJMi8uukbEf6+TuBWrWdof/IPl/6/Lr/0okoAND/5B8v/AF+XX/pRJWjWdof/ACD5f+vy6/8ASiStGgAooooAKKKKACs7TP8AkIax/wBfi/8ApPFWjWdpn/IQ1j/r8X/0nioA0aKKKAOb1bw/rN7qUlxZeIJrWF8bYQpwnGOx/Gqf/CO+Kk/1fiTOPu7lPP1612FFcssLTk29fvf+Z2RxlWMVHSy8l/kcf/ZHjZOY9dtWPo6DH/oBo+x+O4+P7SsZffaP/iBXYUUvqsekpfeyvrsusI/+Ao4//iu0/wCfGTb9Pm/lR9s8dx8/2bYy+24f/Fiuwoo+rP8Anl9//AD64utOP3f8E4qZ/HGqYs5La301HPz3ETDIH1DMfy5ra0LwpYaEPMRfPuz964kHzfh6Vt0VUMNGMueTcn59CamLnKHJFKK6pdfUKKKK6TjCiiigAooooAKKKx9d8WaH4bjLazqMNu2MiLO6Rvog5/Smk27IUpKKu2bFMmnitoWmuJEiiQZZ3YKqj3JrzST4k6/4mdoPAHh2aVM7ft94MIv4Z2/mx+lEPwu1XxBMt14/8RT3pzuFpattjU/XGB+Cj61t7Ll+N2/M5/b838NX/BGhrnxf0DTpfs2kCXWrwnCx2g+Qn/fxz/wEGqP/AAs/xLP/AMeXw81Ng33XcyY9/wDlnj9a7jRfDOjeHYfL0bToLXjBdVy7fVjyfxNalHNSW0b+rDkrPVzt6L/M8z/4Tb4hXH/Hr4G8vd93znPH1yVo/tv4t3P+q8NaXbo3RnkXI+v73+lemUUvax6RQexk95v8P8jzPHxeuf4tJtN3P8J2/wDoVH9hfFm5/wBd4n0yBTztjjGV/KL+temUUe2f8q+4Pq66yf3nmL+B/iFcIftHjkoxBOIgy8+mRjitT4WeI7zVtFutK1uR21bSZjDOZWy7Lk4JPcggr+A9a7qvK/FinwL8UNP8Uw/Jp2qH7NfgdFbj5j+ADfVD61cZe1Tg9+hEoKg1NN266nqbKGUqwBBGCD3rjPCjHQ/E+peH5TiJm862z3Hp/wB84/75NdoCGAIOQeQR3rjvHEElhdaf4gtV/eWkgSXHdCePw6j/AIFXlYr3Uqy+z+XU9vBtTcqD+2vxW3+XzOxoqO3njuraOeFt0cqB0PqCMipK7E76nC007MKKKKBBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVnaH/yD5f8Ar8uv/SiStGs7Q/8AkHy/9fl1/wClElACaCNumyAZ4vLocnP/AC3krO8VJJeahoWmfarq3tr28dbj7JO0EkirBI4XzEIZRuVT8pB4xnGQdLQ/+QfL/wBfl1/6USUmtaJHrMdsftdzY3NpL51vdWrKJImKsh4dWVgVZhhlI5zjIBABQ8LyzxaRqFvPeSTiwvJ4Ip7p9zCNTld7HltoOMnkgDJJyTxXhTXb7Tryy1DXP7Ys7R9Gnu9QudSvPOgvZI/LbzYEyfKAXzG27YvlYfIcfL6Bp3h6HTbGO0iurmWMvLJc+cUc3jSZLGQlfU5AXaBgDG0YrMtvAOnpD9m1C+1DVLJLSSygtL2VCkEMihGUFVVm+UbdzszYzzyaAOfS/wBe1nwbren/AGLV9N8T30TXsNtcXKxEIzBVWF0kIQKoVTyrbiWKgvW/4OH2K81HSrq2urXUIFinkjm1m41FGik3iNkkm5GTG4IAHK9+DVmy8Ix232iS61jVdQuZYPs8d1cTIstvHnO1DGi9wCWILHAyTirujaEukNcTS313qV5c7RNeXhTzHVc7VxGqqAMnACjqSck0AalYdteT2+q6ukWnXV0pu1O+FogB+4i4+Z1Ofw71uVnaZ/yENY/6/F/9J4qAD+07v/oB3/8A33b/APx2j+07v/oB3/8A33b/APx2tGigDO/tO7/6Ad//AN92/wD8do/tO7/6Ad//AN92/wD8drRooAzv7Tu/+gHf/wDfdv8A/HaP7Tu/+gHf/wDfdv8A/Ha0aKAM7+07v/oB3/8A33b/APx2j+07v/oB3/8A33b/APx2rd3d29javc3s8dvBGMvLK4VVHuTXnep/FOfVL1tL+Hulyatd9DdOhEUfvjjj3YgfWrhTlPYzqVYU/iZ3P9p3f/QDv/8Avu3/APjtH9p3f/QDv/8Avu3/APjteew/CW98RSG/8f67dXN44+WK0ZQsI9MlSPwAA9zU/wDwojwx/wA/2rf9/ov/AI3WnJTW8vwMvaVnqofid3/ad3/0A7//AL7t/wD47R/ad3/0A7//AL7t/wD47XCf8KI8Mf8AP9q3/f6L/wCN0f8ACiPDH/P9q3/f6L/43S5aX834f8EOet/J+P8AwDu/7Tu/+gHf/wDfdv8A/HaP7Tu/+gHf/wDfdv8A/Ha4T/hRHhj/AJ/tW/7/AEX/AMbo/wCFEeGP+f7Vv+/0X/xujlpfzfh/wQ5638n4/wDAO4l1ieCJpZ9HvY40GWd5bcBR6kmWuP1H4y6JazNa2Nje395nCRQeWysfTerNn8M1AnwJ8Lq6s15qrgHJVpo8H24jzXbaJ4Y0Xw7D5ejadBa8YLquXb6seT+dP91Hu/wC9eWllH8Tzq7l+KHivGLR9A06TqsDIJ8e+51bP/fNaGhfDjR9KkFxf+H9T1e8J3NLeyW7KT67PNx+ea9KopOtK1o6LyHHDwveWr8zMjv7iKNY4tAvURRhVVrcAD0A82nf2nd/9AO//wC+7f8A+O1o0VidBnf2nd/9AO//AO+7f/47R/ad3/0A7/8A77t//jtaNFAGd/ad3/0A7/8A77t//jtH9p3f/QDv/wDvu3/+O1o0UAZ39p3f/QDv/wDvu3/+O0f2nd/9AO//AO+7f/47WjRQBnf2nd/9AO//AO+7f/47WJ4vsJvFXhe70uTQ71XkXdC7PB8kg5U/6314PsTXWUU02ndEyipJxZ538MvFt1f+GBptxp93c3+lH7PPsaIEAZCZDuDnAx/wGup1OWfU9MuLObQ7/bMhXO+34PY/63scGuF1/HgL4t2murmPStcBhvMfdSTjLH8drf8AfVeq1pXhGWvSX9Myw05R92+sf6TOK8GazdRabJpUun3NxcWMhRhG0Y2rk8Hc46HI4z2rpP7Tu/8AoB3/AP33b/8Ax2ub1T/infiBa6iPltdSXypvQNwM/wDoJ/Ou1rz8K2ounLeOny6fgerjYpzVaO01f59fxM7+07v/AKAd/wD992//AMdo/tO7/wCgHf8A/fdv/wDHa0aK6zhM7+07v/oB3/8A33b/APx2j+07v/oB3/8A33b/APx2tGigDO/tO7/6Ad//AN92/wD8do/tO7/6Ad//AN92/wD8drRooAzv7Tu/+gHf/wDfdv8A/HaP7Tu/+gHf/wDfdv8A/Ha0aKAM7+07v/oB3/8A33b/APx2j+07v/oB3/8A33b/APx2tGigDO/tO7/6Ad//AN92/wD8do/tO7/6Ad//AN92/wD8drRooAzv7Tu/+gHf/wDfdv8A/HaP7Tu/+gHf/wDfdv8A/Ha0aKAM7+07v/oB3/8A33b/APx2j+07v/oB3/8A33b/APx2tGigDO/tO7/6Ad//AN92/wD8do/tO7/6Ad//AN92/wD8drRooAzv7Tu/+gHf/wDfdv8A/HaP7Tu/+gHf/wDfdv8A/Ha0aKAM7+07v/oB3/8A33b/APx2j+07v/oB3/8A33b/APx2tGigDO/tO7/6Ad//AN92/wD8do/tO7/6Ad//AN92/wD8drRooAzv7Tu/+gHf/wDfdv8A/HaP7Tu/+gHf/wDfdv8A/Ha0aKAM7+07v/oB3/8A33b/APx2j+07v/oB3/8A33b/APx2tGigChHqNy8qI2j3saswBdngwvucSE4+gNX6KKACiiigAooooAKytFgV7GViZMm8uukjAf6+TsDWrWdof/IPl/6/Lr/0okoAND/5B8v/AF+XX/pRJWjWboOf7Nk3AA/bLrIBz/y3krSoAKKKKACiiigArO0z/kIax/1+L/6TxVo1naZ/yENY/wCvxf8A0nioA0aKKKACigkKCScAckntXBeIvitpenXH9n+H4n13U2O1IrXJQN7sM5+i5+oq4wlN2iiJ1I01eTO7lljgiaWZ1jjQbmdzgKPUmvPdb+LFubw6X4LspNd1FsgNGp8pffI5YfTA96z4vBHivxzKt1491JrGxzuTTLQgfTPUD6ncfpXoWieHtK8O2f2XRrKK1j/iKjLP7sx5J+taWpw31f4GHNVq/D7q/H7jgbT4c654quk1D4jarJIoO5NNtmwiexI4H4ZP+1Xoml6TYaLZLaaVaRWkC9EiXGT6n1PueauUVE6kp6PY1p0YU9Vv36hRRRWZqFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc9468Nr4p8IXmnBQbjb5tsT2lXkfnyPoTWb8LvEh1/wfFDdEi/00i1uFb73A+Vj9QMfUGuzryq/P/CAfGGK/wDuaR4i+SbsscuRk/8AfRBz6O3pW9P34OHzRy1f3c1U6bP9DuPGOlf2r4buERczQ/vovqvUfiMipfCuq/2x4dtrhm3SqPLl/wB5e/4jB/GtiuK0H/in/G99ozfLbXn762HYHrgfhkf8BrzKn7uvGfSWj/T/ACPZpfvsNKn1j7y9Ov8AmdrRRRXYcAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRXN3/xC8K6Zfy2V9rMMVxC22RNrNtPpkAjNVx8UPBpOP7dh/wC/cn/xNX7Ob6My9tTWjkvvOsoryvxBqGoS67q2o2Ivbq2tbmzNvqdvqLR2thEVjaRZIQ37zAZnJCPlZFBI2/L6pUGoVnaH/wAg+X/r8uv/AEokrRrK0VphYy7I4yv2y6wS5B/18ntQBJof/IPl/wCvy6/9KJK0aztD/wCQfL/1+XX/AKUSVo0AFFFFABRRRQAVnaZ/yENY/wCvxf8A0nirRrO0z/kIax/1+L/6TxUAaNFFFAHB+KvBfiDxbrzxXevLZ+HMLttbYESOcDcG4wec4JJA44rovDvhHRfC1t5Wj2SRMRh5m+aR/qx5/Dp7VtUVo6knHl6GUaUFLn6hRRRWZqFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVy/xD8M/wDCVeDrmziXN3D+/tv+uig8fiCR+NdRRVRk4tNEzipxcX1OS+GviY+J/B0EtwxN7aH7Pc56llHDfiMH65pPHlpJFb2mt2gxPYSgk+qk9/xx+ZrmB/xb/wCMe0fJo/iTt0WObP8ARj+Ak9q9PvLWO+sprWcZjmQo30IqMZRVSDUeuq/ryZWX4h0ppy3i7PzX/BQlldx39hBdwHMcyB19sjpU9ch4DupLeO90K7P76wlO0eqk849s8/8AAhXX1lQqe1pqX9X6nRiaXsarh06enQKKKK2OcKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAMW78HeHL+7kurzRLGaeU7nkeBSWPqT61D/AMIH4U/6F7Tv/Ada6Ciq55dyPZw7I5278E6Xd3Nw3mXUFteMjXdlBLtguSqqo3LjI+VFUhSAQoBzXRVj32tz2XibTNM/s9ngvi6m8MqhVYI77QvJJwnOcAblwTyBONWMviRtKt4PMWG3865n34ERY4jTGOSwDk8jAUf3hUlmjWdof/IPl/6/Lr/0okrRrO0P/kHy/wDX5df+lElACaCQ2myFSCDeXRBHf9/JWlWdof8AyD5f+vy6/wDSiStGgDI1rxAukXFtaw6feane3SSSRWln5e8om0O+ZHRQAXQct1YYzUkXiHTpPDT680xisI4HnleRCDEqA79y9QV2kEeoNZXiGV9L8Y6Rrk1reT2MFheWkps7WS4dHlktnT93GCxBELjIHBxnrVKGC/g+G11pqaez6pfWt9PBaTwF4yXd3WORsbAxEqjax5+bGQCQAbmj+I11S+msrjTL/S7qOMTLFerGDLETgOpR2GMjBBIYdwM1c0jVYda01L+0SRbeVm8ppAB5qBiBIuCflYDcp7gg4FeZx6KwtNXTwra+Imt5dJS0upNT+0C5ysgykDXGGz5bS/dOzds285rq/BEbwz38WnpqkegJHAtimrCcTLKN/mgCf94I8eVjd33Y4xQB11Z2mf8AIQ1j/r8X/wBJ4q0aw7bTYLzVdXkle6VhdquIbuWIf6iLsrAZ560AblFZ39h2n/Pa/wD/AAY3H/xdH9h2n/Pa/wD/AAY3H/xdAGjRWd/Ydp/z2v8A/wAGNx/8XR/Ydp/z2v8A/wAGNx/8XQBo0Vnf2Haf89r/AP8ABjcf/F0f2Haf89r/AP8ABjcf/F0AaNFZ39h2n/Pa/wD/AAY3H/xdH9h2n/Pa/wD/AAY3H/xdAGjRWd/Ydp/z2v8A/wAGNx/8XR/Ydp/z2v8A/wAGNx/8XQBo0Vnf2Haf89r/AP8ABjcf/F0f2Haf89r/AP8ABjcf/F0AaNFZ39h2n/Pa/wD/AAY3H/xdH9h2n/Pa/wD/AAY3H/xdAGjRWd/Ydp/z2v8A/wAGNx/8XR/Ydp/z2v8A/wAGNx/8XQBo0Vnf2Haf89r/AP8ABjcf/F0f2Haf89r/AP8ABjcf/F0AaNFZ39h2n/Pa/wD/AAY3H/xdH9h2n/Pa/wD/AAY3H/xdAGjRWd/Ydp/z2v8A/wAGNx/8XR/Ydp/z2v8A/wAGNx/8XQBo0Vnf2Haf89r/AP8ABjcf/F0f2Haf89r/AP8ABjcf/F0AaNFZ39h2n/Pa/wD/AAY3H/xdH9h2n/Pa/wD/AAY3H/xdAGjRWd/Ydp/z2v8A/wAGNx/8XR/Ydp/z2v8A/wAGNx/8XQBo0Vnf2Haf89r/AP8ABjcf/F0f2Haf89r/AP8ABjcf/F0AYXxL8M/8JL4NuFgUm9s/9Jtio5LKOVH1GR9cVP8AD3xN/wAJT4NtLyVw13EPIuR38xe/4jDfjWt/Ydp/z2v/APwY3H/xdeY2unQeCfi62lyvcw6Nri7rby7qSMLL2BKsCfmyvOfvLW8Pfg4dVqv1OWp+7qKfR6P9DqvEX/Eg8aWGtr8tvdfubk9vTJ/DB/4DXa1zuv8Aha3vtEuI4GunnVd8QlvJZBuHThmI56dO9c1o3iXRE0mFNVn1NbpBtfZeT7TjoRh8DjtXkqccPWlGbspar16/5nuunPFUIygryjo/Tp/kej0VxS+IvCjYzqGprn1u7rj8mqVdb8JOcDV778by7H82rdYmg/tr70czweJX/Lt/czsKK5RdT8LOMjWbn8dQuR/NqmW58MtjGtSc+urTD+b1arUntJfeQ8PWW8H9zOlorn1/4R5zhNZZj7azKf8A2pQ58PRKS+suMf8AUYl/+OVXtId0R7Kptyv7joKK5CbWPCkH3tWvWPpHfXTfyaqEvirw4p2w/wBtTsem29mGfzkrGWKoR3mvvN44LEy2g/uO+orz3+25bj/kH6Brc2f4jqNzj9Cf50eT4quv+PbSp4F9ZdTnyPzlH8qn65Tfw3fomX9RrL42l6tf5noVFefL4Y8XzsC2rNajuBfTN/U/zqyfB/iPy+PFFwX9POkx+eaPrE38NN/gv1D6rTXxVY/i/wBDuKK89Ph3xhaEkXzXw7D+0Jl/9mWjztftP+P7Qb+bHX7PqVz/AEkaj61FfFGS+X+Vw+pSfwTi/n/nY9Corz0eJ9MhIGpWGuWp/wCv+c4/NxV631/wrPgNqOowk9pLy5H6hyKccXQf2l+X5kywOJir8j+Wv5HaUVz1ufD11/qNXlc+n9rTA/l5mavjRbIruE98V65/tKfH/oddEZRl8LucsoSi7SVjSormry48N2GftOr3CsOqrqc7sPwVyaxZvE2jNJ5WmW+tX0nYLfTqD/4+T+lYzxNGGkpI3p4SvU1jBnf0V555HifUv+PLT7mwjP8AHcalcbh+Bk/9lpbvw/faZpcl54o8WTW1pGMyYmdwfbk8n2wahYiU9KcG/wAPzNXhYwV6tSMfxf4f5nb3mq2FgP8ATbyCD2eQAn8OtcZ4h+Is0c8Vr4UtYb2VnAaa53BD/sqo+Yn36fWuG0rRr/xzqpHhmObT9EifbJqN2A0kvrgcDPsOnc9q9W0vwRo+kQKlqLvzNoDzfbZVeQ+p2sB+AAFauOJT97lXlq3+iMIzwck+Xml56RXy3Z0NFZ39h2n/AD2v/wDwY3H/AMXR/Ydp/wA9r/8A8GNx/wDF1sYGjRVCPRraKVJFlvSyMGAa/nYceoL4I9jV+gDmNR8O65dahNPbeI5oInbKRBSAg9ODVYeFfEQP/I0z/wDfLf8AxVdhRXK8LSbu7/e/8ztjja0VZW/8BX+Riajp13NrHh2ZAZ0sp5GuJSQuAbeRA2PdmHA9a5VvCl4vi2a5h0FY9Sl1ZLw+JFki5tQ6EwH5vNyYl8rZt2dGzmvRaK6ji3CsrRbiFLGVXljVheXWQWAP+vkrVrO0P/kHy/8AX5df+lElABof/IPl/wCvy6/9KJK0aztD/wCQfL/1+XX/AKUSVo0AFFFFABRRRQAVnaZ/yENY/wCvxf8A0nirRrO0z/kIax/1+L/6TxUAaNFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFcV8U/Dba/4PkntFP2/TT9pt2X73H3lH1HP1UV2tFVCThJSRFSCnFxfU57wN4kTxT4Rs9R3Az7fKuR/dlXhvz4P0IraaytXbc9tCx9TGDXmPh7/AIoH4s3mgyfJpeufvrM9FR8nCj8dy/8AfNeq1VaCUtNnsRh6knGz3WjKbaPpj536daNnrmBTn9Khbw7orjB0myH0gUfyFaVFYOnB7pHUqtRbSf3mQ3hXQnOTpdv+C4/lUTeC/D7Zzpqc+jsP5GtyiodCk94r7kWsTXW0397OdbwH4dYcWLL9J3/qaSPwH4fjfcbNn9A0z4H610dFT9VofyL7kX9cxP8Az8f3sy4PDWi2+PK0u1yOhaIMf1rQit4YBiCKOMeiKB/KpKK1jCEfhVjCVSc/ibYUUUVZAUUUUAFFFFAAQGBBGQeoNUbjRNLus/aNOtZCe5hXP54q9RUyjGW6KjOUXeLsc9ceBfD8+SLIxE945GH6ZxWe3w20suPLu7xI8/Mm9Tn9K7GisJYShLeCOqOOxMdpswbPwVoNngixWZv707F8/geP0rahght49lvEkSf3UUKP0qSvPPFfxIkXUP8AhH/BEH9qazIShkQbo4D3PoSPyHf0roo4eKdqcUjkr4qTXNVk3+JveMPHOleDrPdev515IMw2cZ+d/c/3R7n8M1x2l+D9c8f6hHrfj93t7BTutdKQleP9odV/9CPtxW14P+G8el3n9t+J5/7V12U7zJIdyQn/AGc9SPXt2ArvK6XONPSG/f8AyORU5VXert2/zI7a2hs7aO3tYkhhjXakcahVUegAqSiiuc6gooooAKKKKACiiigAooooAKztD/5B8v8A1+XX/pRJWjWdof8AyD5f+vy6/wDSiSgBNBGNNkBJP+mXXJ7/AL+StKs7Q/8AkHy/9fl1/wClElaNABRRRQAUUUUAFZ2mf8hDWP8Ar8X/ANJ4q0aztM/5CGsf9fi/+k8VAGjRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBwvxY8Oyav4WGpWGRqGkN9phZeu0YLgfkG/4DW14Q8VWnifw5Z3yzRLcSIFmhDjKSDgjHXqMj2xW+yh1KuAykYIIyCK8+ufgn4TnZjGL633EkCKcYXPpuB6VvGUZQ5Z9NjmlCcanPTV77noVFeZ/8KUsLf/kG+INWtR2HmKcD8AO9H/CsPElvzYfEHU1H9yQOR/6M/pS5Kf8AN+Ae0q9Yfij0yivM/wDhEviXa/8AHl40glx0+0R5/mjUv2b4u2n/AC+6RfY/2VGf/HVo9kukkHt2t4P+vmel0V5n/bnxZtf9d4Z0y5UfxRyDJP8A39/pQPH/AI5gci68A3EmD/yxZun12mj2MujX3oPrEeqa+TPTKK80/wCFrazFj7b4B1eDueHPHrzGKP8AhdVjD/x/eHtXg7n92pwPXkij2FTsP61S7/mel0V5xF8cfCsmN8OpRZP8cCnH5MauxfGPwbJjffzRZP8AHbOcfkDS9jUX2WNYii/tI7qiuSh+KXgyfGzXIhn+/FIn81FWG+IvhFIvMOv2e30DEn8gM1Ps59mV7an/ADL7zpaK4W7+MXg62z5d/NckdobZ/wD2YCs4/GqwuiRo3h/Vr49BiMDP/fJarVGo+hLxNFfaPS6K8z/4T/xvff8AIL8BXEIPQ3bMM/mq0favi7qHSx0nTAehLK2P/Hno9jLq0vmT9Yi/hTfyZ6ZUF9fWumWUt5qFxHb28Q3PJI2Aorzr/hEviVf/APIR8ZwW4P8Az6R4x+SpQPg899cQv4l8Valq8cb7mikLAN7ZLMR26fp2fs4L4pfcHtaj+GH32KV94i8QfE69l0rwesmnaGp2XOpSAqZB3A+v90cnuQDiu78K+DtJ8Iaf9n0uHMrgedcuMySn3PYew4rXsbG102yitLCCO3t4l2pHGuAoqepnUuuWOiKp0bPnm7y/rYKKKKyNwooooAKKKKACiiigAooooAKKKKACsrRY2axlImkUfbLrgBcD9/J6itWs7Q/+QfL/ANfl1/6USUAGh/8AIPl/6/Lr/wBKJK0azdBOdNkJBH+mXXB7fv5KoeJzPPqGh6bFdz2sF9dutw1s5SRkWCRwoccqNyqSRg8YzyaAOhorA8MT3X9lX8FzdvctY3k8EdxckbiinK7yMZwCBnqQMnJya4XRdV8RX0MaQ/2zHdX2hXUjveyp5VzdAII3tsE7RksQPkG1lJGegB6zRXmOzXoPDeqaVDb6vD4jl0xJ7YPqxn835gr7GZsRuDjPb51wx5x1HhKXybzUdNuo76C/txFLJFdag92DG+8I6O3QEo4IwOUPXg0AdNWdpn/IQ1j/AK/F/wDSeKtGsO21KCz1XV45UumY3atmG0llH+oi7qpGeOlAG5RWd/blp/zyv/8AwXXH/wARR/blp/zyv/8AwXXH/wARQBo0Vnf25af88r//AMF1x/8AEUf25af88r//AMF1x/8AEUAaNFZ39uWn/PK//wDBdcf/ABFH9uWn/PK//wDBdcf/ABFAGjRWd/blp/zyv/8AwXXH/wARR/blp/zyv/8AwXXH/wARQBo0Vnf25af88r//AMF1x/8AEUf25af88r//AMF1x/8AEUAaNFZ39uWn/PK//wDBdcf/ABFH9uWn/PK//wDBdcf/ABFAGjRWd/blp/zyv/8AwXXH/wARR/blp/zyv/8AwXXH/wARQBo0Vnf25af88r//AMF1x/8AEUf25af88r//AMF1x/8AEUAaNFZ39uWn/PK//wDBdcf/ABFH9uWn/PK//wDBdcf/ABFAGjRWd/blp/zyv/8AwXXH/wARR/blp/zyv/8AwXXH/wARQBo0Vnf25af88r//AMF1x/8AEUf25af88r//AMF1x/8AEUAaNFZ39uWn/PK//wDBdcf/ABFH9uWn/PK//wDBdcf/ABFAGjRWd/blp/zyv/8AwXXH/wARR/blp/zyv/8AwXXH/wARQBo0Vnf25af88r//AMF1x/8AEUf25af88r//AMF1x/8AEUAaNFZ39uWn/PK//wDBdcf/ABFH9uWn/PK//wDBdcf/ABFAGjRWd/blp/zyv/8AwXXH/wARR/blp/zyv/8AwXXH/wARQBo0Vnf25af88r//AMF1x/8AEUf25af88r//AMF1x/8AEUAaNFZ39uWn/PK//wDBdcf/ABFH9uWn/PK//wDBdcf/ABFAGjRWd/blp/zyv/8AwXXH/wARR/blp/zyv/8AwXXH/wARQBo0Vnf25af88r//AMF1x/8AEUf25af88r//AMF1x/8AEUAaNFZ39uWn/PK//wDBdcf/ABFH9uWn/PK//wDBdcf/ABFAFyW2guM+fBHLkYO9AePTmqU3hzQ7jPn6Np8uRg77VDn8xS/25af88r//AMF1x/8AEUf25af88r//AMF1x/8AEU7tbCcU90UZvAnhWfO/w9pwz/ct1T+QFVl+Gvg9LjzhoNtuxjB3Ff8AvknH6Vr/ANuWn/PK/wD/AAXXH/xFH9uWn/PK/wD/AAXXH/xFV7Sfcj2VN/ZX3CWvhzRLHH2LR7C3I6GK2RT+YFaQAAAAwB0ArO/ty0/55X//AILrj/4ij+3LT/nlf/8AguuP/iKltvctJLY0aKzv7ctP+eV//wCC64/+Io/ty0/55X//AILrj/4ikM0aKzv7ctP+eV//AOC64/8AiKP7ctP+eV//AOC64/8AiKANGis7+3LT/nlf/wDguuP/AIij+3LT/nlf/wDguuP/AIigDRorO/ty0/55X/8A4Lrj/wCIo/ty0/55X/8A4Lrj/wCIoA0aKzv7ctP+eV//AOC64/8AiKP7ctP+eV//AOC64/8AiKANGis7+3LT/nlf/wDguuP/AIij+3LT/nlf/wDguuP/AIigDRoqhHrNtLKkaxXoZ2CgtYTqOfUlMAe5q/QAUUUUAFFFFABWdof/ACD5f+vy6/8ASiStGsrRZWWxlAgkYfbLrkFcH9/J6mgCTQ/+QfL/ANfl1/6USUzW9EXWFtHS8uLG6spvPt7m32lkYqyEEOGVgVZgQR3yMEAh+h/8g+X/AK/Lr/0okrRoAyNO8Ppp2nrafbLi5R3lku3uAjNdtJncXwoA5PRQAAAMY4qjp3gxLKWA3Os6lfR2du9vZxzOi/Z0YAZDIiszBQFDMScc9STXS0UAYFp4WeH7TLea5qV7eTW4to7yQxRyQIDn5diKuS3JJBzgA8DFWtG0P+y5rm6ub641G+ugiy3VwqKxRM7EARVUAbmPTOWNatFABWdpn/IQ1j/r8X/0nirRrO0z/kIax/1+L/6TxUAaNFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFZ2h/wDIPl/6/Lr/ANKJK0aztD/5B8v/AF+XX/pRJQAaH/yD5f8Ar8uv/SiStGs3QQF02QKAALy6AA7fv5K0qACiiigAooooAKztM/5CGsf9fi/+k8VaNZ2mf8hDWP8Ar8X/ANJ4qANGiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACs7Q/+QfL/wBfl1/6USVo1laLbwvYys8MbMby6ySoJ/18lAEmh/8AIPl/6/Lr/wBKJK0aztD/AOQfL/1+XX/pRJWjQAUVl6vr9po89tbzR3FxdXQdobe1haWRlTG9sDoo3KCT3ZR1IFSw65p0/h/+21ulTThAbhp5QUCIoJYsGAK4wcggEYIPSgC/RXNv460mKwvrq5iv7YWUC3MkVxZvG7xMcBlDAbuRjHUcZAyK1tM1T+01kP2G8tPLIGLuHyy2fTnmgC9Wdpn/ACENY/6/F/8ASeKtGs7TP+QhrH/X4v8A6TxUAaNFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFZ2h/8g+X/AK/Lr/0okrRrO0P/AJB8v/X5df8ApRJQAmg5/s2TcQT9suskDH/LeStKs7Q/+QfL/wBfl1/6USVo0Acrr9ymleOtF1a9SVbCPTr61knSJpAkkklq6BtoJGRE+D0yMdSAaEAmX4WXln/ZzXF7f2l/cQadcQsGmV3dwjIcEEiRQVJU8445x3NFAHlllpel3k2oxPca9relSaKkN5c3azmeMpJlY4/lVt7AuzBQWBVc4yK6bwcI/wC19XOjm5OhMsBtzcGU/wCkfP52zzOdm3yenG7f3zXW0UAQ3UElxEEiuprVg2d8IQk+3zKwx+HasXTtOuWvtVA1i9UrdqCQkHzfuIjk5j6844x0HfJroKKAM7+zLv8A6Dl//wB8W/8A8ao/sy7/AOg5f/8AfFv/APGq0aKAM7+zLv8A6Dl//wB8W/8A8ao/sy7/AOg5f/8AfFv/APGq0aKAM7+zLv8A6Dl//wB8W/8A8aqsllqLapPC2sX4gSGN0k8qD5mLOGGfKxwFXj39xW1RQBnf2Zd/9By//wC+Lf8A+NUf2Zd/9By//wC+Lf8A+NVo0UAZ39mXf/Qcv/8Avi3/APjVH9mXf/Qcv/8Avi3/APjVaNFAGd/Zl3/0HL//AL4t/wD41Va6stRiuLNIdYv3SWYpM3lQHYvlu2f9Vx8yqMn1962qKAM7+zLv/oOX/wD3xb//ABqj+zLv/oOX/wD3xb//ABqtGigDO/sy7/6Dl/8A98W//wAao/sy7/6Dl/8A98W//wAarRooAzv7Mu/+g5f/APfFv/8AGqrX1lqMFur22sX8jmaJCvlQHCtIqseIuyknPbFbVFAGd/Zl3/0HL/8A74t//jVH9mXf/Qcv/wDvi3/+NVo0UAZ39mXf/Qcv/wDvi3/+NUf2Zd/9By//AO+Lf/41WjRQBnf2Zd/9By//AO+Lf/41VTVba+sdGvbuLW70yW9u8qho4MEqpIz+76cVuUUAZ39mXf8A0HL/AP74t/8A41R/Zl3/ANBy/wD++Lf/AONVo0UAZ39mXf8A0HL/AP74t/8A41R/Zl3/ANBy/wD++Lf/AONVo0UAZ39mXf8A0HL/AP74t/8A41R/Zl3/ANBy/wD++Lf/AONVo0UAYunWWo3Gl2s13rF/FPJCjyx+VAuxioJGDFkYPY1Z/sy7/wCg5f8A/fFv/wDGq0aKAM7+zLv/AKDl/wD98W//AMao/sy7/wCg5f8A/fFv/wDGq0aKAM7+zLv/AKDl/wD98W//AMao/sy7/wCg5f8A/fFv/wDGq0aKAMW1stRluLxJtYv0SKYJC3lQDevlo2f9Vz8zMMj09qs/2Zd/9By//wC+Lf8A+NVo0UAZ39mXf/Qcv/8Avi3/APjVH9mXf/Qcv/8Avi3/APjVaNFAGd/Zl3/0HL//AL4t/wD41R/Zl3/0HL//AL4t/wD41WjRQBipZai2qTwtrF+IEhjdJPKg+ZizhhnyscBV49/cVZ/sy7/6Dl//AN8W/wD8arRooAzv7Mu/+g5f/wDfFv8A/GqP7Mu/+g5f/wDfFv8A/Gq0aKAM7+zLv/oOX/8A3xb/APxqj+zLv/oOX/8A3xb/APxqtGigDFey1FdUghXWL8wPDI7yeVB8rBkCjPlY5DNx7exqz/Zl3/0HL/8A74t//jVaNFAGd/Zl3/0HL/8A74t//jVH9mXf/Qcv/wDvi3/+NVo0UAZ39mXf/Qcv/wDvi3/+NUf2Zd/9By//AO+Lf/41WjRQBi3VlqMVxZpDrF+6SzFJm8qA7F8t2z/quPmVRk+vvVn+zLv/AKDl/wD98W//AMarRooAzv7Mu/8AoOX/AP3xb/8Axqj+zLv/AKDl/wD98W//AMarRooAzv7Mu/8AoOX/AP3xb/8Axqj+zLv/AKDl/wD98W//AMarRooAxdRstRt9LuprTWL+WeOF3ij8qBt7BSQMCLJyewraoooAKKKKACiiigArK0VZjYy7JIwv2y6wChJ/18nvWrWdof8AyD5f+vy6/wDSiSgA0P8A5B8v/X5df+lElaNZugndpshGeby6PIx/y3krSoAKKKKACiiigAooooAyfE2uP4d0ObUUsJb0Qgs6Ruq7VAJLEk9MDsCckcVrVjeL7K41HwbqtnZRmW4ntXSNAQNzEcDmteRPMjZCWAYEZU4I+h7UAQ299bXc93DbyiSSzlEM6gH925RZAD/wGRD+NZereKbTQr6WHVUeCEWpuYZh8wnKnDxqP74ymF6tu46HFfw74Oj8P6xq1+moX1z9vuBKsc91JIEHkxR/MGYhmzETuPIBA6CqXi7w9qXinVbaKApaQaOU1CznlRXE18CfLHqEUBt3QnzBgjaaAOqspZ57GCW7t/s08katJDv3+WxHK5746Zqeq2nXE13ptvcXVpJZzyRq0ltIwLRMRypIJBweMg4NWaAKOr6hPp1kslnYTahcSSLFHBEQOSfvMx4VQMkn0HAJIBj0PV21e2nM1q1pc2s7W9xCXDhXAB+Vh94EMCDx15AORUfia+1Ow0R5NDsJL29d1jRYwp8oE8yEMyhtoyduRk4GRnITwyiRaMIo9PvbHy3bcL4oZZmPzNIxVmBLEkk56546UAaAvbdtQexEgNykSzNHg5CMSAfzU/lVPVdbi0e8sUvU2Wl3IYTdFsLDJjKBvQNhgGJxu2jqwrNt/BsVv4ym14ajqLGSFIxA95KVBDuxyC2Cvz8LjAxTfG2hz+LLGLw2yPHpl9ltRul25WJCCIlzn5nbHOOFVuQdtAGvomqf21pMeoLbvBDOS0Ac/NJFn5HI7bhhgOoBGecgaFZnh99SbRoo9ciVL6AmGV4wAk+04EqgE4DDDbe2SO2a06AIbuZ7azmmit5Ll40LLDEVDSED7o3EDJ9yBWZo+uz3+qXul6jYfYb6zihnZFmEqNHKZAjBgBzmJwQQMY7gg1pXstxBYzS2dt9qnRC0cHmBPMI/h3HgZ9TXOeFrO5XxHrOpDSLnSLK+WFvIu5EaSW4BfzJMIzBRgxr15KngDlgDpJbyCG7gtpZAs1xu8pMH5toyfyFVNb1ddD08X88LSWscii5dT/qIycGQjuq5BPouT2wczVvB0Wq+JbPV21HUYTbly0MV7KinKBRtAYBenOBzVzxRHqNzoj2OjoBc3zC3M7BSttG3DykHhiq5wuDltoPGSACbSNZj1mS9a0jzaW05t47kOCJ3XiTaB2Vspn1VvTJ0q57wfpdz4e01/D8kRNjpxEen3GQfNtyMqrY6OnKn1AVupIHQ0AFYFv4ttbrx7deF7eF3mtLMXM1wD8isWX91/vBXRj6B19a3JTIIXMKq0gU7FY4BOOAT2rgvCmi+ItM8UWMmqaVbqhsbn7bfR3xlMtxJJG5baUBAJUgDOFUAZ4AoA7m6vbexjje6kEaySpChIPLuwVR+JIFN1G5ms9NuLm1tXvJYYy628bANLjnaue57e/pWP4p8Jx+Jhal7+9tWt7iGXFvdSRqwSQOflVgNxxgN1FaV41zpmgyf2ZbyX1zBCEgikly0rAYXc5564yxyep5oAq6T4mtNd1BotIxc2sdsk0l0rfKrSAMkeO7bfmI42gr/AHq2a5Hwb4fv/CV1cabK5vbO9zfPeBVTZdMR5y7RyFZjvXrjLKSAFz11ABXK6T4wuNY8Q3Wn29lZLHa3ctu5fUR55EbbS4h2Zxn3rqq4y70t7rxBbQWfhj7A9vqgvn1VTD5brg7mBB3l3VihBUdW5IAJAOrv7620zTbm/v5RDa2sTTTSsDhEUFmPHoATU7Z2naAWxwCcZrD8Y+GV8WeF77STeXFo1zbSwpJDKyqC6Fcuqkb1Gfung1p2doml6eIYpLm4WMFgZ5mmkbvjcxJPtzQBkab4uh1S6sbO2tZBezCQ3lu7YNiIztbfxyd+FX+8CWHAroa4fw9ousaT4kbX7q3DzeIiP7Ut4wg+xFFPkHIPzBU/duQTliGGBmu4oAKyb3XHsvEem6WbCVo74sou96hFYI77cZyThDngAZHJrWrG1eyuLnX9AuIIy8VrdSvM2R8imCRQfzYD8aANh3WONnc4VQST6Co7W6hvbOG6tXEkE8ayRuP4lYZB/I1W1jS01jTXtJJ7mAN/HbTtE2cEdVIOOelVvC+gL4a8O2mlpdXF15ESI0k8zyElUVfl3E7V+XhRwM0AZx8ZS7Zb5NIlOiw3TWr3pmUOCsnltIIjz5YcH5s5wMhSMGuorgpLDWv+EaufCI0WdlmllhXUlliFuLd5C3mH5t+4IcbdvL/7PzDvaACsXWtbvtOuBFp2izagFhaeaXzVijRQfuhm+855wvA45K5GdquX8Wz6hNc22mRaPfXmlzIXvpbQx5cA4EHzOpAbksf7o2/xEqAdDY3kWo6dbXttuMNzEsse4YO1gCMjtwaSyvrbUIGmspRLGsskLMAeHjdo3H4MrD8KYYV1DSVjdLizWaIZRH8uSLI+7lDwR04P41leEvCqeFrO5hW+urtp7q4nJnnd1USTySAAMTggPgt/ERk9aAGXvie7XUtQt9I0WXUY9LKreSLOsZDlBJ5can77hGRuSo+cDOc43LG8g1HT7e9s3ElvcxLNE4/iVgCD+Rrmd+r+HtX1kWeh3GqR6lcrdWstvJEqxsYo42SXe6kAGPduAPynGMjB2vDWknQfCek6O0glOn2UNqZB/F5aBc/jigDTqlql3e2kMf8AZunG/mkfaFMyxIgwTuZjkgcY4BOSOMci7WZrtzPBYhY9Jn1WCYmK4itpEWRUKkZAZlBHY4YEZyM0AO0HWE13SFvUhe3PmzQSROQSkkUrROuRwQHRsEdRzVqG9t7i5uYIZA8tq4SZQD8jFQwH5MD+NY/gzTrrTvCcNne27We2SYw2pkDtbwtIxjjLKSCyoVBwTyOrdTFoPg6LQtc1HUU1HULj7ZIrLHPeSyKoEap8wZiGPy5B7ZxQBa1TXLq31ZNL0jTDqF4YPtEm+cQxxJu2rliCcsQ2AAfunJHGbei6tFrelJewxSQku8UkMuN0UiOUdDgkZDKRkEg4yOKx9Rjv9H8YTa3aaVc6rb31hDaSx2jxiSFoXldDiRlBVvPYHByCq8YJIveFrC7sNGf+0UWK5ubu4u3iVt3lebKzqmRwSFYAkcEg44oA2aOnWisTxdZalqPhqex0dUaW5Kxy7pzCfJLDzArgEqxTIBxwTntQBH4R8WWvjHT7y+sIZI7aC8kto3c/69VAKyr/ALLBgR6gg962ftkH2/7F5g+0+V5vl4OdmcZ/Oud8FWWp2Ta0uqaVBpscl8JLWOC481TH5MacfKuANmP88yL4OiXxl/bw1HUSfKK+Qb2Upu37um7GzttxigDQ1rWX0xrS3tLNr69vZDHBCHCLwpZmdj91QB1AJyRgGjRdYbVFuorm0ayvbKUQ3EDOHAJUMGVh95SGGDgdwQCDVPxDBewatpWs6fYPqH2Mywz28TosnlSAZdN5CkhkTgkcFsZIALvDsF7Jf6rquoWT2BvpY/JtpXVpFjRAoL7SVDFtxwCeNuecgAG9VTVr8aVot9qLRmRbS3knKA43bFLYz+FW6gvYhcafcQtBHciSJlMMpwsmRjaTg8Hp0NAGP4X8Q3PiG3a4ktbGKHapBtdQFwQxGdrAINpAPrWxNe29vc20E0gSW6cpCpB+dgpYj8lJ/Cua8OWMj+I31KLw/J4ftk09LQwS+UGmYNuXiJmG1AWAOf42wMc1PrvgyLXNe0/Un1HUbc2srO0cF7LGpBiZPlCsAp+bJI68+tAGrrmrx6JpZu3gluHaSOGKCEDdLJI4RFGeBlmHJ4AyT0qvpWt3N1qc2m6rp32C9jiE6BZhLHLGSRlWwDkEYIIGMjrmm+KbK7u9Lgl02EXF1ZXcN0kBYL5oRxuUE8Biu7GcDOMkDmq2mC+1XxUdXu9LuNMt7eza1hS6eMySs7q7NhGYBRsUDJySW4wASAdHRRRQAUUUUAFFFFABWdof/IPl/wCvy6/9KJK0aytFnVLGVSJMi8uukbEf6+TuBQBJof8AyD5f+vy6/wDSiStGsWxnvbCKaBtIu5f9JnkV43h2sryswIzID0YdRVn+07v/AKAd/wD992//AMdoA0aKzv7Tu/8AoB3/AP33b/8Ax2j+07v/AKAd/wD992//AMdoA0aKzv7Tu/8AoB3/AP33b/8Ax2j+07v/AKAd/wD992//AMdoA0aKzv7Tu/8AoB3/AP33b/8Ax2j+07v/AKAd/wD992//AMdoA0aKzv7Tu/8AoB3/AP33b/8Ax2j+07v/AKAd/wD992//AMdoA0aKzv7Tu/8AoB3/AP33b/8Ax2j+07v/AKAd/wD992//AMdoA0aKzTqtyHCf2Jf7iCQN8HQf9tfel/tO7/6Ad/8A992//wAdoA0aKzv7Tu/+gHf/APfdv/8AHaP7Tu/+gHf/APfdv/8AHaANGis7+07v/oB3/wD33b//AB2j+07v/oB3/wD33b//AB2gDRorO/tO7/6Ad/8A992//wAdo/tO7/6Ad/8A992//wAdoA0aKzv7Tu/+gHf/APfdv/8AHaP7Tu/+gHf/APfdv/8AHaANGis7+07v/oB3/wD33b//AB2j+07v/oB3/wD33b//AB2gDRorNfVblEZ20S/CqMk74On/AH9pf7Tu/wDoB3//AH3b/wDx2gDRorO/tO7/AOgHf/8Afdv/APHaP7Tu/wDoB3//AH3b/wDx2gDRorO/tO7/AOgHf/8Afdv/APHaP7Tu/wDoB3//AH3b/wDx2gDRorO/tO7/AOgHf/8Afdv/APHaP7Tu/wDoB3//AH3b/wDx2gDRorO/tO7/AOgHf/8Afdv/APHaP7Tu/wDoB3//AH3b/wDx2gDRorO/tO7/AOgHf/8Afdv/APHaP7Tu/wDoB3//AH3b/wDx2gDRorO/tO7/AOgHf/8Afdv/APHaP7Tu/wDoB3//AH3b/wDx2gDRorO/tO7/AOgHf/8Afdv/APHaP7Tu/wDoB3//AH3b/wDx2gDRorO/tO7/AOgHf/8Afdv/APHaP7Tu/wDoB3//AH3b/wDx2gDRorO/tO7/AOgHf/8Afdv/APHaR9VuURnbRL8KoyTvg6f9/aANKis7+07v/oB3/wD33b//AB2j+07v/oB3/wD33b//AB2gDRorO/tO7/6Ad/8A992//wAdo/tO7/6Ad/8A992//wAdoA0aKzv7Tu/+gHf/APfdv/8AHaP7Tu/+gHf/APfdv/8AHaANGis7+07v/oB3/wD33b//AB2j+07v/oB3/wD33b//AB2gDRorO/tO7/6Ad/8A992//wAdo/tO7/6Ad/8A992//wAdoA0aKzv7Tu/+gHf/APfdv/8AHaP7Tu/+gHf/APfdv/8AHaANGis7+07v/oB3/wD33b//AB2j+07v/oB3/wD33b//AB2gDRorO/tO7/6Ad/8A992//wAdo/tO7/6Ad/8A992//wAdoA0aKzRqtyXKf2Jf7gASN8HQ/wDbX2pf7Tu/+gHf/wDfdv8A/HaANGis7+07v/oB3/8A33b/APx2j+07v/oB3/8A33b/APx2gDRorO/tO7/6Ad//AN92/wD8do/tO7/6Ad//AN92/wD8doA0aKzv7Tu/+gHf/wDfdv8A/HaP7Tu/+gHf/wDfdv8A/HaANGis7+07v/oB3/8A33b/APx2j+07v/oB3/8A33b/APx2gDRorO/tO7/6Ad//AN92/wD8do/tO7/6Ad//AN92/wD8doA0aKzv7Tu/+gHf/wDfdv8A/HaP7Tu/+gHf/wDfdv8A/HaANGs7Q/8AkHy/9fl1/wClElIuq3LjK6JfkZI+/B1Bx/z1p+ixTQ6cRcwtDI9xPL5bEEqHldhnaSM4I6GgD//Z)"
      ],
      "metadata": {
        "id": "WhD3TfIaU4vj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CNN - 1 + 1 / 8 / X / leaky_relu"
      ],
      "metadata": {
        "id": "4wX_ZtGoq6wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn1 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(8, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn1.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn1.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn1.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8686"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmEYyvFNSQ-t",
        "outputId": "b8985f63-9dd4-4c12-cf1e-04ac124e0ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 2s 4ms/step - loss: 0.4322 - accuracy: 0.7970 - val_loss: 0.3205 - val_accuracy: 0.8534\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3199 - accuracy: 0.8504 - val_loss: 0.3118 - val_accuracy: 0.8551\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3133 - accuracy: 0.8530 - val_loss: 0.3077 - val_accuracy: 0.8576\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3096 - accuracy: 0.8535 - val_loss: 0.3053 - val_accuracy: 0.8578\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3070 - accuracy: 0.8542 - val_loss: 0.3027 - val_accuracy: 0.8584\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3048 - accuracy: 0.8557 - val_loss: 0.3015 - val_accuracy: 0.8577\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3032 - accuracy: 0.8564 - val_loss: 0.2994 - val_accuracy: 0.8590\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3018 - accuracy: 0.8564 - val_loss: 0.2980 - val_accuracy: 0.8606\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3005 - accuracy: 0.8565 - val_loss: 0.2975 - val_accuracy: 0.8586\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2992 - accuracy: 0.8568 - val_loss: 0.2966 - val_accuracy: 0.8581\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2981 - accuracy: 0.8568 - val_loss: 0.2959 - val_accuracy: 0.8565\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2972 - accuracy: 0.8571 - val_loss: 0.2946 - val_accuracy: 0.8579\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2961 - accuracy: 0.8572 - val_loss: 0.2942 - val_accuracy: 0.8570\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2950 - accuracy: 0.8577 - val_loss: 0.2927 - val_accuracy: 0.8580\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2940 - accuracy: 0.8576 - val_loss: 0.2924 - val_accuracy: 0.8576\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2928 - accuracy: 0.8579 - val_loss: 0.2912 - val_accuracy: 0.8577\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2918 - accuracy: 0.8588 - val_loss: 0.2906 - val_accuracy: 0.8570\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2911 - accuracy: 0.8587 - val_loss: 0.2895 - val_accuracy: 0.8590\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2901 - accuracy: 0.8589 - val_loss: 0.2899 - val_accuracy: 0.8593\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2890 - accuracy: 0.8597 - val_loss: 0.2885 - val_accuracy: 0.8596\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2885 - accuracy: 0.8596 - val_loss: 0.2878 - val_accuracy: 0.8617\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2875 - accuracy: 0.8592 - val_loss: 0.2869 - val_accuracy: 0.8613\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2867 - accuracy: 0.8595 - val_loss: 0.2857 - val_accuracy: 0.8618\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2859 - accuracy: 0.8598 - val_loss: 0.2856 - val_accuracy: 0.8601\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2850 - accuracy: 0.8605 - val_loss: 0.2843 - val_accuracy: 0.8626\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2843 - accuracy: 0.8606 - val_loss: 0.2837 - val_accuracy: 0.8638\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2831 - accuracy: 0.8611 - val_loss: 0.2836 - val_accuracy: 0.8639\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2823 - accuracy: 0.8620 - val_loss: 0.2833 - val_accuracy: 0.8620\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2815 - accuracy: 0.8616 - val_loss: 0.2824 - val_accuracy: 0.8636\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2810 - accuracy: 0.8627 - val_loss: 0.2819 - val_accuracy: 0.8603\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.8622 - val_loss: 0.2801 - val_accuracy: 0.8645\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.8633 - val_loss: 0.2795 - val_accuracy: 0.8660\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2796 - accuracy: 0.8630 - val_loss: 0.2797 - val_accuracy: 0.8662\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2791 - accuracy: 0.8632 - val_loss: 0.2793 - val_accuracy: 0.8661\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.8632 - val_loss: 0.2793 - val_accuracy: 0.8665\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.8634 - val_loss: 0.2785 - val_accuracy: 0.8644\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2782 - accuracy: 0.8637 - val_loss: 0.2786 - val_accuracy: 0.8650\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.8632 - val_loss: 0.2778 - val_accuracy: 0.8653\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.8634 - val_loss: 0.2783 - val_accuracy: 0.8640\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.8636 - val_loss: 0.2775 - val_accuracy: 0.8646\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2773 - accuracy: 0.8644 - val_loss: 0.2774 - val_accuracy: 0.8651\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2771 - accuracy: 0.8637 - val_loss: 0.2774 - val_accuracy: 0.8652\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2768 - accuracy: 0.8640 - val_loss: 0.2774 - val_accuracy: 0.8642\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.8641 - val_loss: 0.2776 - val_accuracy: 0.8659\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.8644 - val_loss: 0.2772 - val_accuracy: 0.8664\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2763 - accuracy: 0.8635 - val_loss: 0.2768 - val_accuracy: 0.8656\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2760 - accuracy: 0.8643 - val_loss: 0.2773 - val_accuracy: 0.8650\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2758 - accuracy: 0.8642 - val_loss: 0.2762 - val_accuracy: 0.8662\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2756 - accuracy: 0.8642 - val_loss: 0.2765 - val_accuracy: 0.8652\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2757 - accuracy: 0.8643 - val_loss: 0.2757 - val_accuracy: 0.8668\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8668\n",
            "정확률= 0.8668320178985596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. CNN - 1 + 1 / 16 / X / leaky_relu"
      ],
      "metadata": {
        "id": "uX1ynyKisA7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn2 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(16, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn2.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn2.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn2.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8709"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRq284g7tI1W",
        "outputId": "c75b85ba-a62a-4211-ecf7-7836e6388c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 6ms/step - loss: 0.4141 - accuracy: 0.8143 - val_loss: 0.3154 - val_accuracy: 0.8573\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3149 - accuracy: 0.8548 - val_loss: 0.3072 - val_accuracy: 0.8608\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3087 - accuracy: 0.8552 - val_loss: 0.3034 - val_accuracy: 0.8611\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3050 - accuracy: 0.8570 - val_loss: 0.3001 - val_accuracy: 0.8623\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3020 - accuracy: 0.8580 - val_loss: 0.2982 - val_accuracy: 0.8632\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3001 - accuracy: 0.8582 - val_loss: 0.2962 - val_accuracy: 0.8614\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 3s 11ms/step - loss: 0.2979 - accuracy: 0.8590 - val_loss: 0.2957 - val_accuracy: 0.8614\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2961 - accuracy: 0.8594 - val_loss: 0.2935 - val_accuracy: 0.8609\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2946 - accuracy: 0.8590 - val_loss: 0.2929 - val_accuracy: 0.8635\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2931 - accuracy: 0.8603 - val_loss: 0.2905 - val_accuracy: 0.8615\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2918 - accuracy: 0.8600 - val_loss: 0.2892 - val_accuracy: 0.8621\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2904 - accuracy: 0.8606 - val_loss: 0.2889 - val_accuracy: 0.8618\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2889 - accuracy: 0.8611 - val_loss: 0.2873 - val_accuracy: 0.8617\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2879 - accuracy: 0.8611 - val_loss: 0.2868 - val_accuracy: 0.8641\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2864 - accuracy: 0.8621 - val_loss: 0.2865 - val_accuracy: 0.8630\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2858 - accuracy: 0.8624 - val_loss: 0.2853 - val_accuracy: 0.8637\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2846 - accuracy: 0.8624 - val_loss: 0.2838 - val_accuracy: 0.8659\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2835 - accuracy: 0.8620 - val_loss: 0.2836 - val_accuracy: 0.8654\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2826 - accuracy: 0.8632 - val_loss: 0.2829 - val_accuracy: 0.8645\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2820 - accuracy: 0.8628 - val_loss: 0.2829 - val_accuracy: 0.8634\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2811 - accuracy: 0.8642 - val_loss: 0.2818 - val_accuracy: 0.8644\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2801 - accuracy: 0.8636 - val_loss: 0.2825 - val_accuracy: 0.8647\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2797 - accuracy: 0.8636 - val_loss: 0.2805 - val_accuracy: 0.8652\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2786 - accuracy: 0.8641 - val_loss: 0.2826 - val_accuracy: 0.8636\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2784 - accuracy: 0.8645 - val_loss: 0.2827 - val_accuracy: 0.8647\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.2778 - accuracy: 0.8638 - val_loss: 0.2782 - val_accuracy: 0.8648\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.2770 - accuracy: 0.8650 - val_loss: 0.2786 - val_accuracy: 0.8654\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2763 - accuracy: 0.8652 - val_loss: 0.2782 - val_accuracy: 0.8663\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.2759 - accuracy: 0.8650 - val_loss: 0.2779 - val_accuracy: 0.8630\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2755 - accuracy: 0.8653 - val_loss: 0.2774 - val_accuracy: 0.8668\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2751 - accuracy: 0.8655 - val_loss: 0.2777 - val_accuracy: 0.8641\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2749 - accuracy: 0.8653 - val_loss: 0.2763 - val_accuracy: 0.8669\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8652 - val_loss: 0.2765 - val_accuracy: 0.8652\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2739 - accuracy: 0.8651 - val_loss: 0.2783 - val_accuracy: 0.8656\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2738 - accuracy: 0.8660 - val_loss: 0.2766 - val_accuracy: 0.8649\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2733 - accuracy: 0.8657 - val_loss: 0.2762 - val_accuracy: 0.8662\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2729 - accuracy: 0.8661 - val_loss: 0.2763 - val_accuracy: 0.8673\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2729 - accuracy: 0.8659 - val_loss: 0.2752 - val_accuracy: 0.8678\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2726 - accuracy: 0.8669 - val_loss: 0.2756 - val_accuracy: 0.8658\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2726 - accuracy: 0.8659 - val_loss: 0.2759 - val_accuracy: 0.8646\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2721 - accuracy: 0.8659 - val_loss: 0.2747 - val_accuracy: 0.8667\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2719 - accuracy: 0.8654 - val_loss: 0.2739 - val_accuracy: 0.8672\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2718 - accuracy: 0.8669 - val_loss: 0.2755 - val_accuracy: 0.8664\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2713 - accuracy: 0.8671 - val_loss: 0.2740 - val_accuracy: 0.8676\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2712 - accuracy: 0.8662 - val_loss: 0.2742 - val_accuracy: 0.8677\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2712 - accuracy: 0.8651 - val_loss: 0.2745 - val_accuracy: 0.8668\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2709 - accuracy: 0.8662 - val_loss: 0.2745 - val_accuracy: 0.8670\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2707 - accuracy: 0.8667 - val_loss: 0.2728 - val_accuracy: 0.8674\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2702 - accuracy: 0.8666 - val_loss: 0.2728 - val_accuracy: 0.8663\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2703 - accuracy: 0.8660 - val_loss: 0.2723 - val_accuracy: 0.8670\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2723 - accuracy: 0.8670\n",
            "정확률= 0.8670476675033569\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8709"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. CNN - 1 + 2 / 8 / X / leaky_relu"
      ],
      "metadata": {
        "id": "U47U7NZbsEgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn3 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(8, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn3.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn3.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn3.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8694"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-qYCcF5trB7",
        "outputId": "b8fd9873-0eb4-4cb6-b057-99c57421834e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 5ms/step - loss: 0.3854 - accuracy: 0.8327 - val_loss: 0.3109 - val_accuracy: 0.8577\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3133 - accuracy: 0.8538 - val_loss: 0.3048 - val_accuracy: 0.8605\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3079 - accuracy: 0.8551 - val_loss: 0.3006 - val_accuracy: 0.8599\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3041 - accuracy: 0.8558 - val_loss: 0.2977 - val_accuracy: 0.8625\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3013 - accuracy: 0.8573 - val_loss: 0.2956 - val_accuracy: 0.8617\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2985 - accuracy: 0.8581 - val_loss: 0.2937 - val_accuracy: 0.8617\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2961 - accuracy: 0.8573 - val_loss: 0.2929 - val_accuracy: 0.8606\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2941 - accuracy: 0.8579 - val_loss: 0.2901 - val_accuracy: 0.8628\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2919 - accuracy: 0.8590 - val_loss: 0.2883 - val_accuracy: 0.8636\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2906 - accuracy: 0.8589 - val_loss: 0.2868 - val_accuracy: 0.8645\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2889 - accuracy: 0.8588 - val_loss: 0.2865 - val_accuracy: 0.8639\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2879 - accuracy: 0.8582 - val_loss: 0.2860 - val_accuracy: 0.8638\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2867 - accuracy: 0.8598 - val_loss: 0.2837 - val_accuracy: 0.8655\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2861 - accuracy: 0.8599 - val_loss: 0.2835 - val_accuracy: 0.8655\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2850 - accuracy: 0.8608 - val_loss: 0.2828 - val_accuracy: 0.8647\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2841 - accuracy: 0.8602 - val_loss: 0.2831 - val_accuracy: 0.8662\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2836 - accuracy: 0.8611 - val_loss: 0.2831 - val_accuracy: 0.8654\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2829 - accuracy: 0.8608 - val_loss: 0.2816 - val_accuracy: 0.8659\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2825 - accuracy: 0.8607 - val_loss: 0.2814 - val_accuracy: 0.8663\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.8619 - val_loss: 0.2811 - val_accuracy: 0.8668\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2814 - accuracy: 0.8618 - val_loss: 0.2807 - val_accuracy: 0.8659\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2810 - accuracy: 0.8611 - val_loss: 0.2822 - val_accuracy: 0.8660\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2811 - accuracy: 0.8609 - val_loss: 0.2809 - val_accuracy: 0.8652\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.8618 - val_loss: 0.2832 - val_accuracy: 0.8638\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2801 - accuracy: 0.8615 - val_loss: 0.2810 - val_accuracy: 0.8647\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2796 - accuracy: 0.8619 - val_loss: 0.2803 - val_accuracy: 0.8647\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2791 - accuracy: 0.8627 - val_loss: 0.2813 - val_accuracy: 0.8672\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2791 - accuracy: 0.8615 - val_loss: 0.2796 - val_accuracy: 0.8666\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2787 - accuracy: 0.8621 - val_loss: 0.2786 - val_accuracy: 0.8666\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.8628 - val_loss: 0.2789 - val_accuracy: 0.8670\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2779 - accuracy: 0.8624 - val_loss: 0.2782 - val_accuracy: 0.8670\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2779 - accuracy: 0.8629 - val_loss: 0.2791 - val_accuracy: 0.8674\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2775 - accuracy: 0.8624 - val_loss: 0.2775 - val_accuracy: 0.8667\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2769 - accuracy: 0.8630 - val_loss: 0.2779 - val_accuracy: 0.8666\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2767 - accuracy: 0.8627 - val_loss: 0.2778 - val_accuracy: 0.8660\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2767 - accuracy: 0.8632 - val_loss: 0.2776 - val_accuracy: 0.8654\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2765 - accuracy: 0.8628 - val_loss: 0.2767 - val_accuracy: 0.8659\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2760 - accuracy: 0.8622 - val_loss: 0.2766 - val_accuracy: 0.8678\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2758 - accuracy: 0.8631 - val_loss: 0.2770 - val_accuracy: 0.8677\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2760 - accuracy: 0.8633 - val_loss: 0.2764 - val_accuracy: 0.8675\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2754 - accuracy: 0.8637 - val_loss: 0.2764 - val_accuracy: 0.8656\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2755 - accuracy: 0.8633 - val_loss: 0.2765 - val_accuracy: 0.8666\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2752 - accuracy: 0.8640 - val_loss: 0.2779 - val_accuracy: 0.8664\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2752 - accuracy: 0.8639 - val_loss: 0.2755 - val_accuracy: 0.8668\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2750 - accuracy: 0.8638 - val_loss: 0.2757 - val_accuracy: 0.8686\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2751 - accuracy: 0.8632 - val_loss: 0.2752 - val_accuracy: 0.8677\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2745 - accuracy: 0.8640 - val_loss: 0.2755 - val_accuracy: 0.8669\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8639 - val_loss: 0.2761 - val_accuracy: 0.8674\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.8641 - val_loss: 0.2740 - val_accuracy: 0.8703\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.8649 - val_loss: 0.2758 - val_accuracy: 0.8670\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2758 - accuracy: 0.8670\n",
            "정확률= 0.8670476675033569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. CNN - 1 + 2 / 16 / X / leaky_relu"
      ],
      "metadata": {
        "id": "ZVk-A3Y2sHZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn4 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(16, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn4.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn4.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn4.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8708"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWWBAxUPtwQD",
        "outputId": "a5381063-9ea7-4f93-dae3-4eade764ec17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 2s 4ms/step - loss: 0.3830 - accuracy: 0.8244 - val_loss: 0.3105 - val_accuracy: 0.8571\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3114 - accuracy: 0.8545 - val_loss: 0.3052 - val_accuracy: 0.8572\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3058 - accuracy: 0.8566 - val_loss: 0.2985 - val_accuracy: 0.8620\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3015 - accuracy: 0.8580 - val_loss: 0.2958 - val_accuracy: 0.8639\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2982 - accuracy: 0.8581 - val_loss: 0.2946 - val_accuracy: 0.8632\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2956 - accuracy: 0.8596 - val_loss: 0.2928 - val_accuracy: 0.8610\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2925 - accuracy: 0.8602 - val_loss: 0.2883 - val_accuracy: 0.8628\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2898 - accuracy: 0.8615 - val_loss: 0.2854 - val_accuracy: 0.8649\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2872 - accuracy: 0.8624 - val_loss: 0.2825 - val_accuracy: 0.8648\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2848 - accuracy: 0.8624 - val_loss: 0.2821 - val_accuracy: 0.8648\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2829 - accuracy: 0.8638 - val_loss: 0.2828 - val_accuracy: 0.8638\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2806 - accuracy: 0.8643 - val_loss: 0.2804 - val_accuracy: 0.8627\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2797 - accuracy: 0.8649 - val_loss: 0.2764 - val_accuracy: 0.8676\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.8643 - val_loss: 0.2782 - val_accuracy: 0.8669\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2764 - accuracy: 0.8654 - val_loss: 0.2754 - val_accuracy: 0.8649\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2758 - accuracy: 0.8661 - val_loss: 0.2756 - val_accuracy: 0.8675\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.8655 - val_loss: 0.2729 - val_accuracy: 0.8687\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2736 - accuracy: 0.8666 - val_loss: 0.2746 - val_accuracy: 0.8660\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2722 - accuracy: 0.8668 - val_loss: 0.2740 - val_accuracy: 0.8675\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2717 - accuracy: 0.8664 - val_loss: 0.2722 - val_accuracy: 0.8663\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2709 - accuracy: 0.8671 - val_loss: 0.2711 - val_accuracy: 0.8706\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2704 - accuracy: 0.8661 - val_loss: 0.2693 - val_accuracy: 0.8687\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2698 - accuracy: 0.8677 - val_loss: 0.2705 - val_accuracy: 0.8683\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2691 - accuracy: 0.8665 - val_loss: 0.2681 - val_accuracy: 0.8689\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2684 - accuracy: 0.8671 - val_loss: 0.2680 - val_accuracy: 0.8681\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2677 - accuracy: 0.8683 - val_loss: 0.2672 - val_accuracy: 0.8665\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.8688 - val_loss: 0.2675 - val_accuracy: 0.8699\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2670 - accuracy: 0.8675 - val_loss: 0.2673 - val_accuracy: 0.8702\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2670 - accuracy: 0.8685 - val_loss: 0.2676 - val_accuracy: 0.8711\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2669 - accuracy: 0.8680 - val_loss: 0.2673 - val_accuracy: 0.8702\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2667 - accuracy: 0.8685 - val_loss: 0.2662 - val_accuracy: 0.8722\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2657 - accuracy: 0.8684 - val_loss: 0.2670 - val_accuracy: 0.8715\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2661 - accuracy: 0.8688 - val_loss: 0.2668 - val_accuracy: 0.8718\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.8681 - val_loss: 0.2663 - val_accuracy: 0.8688\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.8683 - val_loss: 0.2648 - val_accuracy: 0.8703\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.8699 - val_loss: 0.2651 - val_accuracy: 0.8709\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.8693 - val_loss: 0.2654 - val_accuracy: 0.8705\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2645 - accuracy: 0.8683 - val_loss: 0.2643 - val_accuracy: 0.8720\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2640 - accuracy: 0.8697 - val_loss: 0.2651 - val_accuracy: 0.8683\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2640 - accuracy: 0.8697 - val_loss: 0.2636 - val_accuracy: 0.8693\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2636 - accuracy: 0.8690 - val_loss: 0.2648 - val_accuracy: 0.8670\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2637 - accuracy: 0.8693 - val_loss: 0.2635 - val_accuracy: 0.8691\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2631 - accuracy: 0.8695 - val_loss: 0.2664 - val_accuracy: 0.8686\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2635 - accuracy: 0.8682 - val_loss: 0.2648 - val_accuracy: 0.8708\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2638 - accuracy: 0.8690 - val_loss: 0.2641 - val_accuracy: 0.8711\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2630 - accuracy: 0.8700 - val_loss: 0.2635 - val_accuracy: 0.8672\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2624 - accuracy: 0.8691 - val_loss: 0.2636 - val_accuracy: 0.8714\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2628 - accuracy: 0.8697 - val_loss: 0.2631 - val_accuracy: 0.8724\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2629 - accuracy: 0.8692 - val_loss: 0.2632 - val_accuracy: 0.8707\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2626 - accuracy: 0.8691 - val_loss: 0.2643 - val_accuracy: 0.8708\n",
            "290/290 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.8708\n",
            "정확률= 0.8708216547966003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. CNN - 1 + 3 / 8 / X / leaky_relu"
      ],
      "metadata": {
        "id": "xcB_eAUDsJrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn5 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(8, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn5.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn5.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn5.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8694"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSMg7ov9t143",
        "outputId": "f43e73df-fc05-4fc0-d5c1-825fe6a3affc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 6ms/step - loss: 0.3922 - accuracy: 0.8144 - val_loss: 0.3166 - val_accuracy: 0.8520\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3148 - accuracy: 0.8514 - val_loss: 0.3078 - val_accuracy: 0.8540\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3103 - accuracy: 0.8528 - val_loss: 0.3051 - val_accuracy: 0.8575\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3075 - accuracy: 0.8524 - val_loss: 0.3032 - val_accuracy: 0.8575\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3048 - accuracy: 0.8528 - val_loss: 0.2997 - val_accuracy: 0.8568\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3017 - accuracy: 0.8536 - val_loss: 0.2979 - val_accuracy: 0.8571\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3002 - accuracy: 0.8537 - val_loss: 0.2981 - val_accuracy: 0.8563\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2977 - accuracy: 0.8540 - val_loss: 0.2937 - val_accuracy: 0.8569\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2962 - accuracy: 0.8544 - val_loss: 0.2935 - val_accuracy: 0.8570\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2946 - accuracy: 0.8545 - val_loss: 0.2920 - val_accuracy: 0.8569\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2923 - accuracy: 0.8556 - val_loss: 0.2912 - val_accuracy: 0.8567\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2910 - accuracy: 0.8567 - val_loss: 0.2899 - val_accuracy: 0.8534\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2894 - accuracy: 0.8561 - val_loss: 0.2893 - val_accuracy: 0.8570\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2879 - accuracy: 0.8572 - val_loss: 0.2924 - val_accuracy: 0.8579\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2865 - accuracy: 0.8579 - val_loss: 0.2873 - val_accuracy: 0.8553\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2857 - accuracy: 0.8581 - val_loss: 0.2850 - val_accuracy: 0.8567\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2841 - accuracy: 0.8578 - val_loss: 0.2838 - val_accuracy: 0.8551\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2836 - accuracy: 0.8591 - val_loss: 0.2836 - val_accuracy: 0.8558\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2825 - accuracy: 0.8581 - val_loss: 0.2830 - val_accuracy: 0.8593\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.8591 - val_loss: 0.2817 - val_accuracy: 0.8591\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2809 - accuracy: 0.8590 - val_loss: 0.2797 - val_accuracy: 0.8612\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2801 - accuracy: 0.8610 - val_loss: 0.2782 - val_accuracy: 0.8633\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2790 - accuracy: 0.8608 - val_loss: 0.2804 - val_accuracy: 0.8620\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2778 - accuracy: 0.8608 - val_loss: 0.2768 - val_accuracy: 0.8652\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2772 - accuracy: 0.8615 - val_loss: 0.2821 - val_accuracy: 0.8609\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2764 - accuracy: 0.8617 - val_loss: 0.2762 - val_accuracy: 0.8648\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2754 - accuracy: 0.8625 - val_loss: 0.2762 - val_accuracy: 0.8675\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2748 - accuracy: 0.8633 - val_loss: 0.2763 - val_accuracy: 0.8640\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2744 - accuracy: 0.8626 - val_loss: 0.2741 - val_accuracy: 0.8655\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2737 - accuracy: 0.8645 - val_loss: 0.2724 - val_accuracy: 0.8670\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2733 - accuracy: 0.8644 - val_loss: 0.2737 - val_accuracy: 0.8673\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2728 - accuracy: 0.8647 - val_loss: 0.2724 - val_accuracy: 0.8700\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2723 - accuracy: 0.8643 - val_loss: 0.2706 - val_accuracy: 0.8687\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2719 - accuracy: 0.8657 - val_loss: 0.2725 - val_accuracy: 0.8687\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2714 - accuracy: 0.8651 - val_loss: 0.2711 - val_accuracy: 0.8681\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2709 - accuracy: 0.8658 - val_loss: 0.2737 - val_accuracy: 0.8673\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2706 - accuracy: 0.8662 - val_loss: 0.2714 - val_accuracy: 0.8684\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2703 - accuracy: 0.8663 - val_loss: 0.2702 - val_accuracy: 0.8692\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2696 - accuracy: 0.8662 - val_loss: 0.2697 - val_accuracy: 0.8681\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2695 - accuracy: 0.8667 - val_loss: 0.2701 - val_accuracy: 0.8669\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2690 - accuracy: 0.8669 - val_loss: 0.2697 - val_accuracy: 0.8670\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2685 - accuracy: 0.8665 - val_loss: 0.2723 - val_accuracy: 0.8672\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.8666 - val_loss: 0.2686 - val_accuracy: 0.8701\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2684 - accuracy: 0.8666 - val_loss: 0.2719 - val_accuracy: 0.8672\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2681 - accuracy: 0.8668 - val_loss: 0.2684 - val_accuracy: 0.8700\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2679 - accuracy: 0.8671 - val_loss: 0.2695 - val_accuracy: 0.8670\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2673 - accuracy: 0.8677 - val_loss: 0.2697 - val_accuracy: 0.8694\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2677 - accuracy: 0.8676 - val_loss: 0.2696 - val_accuracy: 0.8661\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2671 - accuracy: 0.8672 - val_loss: 0.2691 - val_accuracy: 0.8694\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2664 - accuracy: 0.8681 - val_loss: 0.2687 - val_accuracy: 0.8694\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2687 - accuracy: 0.8694\n",
            "정확률= 0.8694198727607727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. CNN - 1 + 3 / 16 / X / leaky_relu"
      ],
      "metadata": {
        "id": "SQGkWLYAsMiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn6 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(16, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn6.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn6.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn6.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8711"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgM0t4oxt3wD",
        "outputId": "b2477583-cdb5-4a80-d702-9baf06502c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 4ms/step - loss: 0.3829 - accuracy: 0.8420 - val_loss: 0.3090 - val_accuracy: 0.8592\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3086 - accuracy: 0.8558 - val_loss: 0.3023 - val_accuracy: 0.8620\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3018 - accuracy: 0.8571 - val_loss: 0.2979 - val_accuracy: 0.8572\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2965 - accuracy: 0.8580 - val_loss: 0.2925 - val_accuracy: 0.8600\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2925 - accuracy: 0.8599 - val_loss: 0.2891 - val_accuracy: 0.8598\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2891 - accuracy: 0.8592 - val_loss: 0.2882 - val_accuracy: 0.8609\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2860 - accuracy: 0.8602 - val_loss: 0.2842 - val_accuracy: 0.8623\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2835 - accuracy: 0.8614 - val_loss: 0.2823 - val_accuracy: 0.8624\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.8624 - val_loss: 0.2804 - val_accuracy: 0.8622\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2800 - accuracy: 0.8618 - val_loss: 0.2812 - val_accuracy: 0.8619\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2782 - accuracy: 0.8633 - val_loss: 0.2782 - val_accuracy: 0.8627\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2771 - accuracy: 0.8625 - val_loss: 0.2770 - val_accuracy: 0.8639\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2757 - accuracy: 0.8636 - val_loss: 0.2763 - val_accuracy: 0.8650\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.8641 - val_loss: 0.2746 - val_accuracy: 0.8649\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2729 - accuracy: 0.8652 - val_loss: 0.2749 - val_accuracy: 0.8617\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2722 - accuracy: 0.8659 - val_loss: 0.2718 - val_accuracy: 0.8641\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2708 - accuracy: 0.8671 - val_loss: 0.2740 - val_accuracy: 0.8662\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2703 - accuracy: 0.8654 - val_loss: 0.2727 - val_accuracy: 0.8655\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2691 - accuracy: 0.8667 - val_loss: 0.2706 - val_accuracy: 0.8688\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2686 - accuracy: 0.8670 - val_loss: 0.2701 - val_accuracy: 0.8672\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.8674 - val_loss: 0.2706 - val_accuracy: 0.8695\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2672 - accuracy: 0.8669 - val_loss: 0.2684 - val_accuracy: 0.8700\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.8685 - val_loss: 0.2678 - val_accuracy: 0.8705\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2661 - accuracy: 0.8679 - val_loss: 0.2662 - val_accuracy: 0.8717\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.8680 - val_loss: 0.2677 - val_accuracy: 0.8706\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2649 - accuracy: 0.8683 - val_loss: 0.2662 - val_accuracy: 0.8711\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2649 - accuracy: 0.8677 - val_loss: 0.2676 - val_accuracy: 0.8714\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2644 - accuracy: 0.8678 - val_loss: 0.2671 - val_accuracy: 0.8699\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.8685 - val_loss: 0.2664 - val_accuracy: 0.8715\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2637 - accuracy: 0.8686 - val_loss: 0.2655 - val_accuracy: 0.8709\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2631 - accuracy: 0.8694 - val_loss: 0.2658 - val_accuracy: 0.8717\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2632 - accuracy: 0.8688 - val_loss: 0.2675 - val_accuracy: 0.8684\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2632 - accuracy: 0.8691 - val_loss: 0.2666 - val_accuracy: 0.8703\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2626 - accuracy: 0.8700 - val_loss: 0.2657 - val_accuracy: 0.8713\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2623 - accuracy: 0.8695 - val_loss: 0.2653 - val_accuracy: 0.8702\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2622 - accuracy: 0.8697 - val_loss: 0.2648 - val_accuracy: 0.8717\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.8692 - val_loss: 0.2641 - val_accuracy: 0.8722\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2618 - accuracy: 0.8699 - val_loss: 0.2656 - val_accuracy: 0.8699\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2617 - accuracy: 0.8702 - val_loss: 0.2636 - val_accuracy: 0.8719\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2610 - accuracy: 0.8702 - val_loss: 0.2644 - val_accuracy: 0.8703\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2611 - accuracy: 0.8698 - val_loss: 0.2664 - val_accuracy: 0.8688\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2610 - accuracy: 0.8696 - val_loss: 0.2638 - val_accuracy: 0.8705\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2608 - accuracy: 0.8701 - val_loss: 0.2645 - val_accuracy: 0.8717\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2605 - accuracy: 0.8697 - val_loss: 0.2647 - val_accuracy: 0.8705\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2607 - accuracy: 0.8699 - val_loss: 0.2640 - val_accuracy: 0.8707\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2600 - accuracy: 0.8704 - val_loss: 0.2630 - val_accuracy: 0.8720\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2605 - accuracy: 0.8692 - val_loss: 0.2651 - val_accuracy: 0.8691\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2600 - accuracy: 0.8708 - val_loss: 0.2640 - val_accuracy: 0.8714\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2602 - accuracy: 0.8697 - val_loss: 0.2638 - val_accuracy: 0.8722\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2595 - accuracy: 0.8699 - val_loss: 0.2632 - val_accuracy: 0.8711\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2632 - accuracy: 0.8711\n",
            "정확률= 0.8711451292037964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. CNN - 1 + 4 / 8 / X / leaky_relu"
      ],
      "metadata": {
        "id": "fPYBnuxJsOyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn7 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(8, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn7.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn7.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn7.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8693"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDpkjKuSt3ZR",
        "outputId": "a611e36c-f031-4e52-8ad8-e004b455c3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 4ms/step - loss: 0.3682 - accuracy: 0.8169 - val_loss: 0.3091 - val_accuracy: 0.8586\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3079 - accuracy: 0.8538 - val_loss: 0.3011 - val_accuracy: 0.8595\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3005 - accuracy: 0.8546 - val_loss: 0.2957 - val_accuracy: 0.8599\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2969 - accuracy: 0.8560 - val_loss: 0.2922 - val_accuracy: 0.8582\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2940 - accuracy: 0.8570 - val_loss: 0.2902 - val_accuracy: 0.8610\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2916 - accuracy: 0.8581 - val_loss: 0.2898 - val_accuracy: 0.8593\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2902 - accuracy: 0.8581 - val_loss: 0.2871 - val_accuracy: 0.8575\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2886 - accuracy: 0.8590 - val_loss: 0.2858 - val_accuracy: 0.8589\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2868 - accuracy: 0.8585 - val_loss: 0.2864 - val_accuracy: 0.8622\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2859 - accuracy: 0.8590 - val_loss: 0.2840 - val_accuracy: 0.8581\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2852 - accuracy: 0.8579 - val_loss: 0.2840 - val_accuracy: 0.8601\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2837 - accuracy: 0.8593 - val_loss: 0.2835 - val_accuracy: 0.8619\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2833 - accuracy: 0.8598 - val_loss: 0.2822 - val_accuracy: 0.8596\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2826 - accuracy: 0.8596 - val_loss: 0.2822 - val_accuracy: 0.8613\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2829 - accuracy: 0.8593 - val_loss: 0.2825 - val_accuracy: 0.8613\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2821 - accuracy: 0.8597 - val_loss: 0.2827 - val_accuracy: 0.8601\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2813 - accuracy: 0.8598 - val_loss: 0.2827 - val_accuracy: 0.8633\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2815 - accuracy: 0.8602 - val_loss: 0.2807 - val_accuracy: 0.8622\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2810 - accuracy: 0.8598 - val_loss: 0.2811 - val_accuracy: 0.8610\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2805 - accuracy: 0.8603 - val_loss: 0.2802 - val_accuracy: 0.8620\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2806 - accuracy: 0.8598 - val_loss: 0.2800 - val_accuracy: 0.8615\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2802 - accuracy: 0.8608 - val_loss: 0.2806 - val_accuracy: 0.8607\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2793 - accuracy: 0.8612 - val_loss: 0.2808 - val_accuracy: 0.8611\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.8615 - val_loss: 0.2811 - val_accuracy: 0.8611\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2789 - accuracy: 0.8613 - val_loss: 0.2802 - val_accuracy: 0.8641\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.8609 - val_loss: 0.2796 - val_accuracy: 0.8625\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.8612 - val_loss: 0.2799 - val_accuracy: 0.8656\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2781 - accuracy: 0.8622 - val_loss: 0.2793 - val_accuracy: 0.8663\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2777 - accuracy: 0.8615 - val_loss: 0.2797 - val_accuracy: 0.8610\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2774 - accuracy: 0.8620 - val_loss: 0.2785 - val_accuracy: 0.8649\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2767 - accuracy: 0.8616 - val_loss: 0.2787 - val_accuracy: 0.8652\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2765 - accuracy: 0.8625 - val_loss: 0.2781 - val_accuracy: 0.8656\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2760 - accuracy: 0.8620 - val_loss: 0.2789 - val_accuracy: 0.8646\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2758 - accuracy: 0.8625 - val_loss: 0.2794 - val_accuracy: 0.8658\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2755 - accuracy: 0.8630 - val_loss: 0.2787 - val_accuracy: 0.8658\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2750 - accuracy: 0.8629 - val_loss: 0.2780 - val_accuracy: 0.8644\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2748 - accuracy: 0.8640 - val_loss: 0.2780 - val_accuracy: 0.8617\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2750 - accuracy: 0.8635 - val_loss: 0.2770 - val_accuracy: 0.8655\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8636 - val_loss: 0.2782 - val_accuracy: 0.8638\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2742 - accuracy: 0.8639 - val_loss: 0.2768 - val_accuracy: 0.8641\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2736 - accuracy: 0.8651 - val_loss: 0.2757 - val_accuracy: 0.8658\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2735 - accuracy: 0.8637 - val_loss: 0.2768 - val_accuracy: 0.8661\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2733 - accuracy: 0.8637 - val_loss: 0.2796 - val_accuracy: 0.8651\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2732 - accuracy: 0.8643 - val_loss: 0.2769 - val_accuracy: 0.8649\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2728 - accuracy: 0.8643 - val_loss: 0.2764 - val_accuracy: 0.8635\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2727 - accuracy: 0.8659 - val_loss: 0.2774 - val_accuracy: 0.8626\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2725 - accuracy: 0.8642 - val_loss: 0.2754 - val_accuracy: 0.8656\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2718 - accuracy: 0.8648 - val_loss: 0.2769 - val_accuracy: 0.8639\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2715 - accuracy: 0.8642 - val_loss: 0.2749 - val_accuracy: 0.8661\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2720 - accuracy: 0.8645 - val_loss: 0.2734 - val_accuracy: 0.8660\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2734 - accuracy: 0.8660\n",
            "정확률= 0.8659693598747253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. CNN - 1 + 4 / 16 / X / leaky_relu"
      ],
      "metadata": {
        "id": "hJcbT5hKsb6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn8 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(16, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn8.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn8.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn8.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8707"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHpUolASt4JH",
        "outputId": "cf652227-fbea-44fc-a056-a515d195b27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 4ms/step - loss: 0.3730 - accuracy: 0.8378 - val_loss: 0.3082 - val_accuracy: 0.8597\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3083 - accuracy: 0.8544 - val_loss: 0.3005 - val_accuracy: 0.8601\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3018 - accuracy: 0.8564 - val_loss: 0.2947 - val_accuracy: 0.8597\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2961 - accuracy: 0.8581 - val_loss: 0.2930 - val_accuracy: 0.8645\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2913 - accuracy: 0.8584 - val_loss: 0.2887 - val_accuracy: 0.8636\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2879 - accuracy: 0.8591 - val_loss: 0.2854 - val_accuracy: 0.8633\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2850 - accuracy: 0.8593 - val_loss: 0.2829 - val_accuracy: 0.8617\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2832 - accuracy: 0.8607 - val_loss: 0.2822 - val_accuracy: 0.8632\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2808 - accuracy: 0.8605 - val_loss: 0.2789 - val_accuracy: 0.8654\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2793 - accuracy: 0.8616 - val_loss: 0.2772 - val_accuracy: 0.8661\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2783 - accuracy: 0.8616 - val_loss: 0.2771 - val_accuracy: 0.8659\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2770 - accuracy: 0.8619 - val_loss: 0.2790 - val_accuracy: 0.8655\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2764 - accuracy: 0.8629 - val_loss: 0.2738 - val_accuracy: 0.8674\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2751 - accuracy: 0.8632 - val_loss: 0.2733 - val_accuracy: 0.8673\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.8632 - val_loss: 0.2740 - val_accuracy: 0.8655\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2727 - accuracy: 0.8631 - val_loss: 0.2738 - val_accuracy: 0.8659\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2718 - accuracy: 0.8641 - val_loss: 0.2752 - val_accuracy: 0.8642\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2715 - accuracy: 0.8640 - val_loss: 0.2712 - val_accuracy: 0.8697\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2707 - accuracy: 0.8654 - val_loss: 0.2728 - val_accuracy: 0.8659\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2697 - accuracy: 0.8649 - val_loss: 0.2705 - val_accuracy: 0.8674\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2694 - accuracy: 0.8651 - val_loss: 0.2701 - val_accuracy: 0.8678\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2685 - accuracy: 0.8651 - val_loss: 0.2717 - val_accuracy: 0.8704\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.8666 - val_loss: 0.2720 - val_accuracy: 0.8649\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2669 - accuracy: 0.8663 - val_loss: 0.2710 - val_accuracy: 0.8676\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2665 - accuracy: 0.8670 - val_loss: 0.2700 - val_accuracy: 0.8683\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2659 - accuracy: 0.8667 - val_loss: 0.2688 - val_accuracy: 0.8696\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2650 - accuracy: 0.8679 - val_loss: 0.2693 - val_accuracy: 0.8704\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2653 - accuracy: 0.8675 - val_loss: 0.2666 - val_accuracy: 0.8699\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.8680 - val_loss: 0.2680 - val_accuracy: 0.8669\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2642 - accuracy: 0.8674 - val_loss: 0.2723 - val_accuracy: 0.8674\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2637 - accuracy: 0.8687 - val_loss: 0.2691 - val_accuracy: 0.8688\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2636 - accuracy: 0.8679 - val_loss: 0.2661 - val_accuracy: 0.8697\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2633 - accuracy: 0.8680 - val_loss: 0.2662 - val_accuracy: 0.8708\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2630 - accuracy: 0.8689 - val_loss: 0.2674 - val_accuracy: 0.8691\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2623 - accuracy: 0.8678 - val_loss: 0.2725 - val_accuracy: 0.8686\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2627 - accuracy: 0.8688 - val_loss: 0.2668 - val_accuracy: 0.8713\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.8681 - val_loss: 0.2659 - val_accuracy: 0.8700\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2622 - accuracy: 0.8691 - val_loss: 0.2670 - val_accuracy: 0.8687\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2616 - accuracy: 0.8686 - val_loss: 0.2662 - val_accuracy: 0.8708\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2620 - accuracy: 0.8679 - val_loss: 0.2675 - val_accuracy: 0.8688\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2611 - accuracy: 0.8693 - val_loss: 0.2671 - val_accuracy: 0.8687\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.8683 - val_loss: 0.2660 - val_accuracy: 0.8717\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2608 - accuracy: 0.8696 - val_loss: 0.2691 - val_accuracy: 0.8693\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2609 - accuracy: 0.8699 - val_loss: 0.2685 - val_accuracy: 0.8667\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2607 - accuracy: 0.8690 - val_loss: 0.2681 - val_accuracy: 0.8693\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2606 - accuracy: 0.8688 - val_loss: 0.2665 - val_accuracy: 0.8680\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2609 - accuracy: 0.8688 - val_loss: 0.2754 - val_accuracy: 0.8641\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2604 - accuracy: 0.8678 - val_loss: 0.2675 - val_accuracy: 0.8683\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2609 - accuracy: 0.8688 - val_loss: 0.2655 - val_accuracy: 0.8688\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2596 - accuracy: 0.8698 - val_loss: 0.2641 - val_accuracy: 0.8707\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.8707\n",
            "정확률= 0.8707138299942017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. CNN - 1 + 5 / 8 / X / leaky_relu"
      ],
      "metadata": {
        "id": "lPOPRvOksfRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn9 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(8, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn9.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn9.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn9.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8714"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKVxwZ2mt4jA",
        "outputId": "980a6c5a-8ca2-4cc8-f9a1-ea2add6c9009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 5ms/step - loss: 0.3767 - accuracy: 0.8255 - val_loss: 0.3221 - val_accuracy: 0.8523\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3129 - accuracy: 0.8526 - val_loss: 0.3115 - val_accuracy: 0.8559\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3048 - accuracy: 0.8559 - val_loss: 0.3048 - val_accuracy: 0.8587\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2995 - accuracy: 0.8580 - val_loss: 0.3071 - val_accuracy: 0.8586\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.2951 - accuracy: 0.8599 - val_loss: 0.2933 - val_accuracy: 0.8610\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.2906 - accuracy: 0.8606 - val_loss: 0.2902 - val_accuracy: 0.8641\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2875 - accuracy: 0.8620 - val_loss: 0.2882 - val_accuracy: 0.8615\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2851 - accuracy: 0.8626 - val_loss: 0.2852 - val_accuracy: 0.8650\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2832 - accuracy: 0.8616 - val_loss: 0.2841 - val_accuracy: 0.8652\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2815 - accuracy: 0.8629 - val_loss: 0.2844 - val_accuracy: 0.8626\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2806 - accuracy: 0.8634 - val_loss: 0.2821 - val_accuracy: 0.8652\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2793 - accuracy: 0.8631 - val_loss: 0.2819 - val_accuracy: 0.8656\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2794 - accuracy: 0.8635 - val_loss: 0.2787 - val_accuracy: 0.8662\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2785 - accuracy: 0.8634 - val_loss: 0.2811 - val_accuracy: 0.8657\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2767 - accuracy: 0.8629 - val_loss: 0.2786 - val_accuracy: 0.8667\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2768 - accuracy: 0.8642 - val_loss: 0.2796 - val_accuracy: 0.8672\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2759 - accuracy: 0.8638 - val_loss: 0.2763 - val_accuracy: 0.8686\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2756 - accuracy: 0.8647 - val_loss: 0.2793 - val_accuracy: 0.8664\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2754 - accuracy: 0.8646 - val_loss: 0.2768 - val_accuracy: 0.8670\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2753 - accuracy: 0.8640 - val_loss: 0.2750 - val_accuracy: 0.8671\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2740 - accuracy: 0.8652 - val_loss: 0.2788 - val_accuracy: 0.8666\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2747 - accuracy: 0.8651 - val_loss: 0.2788 - val_accuracy: 0.8654\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2736 - accuracy: 0.8645 - val_loss: 0.2743 - val_accuracy: 0.8687\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2734 - accuracy: 0.8654 - val_loss: 0.2749 - val_accuracy: 0.8701\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2728 - accuracy: 0.8654 - val_loss: 0.2727 - val_accuracy: 0.8689\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2731 - accuracy: 0.8658 - val_loss: 0.2736 - val_accuracy: 0.8710\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2726 - accuracy: 0.8659 - val_loss: 0.2729 - val_accuracy: 0.8691\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2724 - accuracy: 0.8659 - val_loss: 0.2752 - val_accuracy: 0.8672\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2722 - accuracy: 0.8661 - val_loss: 0.2750 - val_accuracy: 0.8678\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2715 - accuracy: 0.8661 - val_loss: 0.2742 - val_accuracy: 0.8685\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2712 - accuracy: 0.8659 - val_loss: 0.2729 - val_accuracy: 0.8699\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2717 - accuracy: 0.8668 - val_loss: 0.2730 - val_accuracy: 0.8703\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2712 - accuracy: 0.8659 - val_loss: 0.2778 - val_accuracy: 0.8661\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2715 - accuracy: 0.8666 - val_loss: 0.2729 - val_accuracy: 0.8681\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2713 - accuracy: 0.8664 - val_loss: 0.2743 - val_accuracy: 0.8680\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2707 - accuracy: 0.8666 - val_loss: 0.2716 - val_accuracy: 0.8716\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2702 - accuracy: 0.8670 - val_loss: 0.2713 - val_accuracy: 0.8711\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2700 - accuracy: 0.8670 - val_loss: 0.2711 - val_accuracy: 0.8695\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2705 - accuracy: 0.8669 - val_loss: 0.2709 - val_accuracy: 0.8705\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2698 - accuracy: 0.8661 - val_loss: 0.2724 - val_accuracy: 0.8705\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2697 - accuracy: 0.8665 - val_loss: 0.2713 - val_accuracy: 0.8697\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2697 - accuracy: 0.8665 - val_loss: 0.2714 - val_accuracy: 0.8708\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2695 - accuracy: 0.8675 - val_loss: 0.2717 - val_accuracy: 0.8720\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2691 - accuracy: 0.8666 - val_loss: 0.2718 - val_accuracy: 0.8698\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2703 - accuracy: 0.8670 - val_loss: 0.2719 - val_accuracy: 0.8706\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2689 - accuracy: 0.8671 - val_loss: 0.2716 - val_accuracy: 0.8700\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2688 - accuracy: 0.8676 - val_loss: 0.2708 - val_accuracy: 0.8711\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2686 - accuracy: 0.8678 - val_loss: 0.2762 - val_accuracy: 0.8675\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2685 - accuracy: 0.8681 - val_loss: 0.2715 - val_accuracy: 0.8691\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2679 - accuracy: 0.8665 - val_loss: 0.2707 - val_accuracy: 0.8721\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2707 - accuracy: 0.8721\n",
            "정확률= 0.8720741868019104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. CNN - 1 + 5 / 16 / X / leaky_relu"
      ],
      "metadata": {
        "id": "Pq93_5-4shbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn10 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(16, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn10.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn10.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn10.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8706"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRLkld3kt47t",
        "outputId": "d05cff35-27c2-4986-e400-5eb1e9ab12a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 4ms/step - loss: 0.3705 - accuracy: 0.8370 - val_loss: 0.3063 - val_accuracy: 0.8571\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3039 - accuracy: 0.8567 - val_loss: 0.2972 - val_accuracy: 0.8604\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2971 - accuracy: 0.8581 - val_loss: 0.2932 - val_accuracy: 0.8605\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2930 - accuracy: 0.8583 - val_loss: 0.2944 - val_accuracy: 0.8570\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2886 - accuracy: 0.8599 - val_loss: 0.2921 - val_accuracy: 0.8601\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2874 - accuracy: 0.8596 - val_loss: 0.2863 - val_accuracy: 0.8612\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2840 - accuracy: 0.8607 - val_loss: 0.2840 - val_accuracy: 0.8620\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2822 - accuracy: 0.8620 - val_loss: 0.2836 - val_accuracy: 0.8626\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2799 - accuracy: 0.8631 - val_loss: 0.2803 - val_accuracy: 0.8665\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.8623 - val_loss: 0.2792 - val_accuracy: 0.8650\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2768 - accuracy: 0.8629 - val_loss: 0.2854 - val_accuracy: 0.8613\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2755 - accuracy: 0.8647 - val_loss: 0.2787 - val_accuracy: 0.8658\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2752 - accuracy: 0.8631 - val_loss: 0.2783 - val_accuracy: 0.8655\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2754 - accuracy: 0.8629 - val_loss: 0.2788 - val_accuracy: 0.8647\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2742 - accuracy: 0.8638 - val_loss: 0.2767 - val_accuracy: 0.8663\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2734 - accuracy: 0.8662 - val_loss: 0.2741 - val_accuracy: 0.8670\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2733 - accuracy: 0.8648 - val_loss: 0.2746 - val_accuracy: 0.8659\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2719 - accuracy: 0.8653 - val_loss: 0.2754 - val_accuracy: 0.8647\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2719 - accuracy: 0.8656 - val_loss: 0.2745 - val_accuracy: 0.8655\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2717 - accuracy: 0.8669 - val_loss: 0.2751 - val_accuracy: 0.8625\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2706 - accuracy: 0.8656 - val_loss: 0.2737 - val_accuracy: 0.8659\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2701 - accuracy: 0.8659 - val_loss: 0.2730 - val_accuracy: 0.8636\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2702 - accuracy: 0.8663 - val_loss: 0.2721 - val_accuracy: 0.8680\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2702 - accuracy: 0.8655 - val_loss: 0.2765 - val_accuracy: 0.8668\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2694 - accuracy: 0.8670 - val_loss: 0.2734 - val_accuracy: 0.8670\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.8670 - val_loss: 0.2724 - val_accuracy: 0.8652\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2676 - accuracy: 0.8677 - val_loss: 0.2706 - val_accuracy: 0.8670\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2678 - accuracy: 0.8680 - val_loss: 0.2730 - val_accuracy: 0.8674\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2675 - accuracy: 0.8688 - val_loss: 0.2707 - val_accuracy: 0.8677\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.8680 - val_loss: 0.2682 - val_accuracy: 0.8696\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2667 - accuracy: 0.8677 - val_loss: 0.2713 - val_accuracy: 0.8678\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.8683 - val_loss: 0.2766 - val_accuracy: 0.8681\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2663 - accuracy: 0.8691 - val_loss: 0.2747 - val_accuracy: 0.8674\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.2656 - accuracy: 0.8684 - val_loss: 0.2714 - val_accuracy: 0.8662\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2659 - accuracy: 0.8686 - val_loss: 0.2722 - val_accuracy: 0.8668\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2655 - accuracy: 0.8685 - val_loss: 0.2693 - val_accuracy: 0.8695\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.8679 - val_loss: 0.2675 - val_accuracy: 0.8687\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2640 - accuracy: 0.8683 - val_loss: 0.2690 - val_accuracy: 0.8663\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2640 - accuracy: 0.8692 - val_loss: 0.2691 - val_accuracy: 0.8683\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2651 - accuracy: 0.8685 - val_loss: 0.2682 - val_accuracy: 0.8688\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2644 - accuracy: 0.8684 - val_loss: 0.2708 - val_accuracy: 0.8695\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2645 - accuracy: 0.8688 - val_loss: 0.2705 - val_accuracy: 0.8678\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2629 - accuracy: 0.8684 - val_loss: 0.2699 - val_accuracy: 0.8663\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2636 - accuracy: 0.8684 - val_loss: 0.2685 - val_accuracy: 0.8656\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2638 - accuracy: 0.8685 - val_loss: 0.2680 - val_accuracy: 0.8681\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.2630 - accuracy: 0.8691 - val_loss: 0.2718 - val_accuracy: 0.8681\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.2638 - accuracy: 0.8700 - val_loss: 0.2696 - val_accuracy: 0.8675\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.2628 - accuracy: 0.8692 - val_loss: 0.2681 - val_accuracy: 0.8684\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2632 - accuracy: 0.8688 - val_loss: 0.2686 - val_accuracy: 0.8696\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.2626 - accuracy: 0.8702 - val_loss: 0.2692 - val_accuracy: 0.8686\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2692 - accuracy: 0.8686\n",
            "정확률= 0.8685572743415833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. CNN - 1 + 1 / 8 / O / leaky_relu"
      ],
      "metadata": {
        "id": "2UJ8xRf0sm6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn11 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(8, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn11.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn11.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn11.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8568"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdxDYd3qt5VC",
        "outputId": "68876500-c0f3-4797-e424-cd95f8181dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 2s 4ms/step - loss: 0.4774 - accuracy: 0.7710 - val_loss: 0.3210 - val_accuracy: 0.8539\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3691 - accuracy: 0.8373 - val_loss: 0.3109 - val_accuracy: 0.8550\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3562 - accuracy: 0.8431 - val_loss: 0.3091 - val_accuracy: 0.8558\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3505 - accuracy: 0.8430 - val_loss: 0.3082 - val_accuracy: 0.8566\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3451 - accuracy: 0.8437 - val_loss: 0.3076 - val_accuracy: 0.8564\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3445 - accuracy: 0.8446 - val_loss: 0.3072 - val_accuracy: 0.8569\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3439 - accuracy: 0.8443 - val_loss: 0.3077 - val_accuracy: 0.8568\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3430 - accuracy: 0.8427 - val_loss: 0.3072 - val_accuracy: 0.8563\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3417 - accuracy: 0.8444 - val_loss: 0.3076 - val_accuracy: 0.8568\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3395 - accuracy: 0.8438 - val_loss: 0.3073 - val_accuracy: 0.8563\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.8435 - val_loss: 0.3073 - val_accuracy: 0.8560\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3424 - accuracy: 0.8429 - val_loss: 0.3074 - val_accuracy: 0.8564\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3425 - accuracy: 0.8443 - val_loss: 0.3071 - val_accuracy: 0.8572\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3419 - accuracy: 0.8462 - val_loss: 0.3072 - val_accuracy: 0.8568\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3409 - accuracy: 0.8464 - val_loss: 0.3066 - val_accuracy: 0.8567\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3408 - accuracy: 0.8461 - val_loss: 0.3065 - val_accuracy: 0.8568\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.8450 - val_loss: 0.3065 - val_accuracy: 0.8566\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3390 - accuracy: 0.8444 - val_loss: 0.3060 - val_accuracy: 0.8565\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3394 - accuracy: 0.8469 - val_loss: 0.3063 - val_accuracy: 0.8565\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3417 - accuracy: 0.8448 - val_loss: 0.3062 - val_accuracy: 0.8564\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3399 - accuracy: 0.8440 - val_loss: 0.3064 - val_accuracy: 0.8563\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3422 - accuracy: 0.8456 - val_loss: 0.3059 - val_accuracy: 0.8567\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3398 - accuracy: 0.8451 - val_loss: 0.3062 - val_accuracy: 0.8564\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3393 - accuracy: 0.8469 - val_loss: 0.3058 - val_accuracy: 0.8555\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.8455 - val_loss: 0.3057 - val_accuracy: 0.8566\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.8458 - val_loss: 0.3057 - val_accuracy: 0.8576\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3390 - accuracy: 0.8454 - val_loss: 0.3054 - val_accuracy: 0.8553\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8445 - val_loss: 0.3055 - val_accuracy: 0.8568\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8455 - val_loss: 0.3055 - val_accuracy: 0.8552\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.8458 - val_loss: 0.3058 - val_accuracy: 0.8575\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3392 - accuracy: 0.8465 - val_loss: 0.3060 - val_accuracy: 0.8555\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8464 - val_loss: 0.3058 - val_accuracy: 0.8560\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3371 - accuracy: 0.8463 - val_loss: 0.3056 - val_accuracy: 0.8558\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3393 - accuracy: 0.8451 - val_loss: 0.3055 - val_accuracy: 0.8568\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3394 - accuracy: 0.8454 - val_loss: 0.3051 - val_accuracy: 0.8558\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3401 - accuracy: 0.8448 - val_loss: 0.3059 - val_accuracy: 0.8551\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3382 - accuracy: 0.8461 - val_loss: 0.3058 - val_accuracy: 0.8564\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3374 - accuracy: 0.8463 - val_loss: 0.3051 - val_accuracy: 0.8556\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3383 - accuracy: 0.8462 - val_loss: 0.3052 - val_accuracy: 0.8550\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8450 - val_loss: 0.3050 - val_accuracy: 0.8567\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3371 - accuracy: 0.8452 - val_loss: 0.3052 - val_accuracy: 0.8568\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3383 - accuracy: 0.8461 - val_loss: 0.3053 - val_accuracy: 0.8562\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3385 - accuracy: 0.8444 - val_loss: 0.3045 - val_accuracy: 0.8569\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3374 - accuracy: 0.8456 - val_loss: 0.3051 - val_accuracy: 0.8569\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8444 - val_loss: 0.3049 - val_accuracy: 0.8568\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8452 - val_loss: 0.3055 - val_accuracy: 0.8559\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3376 - accuracy: 0.8446 - val_loss: 0.3048 - val_accuracy: 0.8567\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3369 - accuracy: 0.8457 - val_loss: 0.3049 - val_accuracy: 0.8566\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.8451 - val_loss: 0.3049 - val_accuracy: 0.8567\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.8449 - val_loss: 0.3047 - val_accuracy: 0.8568\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3047 - accuracy: 0.8568\n",
            "정확률= 0.8568039536476135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. CNN - 1 + 1 / 16 / O / leaky_relu"
      ],
      "metadata": {
        "id": "or35zpFnsnOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn12 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(16, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn12.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn12.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn12.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8581"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLL_jsZjt5xI",
        "outputId": "e09c14af-3ae4-4157-ae4c-21c09624856f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 2s 4ms/step - loss: 0.4744 - accuracy: 0.7728 - val_loss: 0.3128 - val_accuracy: 0.8548\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3490 - accuracy: 0.8454 - val_loss: 0.3065 - val_accuracy: 0.8573\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3394 - accuracy: 0.8492 - val_loss: 0.3054 - val_accuracy: 0.8582\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8489 - val_loss: 0.3053 - val_accuracy: 0.8571\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.8483 - val_loss: 0.3043 - val_accuracy: 0.8578\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.8502 - val_loss: 0.3046 - val_accuracy: 0.8565\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8485 - val_loss: 0.3034 - val_accuracy: 0.8568\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8491 - val_loss: 0.3026 - val_accuracy: 0.8575\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3289 - accuracy: 0.8485 - val_loss: 0.3024 - val_accuracy: 0.8559\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3280 - accuracy: 0.8487 - val_loss: 0.3020 - val_accuracy: 0.8552\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3271 - accuracy: 0.8495 - val_loss: 0.3022 - val_accuracy: 0.8555\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3275 - accuracy: 0.8498 - val_loss: 0.3011 - val_accuracy: 0.8576\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3269 - accuracy: 0.8476 - val_loss: 0.3011 - val_accuracy: 0.8585\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3265 - accuracy: 0.8490 - val_loss: 0.3004 - val_accuracy: 0.8576\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3282 - accuracy: 0.8493 - val_loss: 0.3007 - val_accuracy: 0.8586\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3285 - accuracy: 0.8488 - val_loss: 0.3009 - val_accuracy: 0.8568\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.8480 - val_loss: 0.3004 - val_accuracy: 0.8571\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3253 - accuracy: 0.8493 - val_loss: 0.3000 - val_accuracy: 0.8586\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3252 - accuracy: 0.8490 - val_loss: 0.2997 - val_accuracy: 0.8598\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8490 - val_loss: 0.2995 - val_accuracy: 0.8572\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3258 - accuracy: 0.8503 - val_loss: 0.2999 - val_accuracy: 0.8584\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8487 - val_loss: 0.2996 - val_accuracy: 0.8560\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3229 - accuracy: 0.8497 - val_loss: 0.2991 - val_accuracy: 0.8575\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3267 - accuracy: 0.8488 - val_loss: 0.2990 - val_accuracy: 0.8591\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3238 - accuracy: 0.8487 - val_loss: 0.2988 - val_accuracy: 0.8577\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3248 - accuracy: 0.8478 - val_loss: 0.2984 - val_accuracy: 0.8568\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3235 - accuracy: 0.8488 - val_loss: 0.2984 - val_accuracy: 0.8583\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3229 - accuracy: 0.8483 - val_loss: 0.2979 - val_accuracy: 0.8576\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.8509 - val_loss: 0.2982 - val_accuracy: 0.8581\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3252 - accuracy: 0.8496 - val_loss: 0.2977 - val_accuracy: 0.8571\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8493 - val_loss: 0.2975 - val_accuracy: 0.8577\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3216 - accuracy: 0.8500 - val_loss: 0.2972 - val_accuracy: 0.8570\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3213 - accuracy: 0.8510 - val_loss: 0.2972 - val_accuracy: 0.8590\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8488 - val_loss: 0.2965 - val_accuracy: 0.8585\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3204 - accuracy: 0.8513 - val_loss: 0.2970 - val_accuracy: 0.8584\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3230 - accuracy: 0.8494 - val_loss: 0.2971 - val_accuracy: 0.8572\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3219 - accuracy: 0.8482 - val_loss: 0.2965 - val_accuracy: 0.8590\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8496 - val_loss: 0.2960 - val_accuracy: 0.8578\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8493 - val_loss: 0.2960 - val_accuracy: 0.8581\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3223 - accuracy: 0.8479 - val_loss: 0.2963 - val_accuracy: 0.8571\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3223 - accuracy: 0.8493 - val_loss: 0.2963 - val_accuracy: 0.8582\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3219 - accuracy: 0.8488 - val_loss: 0.2967 - val_accuracy: 0.8570\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3213 - accuracy: 0.8487 - val_loss: 0.2958 - val_accuracy: 0.8575\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3217 - accuracy: 0.8478 - val_loss: 0.2960 - val_accuracy: 0.8578\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3222 - accuracy: 0.8500 - val_loss: 0.2960 - val_accuracy: 0.8594\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3222 - accuracy: 0.8477 - val_loss: 0.2960 - val_accuracy: 0.8577\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8479 - val_loss: 0.2965 - val_accuracy: 0.8590\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.8501 - val_loss: 0.2956 - val_accuracy: 0.8582\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3214 - accuracy: 0.8486 - val_loss: 0.2960 - val_accuracy: 0.8582\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8483 - val_loss: 0.2958 - val_accuracy: 0.8581\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2958 - accuracy: 0.8581\n",
            "정확률= 0.8580979108810425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. CNN - 1 + 2 / 8 / O / leaky_relu"
      ],
      "metadata": {
        "id": "fuLyzHytstkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn13 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(8, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn13.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn13.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn13.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8568"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm4C7tUvt6Kj",
        "outputId": "4a195cdb-c1ae-4c87-86c5-dd76e35e9c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 2s 4ms/step - loss: 0.4941 - accuracy: 0.7592 - val_loss: 0.3214 - val_accuracy: 0.8476\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3741 - accuracy: 0.8338 - val_loss: 0.3116 - val_accuracy: 0.8556\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3607 - accuracy: 0.8404 - val_loss: 0.3093 - val_accuracy: 0.8560\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3547 - accuracy: 0.8430 - val_loss: 0.3092 - val_accuracy: 0.8556\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3534 - accuracy: 0.8431 - val_loss: 0.3085 - val_accuracy: 0.8577\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3515 - accuracy: 0.8428 - val_loss: 0.3086 - val_accuracy: 0.8559\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3499 - accuracy: 0.8438 - val_loss: 0.3091 - val_accuracy: 0.8559\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3473 - accuracy: 0.8438 - val_loss: 0.3082 - val_accuracy: 0.8564\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3502 - accuracy: 0.8434 - val_loss: 0.3076 - val_accuracy: 0.8572\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3468 - accuracy: 0.8446 - val_loss: 0.3086 - val_accuracy: 0.8569\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3472 - accuracy: 0.8451 - val_loss: 0.3074 - val_accuracy: 0.8571\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3450 - accuracy: 0.8451 - val_loss: 0.3071 - val_accuracy: 0.8571\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3466 - accuracy: 0.8453 - val_loss: 0.3068 - val_accuracy: 0.8565\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3456 - accuracy: 0.8448 - val_loss: 0.3071 - val_accuracy: 0.8572\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3463 - accuracy: 0.8445 - val_loss: 0.3065 - val_accuracy: 0.8568\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3445 - accuracy: 0.8431 - val_loss: 0.3066 - val_accuracy: 0.8566\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3435 - accuracy: 0.8459 - val_loss: 0.3068 - val_accuracy: 0.8571\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3438 - accuracy: 0.8439 - val_loss: 0.3065 - val_accuracy: 0.8563\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3435 - accuracy: 0.8457 - val_loss: 0.3070 - val_accuracy: 0.8576\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3435 - accuracy: 0.8445 - val_loss: 0.3061 - val_accuracy: 0.8579\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3453 - accuracy: 0.8467 - val_loss: 0.3059 - val_accuracy: 0.8570\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3439 - accuracy: 0.8446 - val_loss: 0.3062 - val_accuracy: 0.8572\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3415 - accuracy: 0.8450 - val_loss: 0.3058 - val_accuracy: 0.8579\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3442 - accuracy: 0.8450 - val_loss: 0.3055 - val_accuracy: 0.8568\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3428 - accuracy: 0.8460 - val_loss: 0.3063 - val_accuracy: 0.8556\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3429 - accuracy: 0.8454 - val_loss: 0.3057 - val_accuracy: 0.8558\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3434 - accuracy: 0.8450 - val_loss: 0.3057 - val_accuracy: 0.8575\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3437 - accuracy: 0.8454 - val_loss: 0.3056 - val_accuracy: 0.8572\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.8448 - val_loss: 0.3059 - val_accuracy: 0.8567\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3442 - accuracy: 0.8457 - val_loss: 0.3054 - val_accuracy: 0.8576\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3412 - accuracy: 0.8459 - val_loss: 0.3050 - val_accuracy: 0.8580\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3399 - accuracy: 0.8475 - val_loss: 0.3053 - val_accuracy: 0.8580\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3436 - accuracy: 0.8443 - val_loss: 0.3056 - val_accuracy: 0.8573\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.8462 - val_loss: 0.3053 - val_accuracy: 0.8566\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3440 - accuracy: 0.8442 - val_loss: 0.3053 - val_accuracy: 0.8571\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3414 - accuracy: 0.8447 - val_loss: 0.3055 - val_accuracy: 0.8576\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3396 - accuracy: 0.8459 - val_loss: 0.3052 - val_accuracy: 0.8572\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3424 - accuracy: 0.8442 - val_loss: 0.3052 - val_accuracy: 0.8578\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3415 - accuracy: 0.8454 - val_loss: 0.3047 - val_accuracy: 0.8570\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.8447 - val_loss: 0.3052 - val_accuracy: 0.8568\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.8454 - val_loss: 0.3055 - val_accuracy: 0.8566\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3407 - accuracy: 0.8452 - val_loss: 0.3051 - val_accuracy: 0.8589\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8453 - val_loss: 0.3054 - val_accuracy: 0.8586\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3408 - accuracy: 0.8456 - val_loss: 0.3049 - val_accuracy: 0.8577\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3404 - accuracy: 0.8445 - val_loss: 0.3049 - val_accuracy: 0.8569\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3401 - accuracy: 0.8460 - val_loss: 0.3049 - val_accuracy: 0.8565\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3401 - accuracy: 0.8456 - val_loss: 0.3045 - val_accuracy: 0.8572\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3430 - accuracy: 0.8451 - val_loss: 0.3052 - val_accuracy: 0.8580\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3415 - accuracy: 0.8446 - val_loss: 0.3048 - val_accuracy: 0.8572\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8454 - val_loss: 0.3042 - val_accuracy: 0.8571\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3042 - accuracy: 0.8571\n",
            "정확률= 0.8571274280548096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. CNN - 1 + 2 / 16 / O / leaky_relu"
      ],
      "metadata": {
        "id": "jmZFkh-ssvxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn14 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(16, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn14.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn14.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn14.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8592"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmwpmpRKt6jH",
        "outputId": "98d2b1bc-0921-4edb-bcfb-70757509e4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 2s 4ms/step - loss: 0.4867 - accuracy: 0.7566 - val_loss: 0.3148 - val_accuracy: 0.8535\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3635 - accuracy: 0.8425 - val_loss: 0.3106 - val_accuracy: 0.8548\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3494 - accuracy: 0.8451 - val_loss: 0.3094 - val_accuracy: 0.8550\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3436 - accuracy: 0.8457 - val_loss: 0.3087 - val_accuracy: 0.8558\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8473 - val_loss: 0.3063 - val_accuracy: 0.8570\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3413 - accuracy: 0.8450 - val_loss: 0.3051 - val_accuracy: 0.8573\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3377 - accuracy: 0.8454 - val_loss: 0.3039 - val_accuracy: 0.8583\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3356 - accuracy: 0.8474 - val_loss: 0.3029 - val_accuracy: 0.8593\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3303 - accuracy: 0.8484 - val_loss: 0.3024 - val_accuracy: 0.8587\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.8464 - val_loss: 0.3024 - val_accuracy: 0.8581\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.8468 - val_loss: 0.3017 - val_accuracy: 0.8579\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8457 - val_loss: 0.3013 - val_accuracy: 0.8562\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3344 - accuracy: 0.8465 - val_loss: 0.3003 - val_accuracy: 0.8581\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8478 - val_loss: 0.2997 - val_accuracy: 0.8587\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8468 - val_loss: 0.2999 - val_accuracy: 0.8580\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3333 - accuracy: 0.8472 - val_loss: 0.2994 - val_accuracy: 0.8580\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.8484 - val_loss: 0.2989 - val_accuracy: 0.8592\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3332 - accuracy: 0.8461 - val_loss: 0.2988 - val_accuracy: 0.8592\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8470 - val_loss: 0.2983 - val_accuracy: 0.8592\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8475 - val_loss: 0.2979 - val_accuracy: 0.8593\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3319 - accuracy: 0.8479 - val_loss: 0.2993 - val_accuracy: 0.8576\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3284 - accuracy: 0.8460 - val_loss: 0.2983 - val_accuracy: 0.8570\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3305 - accuracy: 0.8460 - val_loss: 0.2981 - val_accuracy: 0.8586\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8477 - val_loss: 0.2985 - val_accuracy: 0.8592\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.8455 - val_loss: 0.2976 - val_accuracy: 0.8584\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8466 - val_loss: 0.2964 - val_accuracy: 0.8583\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8462 - val_loss: 0.2966 - val_accuracy: 0.8591\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.8451 - val_loss: 0.2977 - val_accuracy: 0.8587\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.8465 - val_loss: 0.2971 - val_accuracy: 0.8587\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3306 - accuracy: 0.8462 - val_loss: 0.2966 - val_accuracy: 0.8604\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8452 - val_loss: 0.2968 - val_accuracy: 0.8584\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8476 - val_loss: 0.2976 - val_accuracy: 0.8596\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3287 - accuracy: 0.8477 - val_loss: 0.2979 - val_accuracy: 0.8597\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.8477 - val_loss: 0.2965 - val_accuracy: 0.8590\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3277 - accuracy: 0.8497 - val_loss: 0.2957 - val_accuracy: 0.8606\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3284 - accuracy: 0.8472 - val_loss: 0.2966 - val_accuracy: 0.8599\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3288 - accuracy: 0.8474 - val_loss: 0.2968 - val_accuracy: 0.8592\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.8482 - val_loss: 0.2964 - val_accuracy: 0.8609\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8472 - val_loss: 0.2957 - val_accuracy: 0.8611\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3297 - accuracy: 0.8470 - val_loss: 0.2958 - val_accuracy: 0.8601\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3288 - accuracy: 0.8466 - val_loss: 0.2956 - val_accuracy: 0.8595\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3288 - accuracy: 0.8472 - val_loss: 0.2956 - val_accuracy: 0.8601\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3306 - accuracy: 0.8457 - val_loss: 0.2949 - val_accuracy: 0.8613\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3286 - accuracy: 0.8481 - val_loss: 0.2947 - val_accuracy: 0.8601\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.8478 - val_loss: 0.2946 - val_accuracy: 0.8601\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.8472 - val_loss: 0.2950 - val_accuracy: 0.8610\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3259 - accuracy: 0.8473 - val_loss: 0.2939 - val_accuracy: 0.8601\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3286 - accuracy: 0.8454 - val_loss: 0.2951 - val_accuracy: 0.8604\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3272 - accuracy: 0.8456 - val_loss: 0.2945 - val_accuracy: 0.8607\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3269 - accuracy: 0.8481 - val_loss: 0.2941 - val_accuracy: 0.8618\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2941 - accuracy: 0.8618\n",
            "정확률= 0.8617640733718872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. CNN - 1 + 3 / 8 / O / leaky_relu"
      ],
      "metadata": {
        "id": "8Dp6d981sywz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn15 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(8, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn15.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn15.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn15.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8584"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cojN83tZt6-9",
        "outputId": "1ebe240a-1453-4f7a-9f4e-bef54c72ba0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 5ms/step - loss: 0.5337 - accuracy: 0.7172 - val_loss: 0.3259 - val_accuracy: 0.8532\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3971 - accuracy: 0.8242 - val_loss: 0.3111 - val_accuracy: 0.8566\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3776 - accuracy: 0.8363 - val_loss: 0.3088 - val_accuracy: 0.8559\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3664 - accuracy: 0.8392 - val_loss: 0.3093 - val_accuracy: 0.8545\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3619 - accuracy: 0.8406 - val_loss: 0.3076 - val_accuracy: 0.8560\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3570 - accuracy: 0.8423 - val_loss: 0.3081 - val_accuracy: 0.8550\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3569 - accuracy: 0.8409 - val_loss: 0.3080 - val_accuracy: 0.8553\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3545 - accuracy: 0.8415 - val_loss: 0.3076 - val_accuracy: 0.8548\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3543 - accuracy: 0.8407 - val_loss: 0.3083 - val_accuracy: 0.8554\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 3s 11ms/step - loss: 0.3540 - accuracy: 0.8412 - val_loss: 0.3070 - val_accuracy: 0.8572\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3519 - accuracy: 0.8425 - val_loss: 0.3078 - val_accuracy: 0.8543\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3504 - accuracy: 0.8433 - val_loss: 0.3063 - val_accuracy: 0.8565\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3558 - accuracy: 0.8425 - val_loss: 0.3068 - val_accuracy: 0.8550\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3530 - accuracy: 0.8415 - val_loss: 0.3080 - val_accuracy: 0.8566\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3530 - accuracy: 0.8411 - val_loss: 0.3071 - val_accuracy: 0.8557\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3513 - accuracy: 0.8425 - val_loss: 0.3079 - val_accuracy: 0.8555\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3537 - accuracy: 0.8409 - val_loss: 0.3071 - val_accuracy: 0.8556\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 3s 10ms/step - loss: 0.3508 - accuracy: 0.8428 - val_loss: 0.3075 - val_accuracy: 0.8545\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3514 - accuracy: 0.8410 - val_loss: 0.3071 - val_accuracy: 0.8550\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3504 - accuracy: 0.8425 - val_loss: 0.3074 - val_accuracy: 0.8546\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3473 - accuracy: 0.8423 - val_loss: 0.3072 - val_accuracy: 0.8558\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3497 - accuracy: 0.8414 - val_loss: 0.3070 - val_accuracy: 0.8563\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3512 - accuracy: 0.8417 - val_loss: 0.3068 - val_accuracy: 0.8560\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3500 - accuracy: 0.8419 - val_loss: 0.3066 - val_accuracy: 0.8567\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3501 - accuracy: 0.8420 - val_loss: 0.3064 - val_accuracy: 0.8563\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3496 - accuracy: 0.8427 - val_loss: 0.3060 - val_accuracy: 0.8562\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3468 - accuracy: 0.8413 - val_loss: 0.3068 - val_accuracy: 0.8565\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3466 - accuracy: 0.8422 - val_loss: 0.3076 - val_accuracy: 0.8552\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3472 - accuracy: 0.8420 - val_loss: 0.3075 - val_accuracy: 0.8565\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3508 - accuracy: 0.8431 - val_loss: 0.3064 - val_accuracy: 0.8565\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3495 - accuracy: 0.8410 - val_loss: 0.3062 - val_accuracy: 0.8563\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3514 - accuracy: 0.8430 - val_loss: 0.3066 - val_accuracy: 0.8555\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3446 - accuracy: 0.8448 - val_loss: 0.3059 - val_accuracy: 0.8565\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3496 - accuracy: 0.8445 - val_loss: 0.3066 - val_accuracy: 0.8560\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3475 - accuracy: 0.8425 - val_loss: 0.3065 - val_accuracy: 0.8571\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3482 - accuracy: 0.8422 - val_loss: 0.3059 - val_accuracy: 0.8564\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3463 - accuracy: 0.8421 - val_loss: 0.3062 - val_accuracy: 0.8552\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3487 - accuracy: 0.8414 - val_loss: 0.3063 - val_accuracy: 0.8558\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3475 - accuracy: 0.8424 - val_loss: 0.3064 - val_accuracy: 0.8550\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3484 - accuracy: 0.8421 - val_loss: 0.3058 - val_accuracy: 0.8556\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3475 - accuracy: 0.8426 - val_loss: 0.3059 - val_accuracy: 0.8571\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3494 - accuracy: 0.8407 - val_loss: 0.3063 - val_accuracy: 0.8555\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3476 - accuracy: 0.8398 - val_loss: 0.3061 - val_accuracy: 0.8565\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3483 - accuracy: 0.8438 - val_loss: 0.3061 - val_accuracy: 0.8566\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3461 - accuracy: 0.8416 - val_loss: 0.3071 - val_accuracy: 0.8562\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3464 - accuracy: 0.8436 - val_loss: 0.3069 - val_accuracy: 0.8559\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3451 - accuracy: 0.8408 - val_loss: 0.3074 - val_accuracy: 0.8572\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3470 - accuracy: 0.8412 - val_loss: 0.3058 - val_accuracy: 0.8558\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3462 - accuracy: 0.8412 - val_loss: 0.3060 - val_accuracy: 0.8563\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3446 - accuracy: 0.8441 - val_loss: 0.3058 - val_accuracy: 0.8560\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3058 - accuracy: 0.8560\n",
            "정확률= 0.8560491800308228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. CNN - 1 + 3 / 16 / O / leaky_relu"
      ],
      "metadata": {
        "id": "De-rdF0as0v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn16 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(16, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn16.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn16.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn16.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8607"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aEEE_Bqt7dM",
        "outputId": "17768ee5-ad33-4543-9720-5bc59b02bb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 4ms/step - loss: 0.5019 - accuracy: 0.7640 - val_loss: 0.3112 - val_accuracy: 0.8545\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8366 - val_loss: 0.3098 - val_accuracy: 0.8572\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3592 - accuracy: 0.8425 - val_loss: 0.3081 - val_accuracy: 0.8570\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3506 - accuracy: 0.8456 - val_loss: 0.3076 - val_accuracy: 0.8578\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3483 - accuracy: 0.8471 - val_loss: 0.3063 - val_accuracy: 0.8573\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3418 - accuracy: 0.8474 - val_loss: 0.3056 - val_accuracy: 0.8597\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3465 - accuracy: 0.8461 - val_loss: 0.3044 - val_accuracy: 0.8594\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8473 - val_loss: 0.3043 - val_accuracy: 0.8587\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3408 - accuracy: 0.8482 - val_loss: 0.3027 - val_accuracy: 0.8592\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.8472 - val_loss: 0.3020 - val_accuracy: 0.8612\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3423 - accuracy: 0.8470 - val_loss: 0.3020 - val_accuracy: 0.8606\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8497 - val_loss: 0.3009 - val_accuracy: 0.8587\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.8473 - val_loss: 0.3004 - val_accuracy: 0.8605\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3369 - accuracy: 0.8492 - val_loss: 0.3007 - val_accuracy: 0.8608\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3366 - accuracy: 0.8482 - val_loss: 0.3005 - val_accuracy: 0.8601\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3359 - accuracy: 0.8488 - val_loss: 0.3000 - val_accuracy: 0.8596\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3381 - accuracy: 0.8475 - val_loss: 0.2992 - val_accuracy: 0.8599\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3370 - accuracy: 0.8470 - val_loss: 0.2993 - val_accuracy: 0.8599\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3360 - accuracy: 0.8479 - val_loss: 0.2992 - val_accuracy: 0.8582\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3355 - accuracy: 0.8481 - val_loss: 0.2987 - val_accuracy: 0.8601\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3352 - accuracy: 0.8468 - val_loss: 0.2974 - val_accuracy: 0.8576\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8466 - val_loss: 0.2973 - val_accuracy: 0.8591\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3382 - accuracy: 0.8482 - val_loss: 0.2975 - val_accuracy: 0.8590\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3323 - accuracy: 0.8489 - val_loss: 0.2970 - val_accuracy: 0.8612\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3340 - accuracy: 0.8477 - val_loss: 0.2971 - val_accuracy: 0.8575\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3347 - accuracy: 0.8448 - val_loss: 0.2977 - val_accuracy: 0.8585\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3337 - accuracy: 0.8483 - val_loss: 0.2974 - val_accuracy: 0.8614\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3321 - accuracy: 0.8485 - val_loss: 0.2964 - val_accuracy: 0.8575\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3323 - accuracy: 0.8488 - val_loss: 0.2967 - val_accuracy: 0.8610\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3326 - accuracy: 0.8474 - val_loss: 0.2968 - val_accuracy: 0.8589\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3324 - accuracy: 0.8474 - val_loss: 0.2962 - val_accuracy: 0.8607\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3316 - accuracy: 0.8478 - val_loss: 0.2966 - val_accuracy: 0.8568\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3326 - accuracy: 0.8453 - val_loss: 0.2970 - val_accuracy: 0.8564\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.8454 - val_loss: 0.2959 - val_accuracy: 0.8573\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8465 - val_loss: 0.2965 - val_accuracy: 0.8568\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3325 - accuracy: 0.8475 - val_loss: 0.2961 - val_accuracy: 0.8572\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3331 - accuracy: 0.8465 - val_loss: 0.2954 - val_accuracy: 0.8575\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3313 - accuracy: 0.8485 - val_loss: 0.2959 - val_accuracy: 0.8609\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3333 - accuracy: 0.8443 - val_loss: 0.2955 - val_accuracy: 0.8580\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8452 - val_loss: 0.2959 - val_accuracy: 0.8573\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3326 - accuracy: 0.8475 - val_loss: 0.2946 - val_accuracy: 0.8584\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3312 - accuracy: 0.8474 - val_loss: 0.2963 - val_accuracy: 0.8599\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3332 - accuracy: 0.8464 - val_loss: 0.2951 - val_accuracy: 0.8575\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3315 - accuracy: 0.8484 - val_loss: 0.2953 - val_accuracy: 0.8581\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3316 - accuracy: 0.8480 - val_loss: 0.2953 - val_accuracy: 0.8570\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8463 - val_loss: 0.2951 - val_accuracy: 0.8575\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.8468 - val_loss: 0.2959 - val_accuracy: 0.8567\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8472 - val_loss: 0.2962 - val_accuracy: 0.8592\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3326 - accuracy: 0.8460 - val_loss: 0.2946 - val_accuracy: 0.8583\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8454 - val_loss: 0.2945 - val_accuracy: 0.8584\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2945 - accuracy: 0.8584\n",
            "정확률= 0.8584213852882385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. CNN - 1 + 4 / 8 / O / leaky_relu"
      ],
      "metadata": {
        "id": "zJPfPI3Ws2Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn17 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(8, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn17.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn17.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn17.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8591"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i2Hh_H-t7xh",
        "outputId": "2ac45864-eba6-4a56-b80e-929d0e27e401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 5ms/step - loss: 0.5708 - accuracy: 0.7213 - val_loss: 0.3313 - val_accuracy: 0.8527\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4181 - accuracy: 0.8162 - val_loss: 0.3127 - val_accuracy: 0.8544\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3891 - accuracy: 0.8293 - val_loss: 0.3098 - val_accuracy: 0.8565\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3772 - accuracy: 0.8344 - val_loss: 0.3105 - val_accuracy: 0.8551\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3732 - accuracy: 0.8350 - val_loss: 0.3118 - val_accuracy: 0.8583\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3709 - accuracy: 0.8387 - val_loss: 0.3104 - val_accuracy: 0.8579\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3661 - accuracy: 0.8402 - val_loss: 0.3084 - val_accuracy: 0.8566\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3648 - accuracy: 0.8413 - val_loss: 0.3081 - val_accuracy: 0.8573\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3609 - accuracy: 0.8420 - val_loss: 0.3110 - val_accuracy: 0.8560\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3628 - accuracy: 0.8409 - val_loss: 0.3082 - val_accuracy: 0.8564\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3608 - accuracy: 0.8409 - val_loss: 0.3075 - val_accuracy: 0.8559\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3603 - accuracy: 0.8435 - val_loss: 0.3088 - val_accuracy: 0.8562\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3594 - accuracy: 0.8406 - val_loss: 0.3085 - val_accuracy: 0.8558\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3632 - accuracy: 0.8424 - val_loss: 0.3063 - val_accuracy: 0.8554\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3579 - accuracy: 0.8420 - val_loss: 0.3075 - val_accuracy: 0.8562\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3601 - accuracy: 0.8414 - val_loss: 0.3074 - val_accuracy: 0.8553\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3593 - accuracy: 0.8417 - val_loss: 0.3070 - val_accuracy: 0.8565\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3576 - accuracy: 0.8427 - val_loss: 0.3061 - val_accuracy: 0.8578\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3578 - accuracy: 0.8414 - val_loss: 0.3074 - val_accuracy: 0.8578\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3588 - accuracy: 0.8432 - val_loss: 0.3053 - val_accuracy: 0.8556\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3591 - accuracy: 0.8413 - val_loss: 0.3055 - val_accuracy: 0.8567\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3544 - accuracy: 0.8428 - val_loss: 0.3051 - val_accuracy: 0.8571\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3563 - accuracy: 0.8430 - val_loss: 0.3041 - val_accuracy: 0.8570\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3585 - accuracy: 0.8410 - val_loss: 0.3054 - val_accuracy: 0.8562\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3570 - accuracy: 0.8423 - val_loss: 0.3057 - val_accuracy: 0.8585\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3548 - accuracy: 0.8431 - val_loss: 0.3040 - val_accuracy: 0.8554\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3558 - accuracy: 0.8427 - val_loss: 0.3042 - val_accuracy: 0.8589\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3524 - accuracy: 0.8432 - val_loss: 0.3055 - val_accuracy: 0.8553\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3548 - accuracy: 0.8412 - val_loss: 0.3053 - val_accuracy: 0.8565\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3521 - accuracy: 0.8419 - val_loss: 0.3050 - val_accuracy: 0.8570\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3571 - accuracy: 0.8404 - val_loss: 0.3042 - val_accuracy: 0.8576\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3520 - accuracy: 0.8432 - val_loss: 0.3043 - val_accuracy: 0.8568\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3554 - accuracy: 0.8410 - val_loss: 0.3039 - val_accuracy: 0.8576\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3541 - accuracy: 0.8415 - val_loss: 0.3042 - val_accuracy: 0.8585\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3543 - accuracy: 0.8429 - val_loss: 0.3064 - val_accuracy: 0.8554\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3518 - accuracy: 0.8426 - val_loss: 0.3041 - val_accuracy: 0.8590\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3564 - accuracy: 0.8409 - val_loss: 0.3043 - val_accuracy: 0.8572\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3551 - accuracy: 0.8417 - val_loss: 0.3040 - val_accuracy: 0.8560\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3530 - accuracy: 0.8396 - val_loss: 0.3038 - val_accuracy: 0.8572\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3559 - accuracy: 0.8418 - val_loss: 0.3030 - val_accuracy: 0.8594\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3511 - accuracy: 0.8427 - val_loss: 0.3034 - val_accuracy: 0.8563\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3536 - accuracy: 0.8420 - val_loss: 0.3065 - val_accuracy: 0.8569\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3533 - accuracy: 0.8386 - val_loss: 0.3042 - val_accuracy: 0.8578\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3514 - accuracy: 0.8416 - val_loss: 0.3045 - val_accuracy: 0.8580\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3500 - accuracy: 0.8398 - val_loss: 0.3026 - val_accuracy: 0.8579\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3512 - accuracy: 0.8432 - val_loss: 0.3031 - val_accuracy: 0.8560\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3533 - accuracy: 0.8408 - val_loss: 0.3032 - val_accuracy: 0.8566\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3496 - accuracy: 0.8425 - val_loss: 0.3032 - val_accuracy: 0.8573\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3538 - accuracy: 0.8402 - val_loss: 0.3026 - val_accuracy: 0.8580\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3527 - accuracy: 0.8395 - val_loss: 0.3022 - val_accuracy: 0.8591\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3022 - accuracy: 0.8591\n",
            "정확률= 0.8590683341026306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. CNN - 1 + 4 / 16 / O / leaky_relu"
      ],
      "metadata": {
        "id": "Kc09qAjas5TB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn18 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(16, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn18.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn18.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn18.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8603"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFKf3lXSt8Ya",
        "outputId": "891b8e81-6951-4ed9-83c4-7029eeecc98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 5ms/step - loss: 0.5367 - accuracy: 0.7503 - val_loss: 0.3264 - val_accuracy: 0.8546\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4034 - accuracy: 0.8267 - val_loss: 0.3143 - val_accuracy: 0.8562\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3779 - accuracy: 0.8372 - val_loss: 0.3117 - val_accuracy: 0.8559\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3674 - accuracy: 0.8391 - val_loss: 0.3131 - val_accuracy: 0.8541\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 3ms/step - loss: 0.3650 - accuracy: 0.8409 - val_loss: 0.3102 - val_accuracy: 0.8564\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3610 - accuracy: 0.8441 - val_loss: 0.3075 - val_accuracy: 0.8572\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 3s 11ms/step - loss: 0.3573 - accuracy: 0.8447 - val_loss: 0.3084 - val_accuracy: 0.8567\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3556 - accuracy: 0.8440 - val_loss: 0.3057 - val_accuracy: 0.8579\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 2s 9ms/step - loss: 0.3576 - accuracy: 0.8451 - val_loss: 0.3052 - val_accuracy: 0.8576\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3533 - accuracy: 0.8432 - val_loss: 0.3039 - val_accuracy: 0.8598\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3541 - accuracy: 0.8462 - val_loss: 0.3037 - val_accuracy: 0.8585\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 3s 10ms/step - loss: 0.3505 - accuracy: 0.8454 - val_loss: 0.3010 - val_accuracy: 0.8586\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3475 - accuracy: 0.8455 - val_loss: 0.3015 - val_accuracy: 0.8590\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3465 - accuracy: 0.8463 - val_loss: 0.3013 - val_accuracy: 0.8587\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3504 - accuracy: 0.8461 - val_loss: 0.3013 - val_accuracy: 0.8589\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3495 - accuracy: 0.8447 - val_loss: 0.3001 - val_accuracy: 0.8614\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3474 - accuracy: 0.8449 - val_loss: 0.3002 - val_accuracy: 0.8617\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3461 - accuracy: 0.8451 - val_loss: 0.2992 - val_accuracy: 0.8608\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3421 - accuracy: 0.8464 - val_loss: 0.2992 - val_accuracy: 0.8582\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3440 - accuracy: 0.8462 - val_loss: 0.2978 - val_accuracy: 0.8623\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3410 - accuracy: 0.8461 - val_loss: 0.2993 - val_accuracy: 0.8564\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3449 - accuracy: 0.8450 - val_loss: 0.2981 - val_accuracy: 0.8590\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3426 - accuracy: 0.8444 - val_loss: 0.2995 - val_accuracy: 0.8575\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3408 - accuracy: 0.8472 - val_loss: 0.2979 - val_accuracy: 0.8573\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3435 - accuracy: 0.8452 - val_loss: 0.2977 - val_accuracy: 0.8585\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3423 - accuracy: 0.8450 - val_loss: 0.2970 - val_accuracy: 0.8608\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3400 - accuracy: 0.8452 - val_loss: 0.3002 - val_accuracy: 0.8559\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 2s 9ms/step - loss: 0.3400 - accuracy: 0.8456 - val_loss: 0.2974 - val_accuracy: 0.8600\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 3s 10ms/step - loss: 0.3410 - accuracy: 0.8454 - val_loss: 0.2966 - val_accuracy: 0.8623\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3419 - accuracy: 0.8452 - val_loss: 0.2971 - val_accuracy: 0.8594\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3383 - accuracy: 0.8456 - val_loss: 0.2972 - val_accuracy: 0.8585\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3426 - accuracy: 0.8448 - val_loss: 0.2964 - val_accuracy: 0.8609\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3415 - accuracy: 0.8454 - val_loss: 0.2972 - val_accuracy: 0.8624\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3384 - accuracy: 0.8457 - val_loss: 0.2968 - val_accuracy: 0.8606\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 3s 11ms/step - loss: 0.3381 - accuracy: 0.8480 - val_loss: 0.2961 - val_accuracy: 0.8582\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3354 - accuracy: 0.8466 - val_loss: 0.2961 - val_accuracy: 0.8617\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3389 - accuracy: 0.8458 - val_loss: 0.2979 - val_accuracy: 0.8601\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.8446 - val_loss: 0.2952 - val_accuracy: 0.8595\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3368 - accuracy: 0.8467 - val_loss: 0.2955 - val_accuracy: 0.8611\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3372 - accuracy: 0.8460 - val_loss: 0.2959 - val_accuracy: 0.8600\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3384 - accuracy: 0.8456 - val_loss: 0.2965 - val_accuracy: 0.8609\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3380 - accuracy: 0.8450 - val_loss: 0.2956 - val_accuracy: 0.8603\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3351 - accuracy: 0.8475 - val_loss: 0.2959 - val_accuracy: 0.8603\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3349 - accuracy: 0.8465 - val_loss: 0.2954 - val_accuracy: 0.8597\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3358 - accuracy: 0.8448 - val_loss: 0.2949 - val_accuracy: 0.8596\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3373 - accuracy: 0.8444 - val_loss: 0.2945 - val_accuracy: 0.8601\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3364 - accuracy: 0.8449 - val_loss: 0.2956 - val_accuracy: 0.8617\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3357 - accuracy: 0.8454 - val_loss: 0.2946 - val_accuracy: 0.8624\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3344 - accuracy: 0.8475 - val_loss: 0.2959 - val_accuracy: 0.8565\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3388 - accuracy: 0.8448 - val_loss: 0.2966 - val_accuracy: 0.8592\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2966 - accuracy: 0.8592\n",
            "정확률= 0.8591762185096741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. CNN - 1 + 5 / 8 / O / leaky_relu"
      ],
      "metadata": {
        "id": "46lh5V2xs7Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn19 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(8, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn19.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn19.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn19.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8609"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tI6hEyjt8yC",
        "outputId": "7c839691-3792-4298-dffc-2acab261f951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 3s 5ms/step - loss: 0.5881 - accuracy: 0.7087 - val_loss: 0.3464 - val_accuracy: 0.8541\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4356 - accuracy: 0.8087 - val_loss: 0.3163 - val_accuracy: 0.8557\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3915 - accuracy: 0.8296 - val_loss: 0.3118 - val_accuracy: 0.8555\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3853 - accuracy: 0.8327 - val_loss: 0.3104 - val_accuracy: 0.8557\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3796 - accuracy: 0.8367 - val_loss: 0.3139 - val_accuracy: 0.8530\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3742 - accuracy: 0.8386 - val_loss: 0.3130 - val_accuracy: 0.8543\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3726 - accuracy: 0.8395 - val_loss: 0.3118 - val_accuracy: 0.8536\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3690 - accuracy: 0.8422 - val_loss: 0.3105 - val_accuracy: 0.8545\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3673 - accuracy: 0.8413 - val_loss: 0.3106 - val_accuracy: 0.8551\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3709 - accuracy: 0.8396 - val_loss: 0.3130 - val_accuracy: 0.8538\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3626 - accuracy: 0.8396 - val_loss: 0.3089 - val_accuracy: 0.8541\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3635 - accuracy: 0.8422 - val_loss: 0.3086 - val_accuracy: 0.8550\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3668 - accuracy: 0.8407 - val_loss: 0.3091 - val_accuracy: 0.8552\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3670 - accuracy: 0.8412 - val_loss: 0.3082 - val_accuracy: 0.8534\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3628 - accuracy: 0.8419 - val_loss: 0.3074 - val_accuracy: 0.8550\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3640 - accuracy: 0.8422 - val_loss: 0.3088 - val_accuracy: 0.8554\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3615 - accuracy: 0.8413 - val_loss: 0.3072 - val_accuracy: 0.8538\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3619 - accuracy: 0.8425 - val_loss: 0.3083 - val_accuracy: 0.8560\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3621 - accuracy: 0.8413 - val_loss: 0.3073 - val_accuracy: 0.8563\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3577 - accuracy: 0.8428 - val_loss: 0.3067 - val_accuracy: 0.8534\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3607 - accuracy: 0.8425 - val_loss: 0.3092 - val_accuracy: 0.8540\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3618 - accuracy: 0.8430 - val_loss: 0.3070 - val_accuracy: 0.8516\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3628 - accuracy: 0.8412 - val_loss: 0.3098 - val_accuracy: 0.8560\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3596 - accuracy: 0.8458 - val_loss: 0.3062 - val_accuracy: 0.8540\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3587 - accuracy: 0.8411 - val_loss: 0.3071 - val_accuracy: 0.8557\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3569 - accuracy: 0.8413 - val_loss: 0.3061 - val_accuracy: 0.8534\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3591 - accuracy: 0.8436 - val_loss: 0.3064 - val_accuracy: 0.8556\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3578 - accuracy: 0.8446 - val_loss: 0.3064 - val_accuracy: 0.8517\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3602 - accuracy: 0.8425 - val_loss: 0.3055 - val_accuracy: 0.8532\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3597 - accuracy: 0.8426 - val_loss: 0.3057 - val_accuracy: 0.8525\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3584 - accuracy: 0.8421 - val_loss: 0.3054 - val_accuracy: 0.8531\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3594 - accuracy: 0.8421 - val_loss: 0.3053 - val_accuracy: 0.8534\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3591 - accuracy: 0.8424 - val_loss: 0.3074 - val_accuracy: 0.8512\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3566 - accuracy: 0.8409 - val_loss: 0.3066 - val_accuracy: 0.8539\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3578 - accuracy: 0.8413 - val_loss: 0.3060 - val_accuracy: 0.8522\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3588 - accuracy: 0.8434 - val_loss: 0.3074 - val_accuracy: 0.8550\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3610 - accuracy: 0.8406 - val_loss: 0.3056 - val_accuracy: 0.8521\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3554 - accuracy: 0.8429 - val_loss: 0.3055 - val_accuracy: 0.8530\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3559 - accuracy: 0.8414 - val_loss: 0.3050 - val_accuracy: 0.8546\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3587 - accuracy: 0.8432 - val_loss: 0.3040 - val_accuracy: 0.8557\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3579 - accuracy: 0.8416 - val_loss: 0.3064 - val_accuracy: 0.8553\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3579 - accuracy: 0.8418 - val_loss: 0.3071 - val_accuracy: 0.8543\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3589 - accuracy: 0.8392 - val_loss: 0.3049 - val_accuracy: 0.8541\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3543 - accuracy: 0.8419 - val_loss: 0.3055 - val_accuracy: 0.8507\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3574 - accuracy: 0.8435 - val_loss: 0.3050 - val_accuracy: 0.8558\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3564 - accuracy: 0.8419 - val_loss: 0.3055 - val_accuracy: 0.8544\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3590 - accuracy: 0.8412 - val_loss: 0.3071 - val_accuracy: 0.8541\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3568 - accuracy: 0.8417 - val_loss: 0.3039 - val_accuracy: 0.8537\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3563 - accuracy: 0.8395 - val_loss: 0.3036 - val_accuracy: 0.8556\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3565 - accuracy: 0.8406 - val_loss: 0.3052 - val_accuracy: 0.8544\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.3052 - accuracy: 0.8544\n",
            "정확률= 0.8544317483901978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. CNN - 1 + 5 / 16 / O / leaky_relu"
      ],
      "metadata": {
        "id": "zE5H2AVCs9CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn20 = Sequential([\n",
        "    keras.layers.Input(shape=(8, 1)),\n",
        "    keras.layers.Conv1D(16, 8, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(16, activation='leaky_relu'),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "cnn20.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "hist = cnn20.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test)).history\n",
        "\n",
        "res = cnn20.evaluate(x_test, y_test)\n",
        "print('정확률=', res[1])\n",
        "# 0.8616"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7L96WeEt9Lp",
        "outputId": "8206659b-87ec-4c41-ba64-e50b805eb651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 6s 9ms/step - loss: 0.5191 - accuracy: 0.7399 - val_loss: 0.3156 - val_accuracy: 0.8529\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3977 - accuracy: 0.8294 - val_loss: 0.3104 - val_accuracy: 0.8573\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 3s 10ms/step - loss: 0.3759 - accuracy: 0.8381 - val_loss: 0.3096 - val_accuracy: 0.8569\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.3681 - accuracy: 0.8385 - val_loss: 0.3067 - val_accuracy: 0.8591\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3608 - accuracy: 0.8416 - val_loss: 0.3053 - val_accuracy: 0.8592\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3565 - accuracy: 0.8436 - val_loss: 0.3060 - val_accuracy: 0.8592\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3550 - accuracy: 0.8418 - val_loss: 0.3044 - val_accuracy: 0.8603\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3545 - accuracy: 0.8432 - val_loss: 0.3040 - val_accuracy: 0.8599\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3518 - accuracy: 0.8428 - val_loss: 0.3028 - val_accuracy: 0.8615\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 3s 10ms/step - loss: 0.3524 - accuracy: 0.8443 - val_loss: 0.3022 - val_accuracy: 0.8591\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3511 - accuracy: 0.8437 - val_loss: 0.3038 - val_accuracy: 0.8594\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3546 - accuracy: 0.8430 - val_loss: 0.3016 - val_accuracy: 0.8580\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3478 - accuracy: 0.8425 - val_loss: 0.3019 - val_accuracy: 0.8593\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3491 - accuracy: 0.8440 - val_loss: 0.2996 - val_accuracy: 0.8619\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3481 - accuracy: 0.8445 - val_loss: 0.2993 - val_accuracy: 0.8578\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3490 - accuracy: 0.8447 - val_loss: 0.2980 - val_accuracy: 0.8607\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 3s 9ms/step - loss: 0.3492 - accuracy: 0.8447 - val_loss: 0.2977 - val_accuracy: 0.8600\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 3s 10ms/step - loss: 0.3453 - accuracy: 0.8431 - val_loss: 0.2980 - val_accuracy: 0.8612\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3470 - accuracy: 0.8439 - val_loss: 0.2997 - val_accuracy: 0.8575\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3456 - accuracy: 0.8456 - val_loss: 0.2987 - val_accuracy: 0.8619\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3448 - accuracy: 0.8441 - val_loss: 0.2969 - val_accuracy: 0.8610\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3454 - accuracy: 0.8464 - val_loss: 0.2965 - val_accuracy: 0.8614\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3459 - accuracy: 0.8423 - val_loss: 0.2968 - val_accuracy: 0.8604\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 2s 8ms/step - loss: 0.3448 - accuracy: 0.8429 - val_loss: 0.2965 - val_accuracy: 0.8594\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 3s 10ms/step - loss: 0.3453 - accuracy: 0.8444 - val_loss: 0.2957 - val_accuracy: 0.8614\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3411 - accuracy: 0.8430 - val_loss: 0.2961 - val_accuracy: 0.8605\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3435 - accuracy: 0.8440 - val_loss: 0.2956 - val_accuracy: 0.8605\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 5ms/step - loss: 0.3417 - accuracy: 0.8437 - val_loss: 0.2971 - val_accuracy: 0.8583\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8445 - val_loss: 0.2980 - val_accuracy: 0.8597\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3416 - accuracy: 0.8434 - val_loss: 0.2957 - val_accuracy: 0.8599\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8447 - val_loss: 0.2964 - val_accuracy: 0.8605\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3375 - accuracy: 0.8450 - val_loss: 0.2948 - val_accuracy: 0.8621\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3422 - accuracy: 0.8441 - val_loss: 0.2964 - val_accuracy: 0.8601\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 2s 5ms/step - loss: 0.3404 - accuracy: 0.8458 - val_loss: 0.2943 - val_accuracy: 0.8610\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3396 - accuracy: 0.8446 - val_loss: 0.2946 - val_accuracy: 0.8589\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3408 - accuracy: 0.8437 - val_loss: 0.2953 - val_accuracy: 0.8581\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3398 - accuracy: 0.8434 - val_loss: 0.2951 - val_accuracy: 0.8613\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.8413 - val_loss: 0.2961 - val_accuracy: 0.8613\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3394 - accuracy: 0.8408 - val_loss: 0.2949 - val_accuracy: 0.8611\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.8440 - val_loss: 0.2942 - val_accuracy: 0.8584\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.8422 - val_loss: 0.2950 - val_accuracy: 0.8581\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3381 - accuracy: 0.8434 - val_loss: 0.2954 - val_accuracy: 0.8618\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3385 - accuracy: 0.8435 - val_loss: 0.2948 - val_accuracy: 0.8612\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3384 - accuracy: 0.8429 - val_loss: 0.2957 - val_accuracy: 0.8586\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 2s 6ms/step - loss: 0.3391 - accuracy: 0.8434 - val_loss: 0.2948 - val_accuracy: 0.8600\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 2s 7ms/step - loss: 0.3368 - accuracy: 0.8436 - val_loss: 0.2937 - val_accuracy: 0.8580\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3399 - accuracy: 0.8431 - val_loss: 0.2953 - val_accuracy: 0.8600\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3390 - accuracy: 0.8437 - val_loss: 0.2949 - val_accuracy: 0.8583\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3363 - accuracy: 0.8433 - val_loss: 0.2961 - val_accuracy: 0.8610\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3377 - accuracy: 0.8447 - val_loss: 0.2935 - val_accuracy: 0.8617\n",
            "290/290 [==============================] - 1s 2ms/step - loss: 0.2935 - accuracy: 0.8617\n",
            "정확률= 0.8616562485694885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN과 CNN 비교"
      ],
      "metadata": {
        "id": "D83L21Pw8-Os"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![수정_표.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAeAB4AAD/4QLcRXhpZgAATU0AKgAAAAgABAE7AAIAAAAKAAABSodpAAQAAAABAAABVJydAAEAAAAIAAACzOocAAcAAAEMAAAAPgAAAAAc6gAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6rmA7ZiB66+8AAAFkAMAAgAAABQAAAKikAQAAgAAABQAAAK2kpEAAgAAAAMwNQAAkpIAAgAAAAMwNQAA6hwABwAAAQwAAAGWAAAAABzqAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDI0OjA1OjI2IDIzOjI2OjU1ADIwMjQ6MDU6MjYgMjM6MjY6NTUAAABArgHW/LsAAP/hBBxodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0n77u/JyBpZD0nVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkJz8+DQo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIj48cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIi8+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iPjx4bXA6Q3JlYXRlRGF0ZT4yMDI0LTA1LTI2VDIzOjI2OjU1LjA1MTwveG1wOkNyZWF0ZURhdGU+PC9yZGY6RGVzY3JpcHRpb24+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iPjxkYzpjcmVhdG9yPjxyZGY6U2VxIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpsaT7quYDtmIHrr7w8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIDw/eHBhY2tldCBlbmQ9J3cnPz7/2wBDAAcFBQYFBAcGBQYIBwcIChELCgkJChUPEAwRGBUaGRgVGBcbHichGx0lHRcYIi4iJSgpKywrGiAvMy8qMicqKyr/2wBDAQcICAoJChQLCxQqHBgcKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKir/wAARCAI7A0sDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD1Xwx4Ys9b028vtQvtcadtW1GP91rt7EoVL2ZEARJQoAVVHA7Vsf8ACB6R/wA/niD/AMKPUP8A4/R4D/5F26/7DWq/+nC4rkdY/wCEI/4W9rX/AAnn/CP4/sux+y/2z5H9+43bPN/4DnHtQHRs67/hA9I/5/PEH/hR6h/8frL1fSPBegNEuveJr/TGmBMQvfF15CXA643XAzjI6etYml/8IN/wtrQP+ED/AOEfz9gvvtX9jeR6w7d/lf8AAsZ966PX4dVs/iFpWt2Oh3mrWsOm3NrKLOWBXR3khZciWRMjEbdCaO3nf8L/AOQdGZzW/gUW0NxF4k1a5gmimljmtfE2oToywjMhDJMR8o7dfSti28F6Hd2sVzb33iB4ZkEkbf8ACRagMqRkHBm9K43xBpHiC/vIby4TxFPu07VIhaahDaP5BaEBNptVI+Y8AMxJx09fS9AjeHw3pkUyNHIlpErowwVIQZBHY0LW/wAvxv8A5IH0+f4W/wAzmNX0fwZ4fMQ17xLqGmGbPlfbfF17D5mMZxuuBnGR09azftXwx/6H3/y97n/5JrZ8V+Jr6z1EabpwurVdgM19Hol7elM9oxHEYycdy5weqnpXKeH9Vj8PG+k0Sx8Q25a5cy2+o6LqEy6k3B+1F1t8wyOScjDD5R8vQ0k/6/r+vKwPQ7C58IeHrOxkvbvVdagtYkMkk8vie/VEUDO4sZ8AY71g/a/hj/0P3/l73P8A8k11Gq3+r6n8Pry88MRSw6xLZubSOWExMs2CANs6p/F03qARzjFcsP8AhLyo3/8ACf5xzj/hH6bum0HRM6C08H+H9Qs4ruw1TWrq2mUPFND4nv3R1PQhhPgj6Vk+EfCVjqWi3E95f6/JImqahApHiG/XCR3k0aDAmHRUUZ6nGTk810/hHTU0bwhpunQ295bJawCJYr54mmUDj5zEShPf5TiqngP/AJF26/7DWq/+nC4pvR6CWwf8IHpH/P54g/8ACj1D/wCP0f8ACB6R/wA/niD/AMKPUP8A4/XSUUhnN/8ACB6R/wA/niD/AMKPUP8A4/SN4F0ZELPe6+qqMknxJqAAH/f+ulrkfiFeaBNocmi6z4k0rRp7gxzRpqFzGiyhJA2GRmUsjFdpHoTSY0Z1lbeANSvxY6d4wubu7YkC3g8ZXbyEjttFxmtebwTodtBJPcahrsUUal3kfxLfqqKBkkkz8ADvXG6x4u0/xLoM2halr3gCws508trqDxCtw8Q/vRxGNAGHUHf8px1xXcX13ZeKfAmqxeGdQtdX82zmto5La5SVWkMZAUuDjPI6nvRK6i2lsEbOST6kUfgfRZoklhv9ekjdQyOviW/IYHoQfP5FVrTwx4cvr6+s7XUvED3FhIsdyn/CQ6iPLZkDgZM2D8rA8Z60aTrutWGi2VnN4F15pLe3jicrcWGCVUA4/wBK6cUzwvcCPxd44uJopUC3ds7RhN7r/ocRI2pncfZc57ZqnZSaW3/BRMbta7j9U8L+HNF0ybUNT1LxBBawAGST/hIdRbbkgDgTE9SKuf8ACB6R/wA/niD/AMKPUP8A4/XnGq6L4X8XXU0niTw0+nwyytJKNL8JXzXNy2chnuWtVYZ6kKoJP8RGQdrwYNK8P69b22m+H49kymD+008K3en3IU42rIRbCNskDc26Ne+3ilHXcb0Ot/4QPSP+fzxB/wCFHqH/AMfqG68HaBY2r3N7qet20EfLyzeJ79FXnHJM+BzXTzTRW1vJPcSJFFGpd5JGCqigZJJPQAd68u1TXfDnjCJrPxd478L2+jlstpumawm6fHTzJyysQDhtqqvI5LDilfWwHYf8IHpH/P54g/8ACj1D/wCP0f8ACB6R/wA/niD/AMKPUP8A4/WN4e8Y2cWqW2lf8Jx4Z162kPlwy/2hGl7nHyqUQlZmJwMjy/oT172qF5HN/wDCB6R/z+eIP/Cj1D/4/R/wgekf8/niD/wo9Q/+P10lFIZ5/wCNvCVjpXw/8Q6hYX+vxXVppdzPC58Q37bXWJmU4MxB5A4IIrc/4QPSP+fzxB/4Ueof/H6PiP8A8ks8V/8AYFvP/RD10lAHLXHgzQbO2kuLvUtcghjXc8svia/VVHqSZ8AVm6XYeBdcuTb6L4rvNRnA3GK08YXkrAeuFuCad4+1Pw9LLZWt54n0Gw1DTLtLwWOqXkaJN8jALIpbIHzbg2DggHBrC1DxdpXieSxh1vxJ4H0uC0u4roXFn4hW6mzG4bam6OMJnGC2TwSMULX+vx/4HkD0/r8P+D5nWXXg7QLG3ae91PW7eFSA0kvia/RQScDkz45JA/Gpv+ED0j/n88Qf+FHqH/x+q/jAf8JV8O7k+F2i1fz2ieA2k8bLMEmUttcsF/hPfqKtR+JtVeVEbwRr0aswBdp7DCj1OLknH0Bo62Dpco6d4Y8OatFNJp+peIJkguJLaQ/8JDqK7ZI2KuvMw6EEZ6elGoeF/Dmli2N/qXiCIXVwltD/AMVDqLbpHOFXiY4z6niq/g2+Gm+F/EN20Uk3la5qJEcUMkrMftD4G2NWY8+inHXFcJc+FPCHiBkm1zw9NpRj+eK20Twbdrsk/vPK1rmYDspRUP8AErcYSd7eif3q/wDw34jas2vNr7j0/wD4QPSP+fzxB/4Ueof/AB+j/hA9I/5/PEH/AIUeof8Ax+sHwFPY6dqsunWXh62sVnjBN7Z+HLvTfPZckCRXgCLgE4PmHJPAGa9CqmSc3/wgekf8/niD/wAKPUP/AI/R/wAIHpH/AD+eIP8Awo9Q/wDj9c14U8Wad4T0F9P8QW2sWly2rXioDol46yGS6laMK6xFWLKwIwTnNdxpGu2mtrKbOG/j8ogN9t064tc59PNRd3TtnFLfYb0djM/4QPSP+fzxB/4Ueof/AB+j/hA9I/5/PEH/AIUeof8Ax+uT17/hCv8Ahb2o/wDCd/2Ds/se0+zf2z5OM+bPu2eb+Gce1b/hh/hqusY8GN4UGpNGwxpJtvOKcE/6v5scDPahaoJaO3p+Rd/4QPSP+fzxB/4Ueof/AB+mS+CNEgheWa/16OONSzu/iW/AUDkknz+BXT15rrfirRvEEtzpmp+PPC+maMzGOaG01WNrm5jzgq0jMoiBGQwVWb0cUnfZD82dHD4J0O4gjmt9Q12WKRQ6SJ4lv2V1IyCCJ+QR3p//AAgekf8AP54g/wDCj1D/AOP1zOj+KtE8OyW2m6T478LajoqMscNvearGlxax9AqyKW80KOFVlDermvSutU+6JXZnn+geErG81rxPBcX+vvHZaokEA/4SG/GxDZ20hGRNz80jnJyecdABW5/wgekf8/niD/wo9Q/+P0eF/wDkYvGf/Yaj/wDTfZ10lIZyl74R8O6bZS3mo6rrVpawjdJPP4nv0RB6ljPgVhLc/DJmCr48JYnAA8b3PP8A5M132pXM1pp8k1tYXOoSLgC3tWjWRsnHBkdF468sOleZ6bJ46t9L8KW974c8Ryy6XcO+pSf2naMbtPLkVASbkF/maMkNgcewoW4PY6a08MeG76+vbO11LxBJPYSLHcp/wkOojYzIHUZM2DlWB4z1rKnk+G1tcSQXPjl4ZomKSRyeNrpWRgcEEG5yCD2ra8KW92nizxZdXVlcWqXd1bSRCZMbgLWIHBGVbDAqSpIyDzWL8OrnxGuivHa6Vpcmm/2vfg3EmpyJMF+2S7j5QgK5HOBv5wORng7egPRX/rqaMfh/wtNqNrYwavrks95bNd24j8R6iyywqVBcOJtuMyJ35zxWh/wgekf8/niD/wAKPUP/AI/WNHqFzffGrTludIvNOEOjXqo108LCcefb/MvlyOQOP4tp5HHWu9p/ZT73/Nr9A2bX9bI5v/hA9I/5/PEH/hR6h/8AH6yLTS/CF9dW9ta6v4gea5luIYl/t/UxueBtsoyZeNp9evbNVr3wx4Zf4jaPYaD4c0q2urCT+09Qu7WyijeFcMIkLAA5dznHpG1YHg/UIZvHWkWSJcCW31LXWdntpFjO6Y42yFQjn1Ck474pLX8fw/pg9Pw/G/8AwPvO/wD+ED0j/n88Qf8AhR6h/wDH6htfB2gX1stxZanrdxC2QssPie/dTg4OCJ8cEEfhWb4j8YWj6pc6SPG/hnQII/3c0rahG96px8yhHKrEwPc7/oDWPpmu+G/B8K2ng/x34YuNKB3DTNT1hMxEnLGO4DMwBJLEMr8ngqOKFqD0Ow/4QPSP+fzxB/4Ueof/AB+j/hA9I/5/PEH/AIUeof8Ax+ugt7iK6to7i2ljmhlQPHJGwZXUjIII4II71JQB5/oHhKxvNa8TwXF/r7x2WqJBAP8AhIb8bENnbSEZE3PzSOcnJ5x0AFbn/CB6R/z+eIP/AAo9Q/8Aj9Hhf/kYvGf/AGGo/wD032daeua5aeH9NN5fCVwXWKKGCMvJNIxwqIo6sT+Hc4AJoAzP+ED0j/n88Qf+FHqH/wAfo/4QPSP+fzxB/wCFHqH/AMfrnbnWJdT+L3hJLrSb/Sp47TUGMN6IyWUrFghondD0PG7I7gZGdvTviFpuoaJPrX2O+ttIt0maa+uFjVEaNyhTAcuzEjjapB6Z3cUdL+v4AT/8IHpH/P54g/8ACj1D/wCP0f8ACB6R/wA/niD/AMKPUP8A4/SQeNY/7QsrbVdE1XSI9QkEVpc3qReXLIRkJ+7kZkYgHAcLnp14qM+O4Zb7UrPStE1bVJ9LuDBdrapEPLO0NuBeRQwIbhRluPu4wSAS/wDCB6R/z+eIP/Cj1D/4/R/wgekf8/niD/wo9Q/+P05/HGkto2m6hYfaNQOqOY7K1t4/30zgEsu1yu3btO4sVC45IpkPje02ammo6dqGmXum2hvZbK6WMyPCAfnRkdkYZBHDcHrjIpN2vfoNK+wv/CB6R/z+eIP/AAo9Q/8Aj9H/AAgekf8AP54g/wDCj1D/AOP1am8U2UOkaPqLRXBh1iWCKBQq7lMwyu7nAA74z+NYXhPxZrGr+NPEem3+kX0VpZXaRQyubbbbr5KttfbIWYsTkYDcEZxyBVtWu36W/wA0TdWv/Wv/AAxp/wDCB6R/z+eIP/Cj1D/4/WbYaL4N1W+nstM8SajeXdvnzoLfxbeySRYODuUXBI545rQ+I08tt8O9YeCZ7djBsaVCQyKzBWYEcjCk81g/EbStC0vRfDMkjw6TbafqcFvFcR3TWfkwMCkiCZGUopTk4IztFTfWz8l9+g+n3v7jUsvDHhzUbi9gs9S8QSSWE/2e5X/hIdRHlybFfbzNz8rqcjI5qaDwd4fuZJ47bVNbme3k8uZY/E9+xifAbawE/BwwOD2I9ay/hY2nPJ4sbRL77fYnW/3Nz9sa78wfZoMnzWZi3ORyT0x2rNbSvFOneLPEc9pD4ojtb/UBcQNo7aUYpF8iJNx+0neGyhGOBgCq7eifz0/zYd/W35nTDwd4fa9azGqa2bpYxK0A8T3+8ISQGK+fnBIIz7Gpv+ED0j/n88Qf+FHqH/x+sXwdpWvJ471LVtZh1kW8umw20UusNY+aWWSRioFodu3DA5YZyT7V31Lon/W4dX/XQ8/8E+ErHVfh/wCHtQv7/X5bq70u2nmceIb9dztErMcCYAck8AAVuf8ACB6R/wA/niD/AMKPUP8A4/R8OP8AklnhT/sC2f8A6ISs34pS6QvhdI9WbQPOaZWgTWzBggEeYYhP8nmBC2M8ZIzxSbsNak2neGPDmrRTSafqXiCZILiS2kP/AAkOortkjYq68zDoQRnp6UaX4X8Oa1psd/pupeIJraUsEf8A4SHUVztYqeDMD1BFeaeA7/wTL4vsZNM/saJI53jkbWI9Gin8wfLH9m+yAMW3/wAR+Ug/KTxXe/DKe6034eC+1i/sxpkX2iSMJbNG8CiaQsXcyMH/AAVce9N6JNk31saieDvD8l5LaR6prbXMKK8kK+J78uitnaSvn5AO1sHvg+lQr4Y8OPrUmkrqXiA30Vuty8X/AAkOo8RszKrZ87HVWGM54rGgPiBPEGoeL1s7pNL1iFLMW1vAPt1pDHnyrny2B3EtJITGQSFKZUkMtXdAsLnT/i9qcd3q95qrtodswmvEhVlHnzfKBFGgx35GeetC3Sfn+Cb/AK/zH0bXl+aX6/0i5feGPDmmy2cd7qXiCJ764Ftbj/hIdRO+QqzbeJuOEY5OBxRc+F/DlpqVlYXGpeIEub4uLdP+Eh1E79i7m5E2Bgc84rh9W0TwbP4s1qPxPPoHhd4Lj/RIH0qwVr1CisZi1xE5ly5Yfu8YwQeeat2V3baIfAN7caIumK8l80ltpWlSDeTEVWUW8Sll3KFYjGVzg9KS+G7/AKuEtHZHc/8ACB6R/wA/niD/AMKPUP8A4/VO88MeHLC8sbW71LxBHPqErQ2y/wDCQ6ifMcIzkZE2B8qMecdK65HEkauAcMMgMpB/EHkV4rqGheC5dc1hfEE2g+Fri3unjtLFtHsQbiMAFZf30LPNvOT+7I67fvc0Xs7D3VzvZ/C/hy11O00+fUfEC3V6JGgj/wCEh1E7wgBbkTYGAR1q3/wgekf8/niD/wAKPUP/AI/XFWVtqJn+H/8AZFlpnh29ltbyWSD+zGEKEohY+QrxlS3XBbIzzmuo8U+L4dN1IaXH4p8MaLJsBml1K9Xz48/3YCVHI5DM2P8AZI6t6Owlqrk9v4O0C6837LqetzeTIYpfL8T37bHHVTifgjI4PrU3/CB6R/z+eIP/AAo9Q/8Aj9cZp+p+GfCzSTeFPiPoEzXL+dfW+rarFIt3MfvTB1bMTtxnAKYAwg616XpGpQavpNvfWtxaXMcyZ8yyuBPCT0YLIANwBBGcDp0FPoLqcXr/AISsbPWvDEFvf6+kd7qjwTj/AISG/O9BZ3MgGTNx80aHIweMdCRW5/wgekf8/niD/wAKPUP/AI/R4o/5GLwZ/wBhqT/033ldJSGc3/wgekf8/niD/wAKPUP/AI/R/wAIHpH/AD+eIP8Awo9Q/wDj9dJRQByWoeFPDek2Ml7qmsaxZWkWPMnufFF9HGmTgZZpwByQPxrJtB8OtQvIrSw8ay3NzMwSKGHxpdO7segCi5yT7Cu21jUH0vS5buGxudQlTAS2tUDSSMTgAZIAGTySQAMk1wej6N4q0O+vH1K4n2+Jbhbi4uNJSOR9KuDhQoEisHi8tUQvtJBUnAByot/6/r+vMHt/X9f15GzaeGPDl9fX1na6l4ge4sJFjuU/4SHUR5bMgcDJmwflYHjPWibwx4ct9WtdMm1LxAt5eRySQR/8JDqJ3rHt3nPnYGN69T34qv4GspLXxV41tby+n1JxfW4ae6WMPIDaRcERoq9DjhRxXBXXhzQYtSubbVNEXT9baWc2Gk2PhG2ntZ40b5CJPs7FgVKFj5qYLc7KV9vS/wCA7Hov/CL+HBrQ0n+0vEH2425uRF/wkOo/6vdt3Z87HU4xnNXP+ED0j/n88Qf+FHqH/wAfrmNMh1TTfiDoVvY6JpdpIPDii8s45zbxWuZ1MnlBI2DYYnC/KD/eqTx5/wAIx/wsjw5/wmv9k/2f/Z97t/tfyvJ8zfBjHmcbsZ9+tPt53/Bv/IlO9/l+KX+Z0f8Awgekf8/niD/wo9Q/+P0f8IHpH/P54g/8KPUP/j9ZOiP8J01q2PhtvBq6oWxbmwNqJ9xBGE2fNnGeld1TGc3/AMIHpH/P54g/8KPUP/j9H/CB6R/z+eIP/Cj1D/4/XSUUgOb/AOED0j/n88Qf+FHqH/x+k8A77z4beGrm7nuJp5tJtZJZHncs7GFSSTnkknNdLXN/Dj/klnhT/sC2f/ohKADwH/yLl1/2GtV/9OFxVbVj411HS72xTQ9ARbmGSFZDrc2QGUjOPsnv0z+NZnhK78Vx6Verpei6PcWo1nU9ktxq8sLt/p8+cots4HOR945AB4zgbn27xv8A9C94f/8AB9P/APIdJxUlZjTad0U9FXxtpWi6fpzaHoEq2lvHAZRrcw3bFC7sfZPbOM/jVr4hPOnga9NtpVvq8heFTaXFi17GymVAzGFfmfapLYH92nfbvG//AEL3h/8A8H0//wAh0fbvG/8A0L3h/wD8H0//AMh1Um5O7FFKNrdDy+98O6ReWE9r/ZOiwedG0fmwfCzUFkjyMblO7hh1B9a9m0SNItA0+OJpGRLaNVaWFonICgZKNhlP+yeR0NZP27xv/wBC94f/APB9P/8AIdH27xv/ANC94f8A/B9P/wDIdHQXW5B48s726t9LMdtc3ulxXm7VLO0bEk8OxgOMguocqWQcsB0PQ81Ppuhzz2A+Hnha60jVUvIXa8i0WXTI44Q4Mvms6RiRSm5dnzZJHHGR1n27xv8A9C94f/8AB9P/APIdH27xv/0L3h//AMH0/wD8h0lo/wARmnq/h7RdfSJNd0iw1NYSTGt7bJMEJ6kbgcdK8oPw40r/AIUlL/xRtn/bfz7f+JWn2n/j5OP4d33P09q9E+3eN/8AoXvD/wD4Pp//AJDo+3eN/wDoXvD/AP4Pp/8A5DpWDc09I8O6JoCyjQdHsNMExBlFlapDvx0ztAzjJ6+tZngP/kXbr/sNar/6cLij7d43/wChe8P/APg+n/8AkOuf8F3njFdBuRa6Focif2tqRLSa1MhDfbp9wwLU8BsgHPIAOBnAYHolFc39u8b/APQveH//AAfT/wDyHR9u8b/9C94f/wDB9P8A/IdAHSVz3jbUdT0rQYbvR0uXkS/tROtram4fyDMolwiqxPybugyO1M+3eN/+he8P/wDg+n/+Q6Pt3jf/AKF7w/8A+D6f/wCQ6OqYB/wnmkf8+fiD/wAJzUP/AIxXQwyrPBHKgcLIoYB0KMARnlSAQfYjIrnvt3jf/oXvD/8A4Pp//kOj7d43/wChe8P/APg+n/8AkOgB0ngbSZZWka714FiWIXxDfqOfQCbA+gqr4P0+70vXvE1pK+pPYR3cP2Fr+5muMobdC2x5WYkby3Q4ByKsfbvG/wD0L3h//wAH0/8A8h0fbvG//QveH/8AwfT/APyHQtAMPVvM/wCEk1P/AIS7/hJPsPmp/Zf9ifa/K8ry13bvsf7zfv358zjG3b3rR8HnUDrF/wCQNVHh7yIvsn9sb/P87L+Zt8399sxs/wBZznOOKt/bvG//AEL3h/8A8H0//wAh0fbvG/8A0L3h/wD8H0//AMh0LQHqdJXMfEe0ub74e6rbWVvLczyIgSKFC7N+8U8Acnin/bvG/wD0L3h//wAH0/8A8h0fbvG//QveH/8AwfT/APyHQB0lFc39u8b/APQveH//AAfT/wDyHR9u8b/9C94f/wDB9P8A/IdAHSUVzf27xv8A9C94f/8AB9P/APIdH27xv/0L3h//AMH0/wD8h0AHxH/5JZ4r/wCwLef+iHrpK878fXnjFvht4lW80LQ4rc6TdCWSLWpndV8lslVNqoYgdASM+o610H27xv8A9C94f/8AB9P/APIdADfFusahouo6BNaxXsmnveumoizsXumEXkSFcrGjMB5gTkD9KenjrSXdUW018FjgbvDt+B+ZhwKT7d43/wChe8P/APg+n/8AkOj7d43/AOhe8P8A/g+n/wDkOgGdFLGJoXjcsFdSpKMVIB9COQfcc1zv/CB6R/z+eIP/AAo9Q/8Aj9H27xv/ANC94f8A/B9P/wDIdH27xv8A9C94f/8AB9P/APIdADPAVvfWmi31vqJvmMWqXaW5v5ZJJDAJmEfzyEsy7cYJJyK5xsfa7z/hOv8AhLPtv2qbyP7I+3/Zvs+8+Vs+xcfc258z5857Yrpvt3jf/oXvD/8A4Pp//kOj7d43/wChe8P/APg+n/8AkOl29LB39b/8Ab4LOqmHUf7QF6NP+0j+zBqOPtPk7Fzv7437sb/nx96t6+e8jspG02CC4ugP3cVxMYUY57uEcjj/AGTWH9u8b/8AQveH/wDwfT//ACHR9u8b/wDQveH/APwfT/8AyHTeoIyPEFj4311dOH9jeH4PsOoQ3v8AyG523+WSdv8Ax6DGc9eceldBp114plvkXVtH0i2tSDvlttWlncccYRrZAef9ofjVb7d43/6F7w//AOD6f/5Do+3eN/8AoXvD/wD4Pp//AJDoWit/X9aA9XcV77xqHbZ4f0Arn5SddmBI+n2Shb7xtuG7w9oAXPJGuzHH/kpSfbvG/wD0L3h//wAH0/8A8h0fbvG//QveH/8AwfT/APyHQB0lZ3iKKSfwvqsUKNJJJZzKiIMliUIAA7msz7d43/6F7w//AOD6f/5Do+3eN/8AoXvD/wD4Pp//AJDqZR5ouPccXytMveFYZbfwbosNxG8UsdhAjxupVkYRqCCD0IPataub+3eN/wDoXvD/AP4Pp/8A5Do+3eN/+he8P/8Ag+n/APkOtJS5pNkRjyxUeweF/wDkYvGf/Yaj/wDTfZ10led+HLzxiNe8WGDQtDd21aMzK+tTKEb7Da8KRancNu05IHJIxxk9B9u8b/8AQveH/wDwfT//ACHUlHSV4ibG3vry9n1bwvoVncm8uAY5Phxe3jMolYK5mRgrllAbI/vV6V9u8b/9C94f/wDB9P8A/IdH27xv/wBC94f/APB9P/8AIdLrcfSxkfDLSbTS/wC2nswI/tlxHM0EPh240iCLEYTCRy53Z25JB6n3rUT4e6DE0v2Z9YtllleZo7bXb2GPe7FmIRJgoyxJ4A60/wC3eN/+he8P/wDg+n/+Q6Pt3jf/AKF7w/8A+D6f/wCQ6p6iKa6PJY/EzRTaxXkljb6LeQm4nkknwzTQEK0rkksQGIyc4B9K6913xsoYruBG5eo9xXOfbvG//QveH/8AwfT/APyHR9u8b/8AQveH/wDwfT//ACHS3SXr+Lb/AFDrf+trGjoXh+y8PWTwWPmSPNIZbi5nffNcSHq7sep4A9AAAAAAK4nQ9A1XTfFOhG8sZURL7WZndRvVEll3RlmXIG4HgHmul+3eN/8AoXvD/wD4Pp//AJDo+3eN/wDoXvD/AP4Pp/8A5Do63Dpb5/n/AJnSVzHw5tLmx8BWFve28tvMrzlopkKMMzORkHnkEH8af9u8b/8AQveH/wDwfT//ACHR9u8b/wDQveH/APwfT/8AyHQB0lFc39u8b/8AQveH/wDwfT//ACHR9u8b/wDQveH/APwfT/8AyHQAeF/+Ri8Z/wDYaj/9N9nSeNdJ1DULbS73R4UubzSNQS9S1eTyxcKFZGQMeA21yQTxkDOAc1geHLzxiNe8WGDQtDd21aMzK+tTKEb7Da8KRancNu05IHJIxxk9B9u8b/8AQveH/wDwfT//ACHQHkZRt9f1r4j+HtZn0GXTdNsLa8jkFzcQtMryCPGVjdl2nbxhieuQvGaun+DNVl+Dw0C4RLXU47h7mJJJAU3rdGaMMyZ+VsLnGSAfUVv/AG7xv/0L3h//AMH0/wD8h0fbvG//AEL3h/8A8H0//wAh0dP673Az9Sj1vxedOsLvw/caNb219BeXVzdXMEgbyXEgSIRuxbcygZcJhcnGeKzfDmparp2ueL/sGgTarHLrb7HtZ4Yyj+TED5nmOvy9OV3Hr8vAz0X27xv/ANC94f8A/B9P/wDIdVLGHxXpsl3JZeGPD8bXs5uZz/wkFwd8hUKW5tOOFHA44oWjfo/v0/yB62/rv/mZVl4R1jw9beHtUgt49T1DTzeNfWcEwTzPtT+bJ5RfCkq4AG4qCM8jirtxoWp+LNWvNR1Gxk0WE6RcaZbQXEsckzGYqXkfy2ZFA2KAAxJy2ccZ0/t3jf8A6F7w/wD+D6f/AOQ6Pt3jf/oXvD//AIPp/wD5DpNJq3r+P/DsabX9edzml0/xRfaD4T0qbw+9o2jX1m17NJdQskiRDaXi2uSRxn5gpxwFPbc0PT9S0jx74iebTppbHWJ4rqG+jkj8uLbAsZR1Lh92U42qRgjkc1Z+3eN/+he8P/8Ag+n/APkOj7d43/6F7w//AOD6f/5Dqru7fe/42/yRKSWi9Puv/mb17Z2+o2M9lfQpPbXEbRSxOMq6kYIP4VhaX4Mt9Ov7S5uNU1LUxYKVsIb6RHW0BG0lSqKzNt+XdIXbBPPJyn27xv8A9C94f/8AB9P/APIdH27xv/0L3h//AMH0/wD8h0thlfwtpsg1Txkmo2bfZ7zVtyLPF8k8ZtYFJGRhlyGHpwRWL49+HHhn/hBtS/sTwbpP27YnlfZNLi83O9c7dq56Z6dq6L7d43/6F7w//wCD6f8A+Q6Pt3jf/oXvD/8A4Pp//kOjovRL7lYO/wA/xJbXwF4QsbuK6svCmiW9xCweKaHToUdGHQghcg+9b9c39u8b/wDQveH/APwfT/8AyHR9u8b/APQveH//AAfT/wDyHQAfDj/klnhT/sC2f/ohK1NfkuIvDWpyWUTzXK2krRRIXDO4Q4A2ENkn+6QfQ5ri/AN54xX4beGls9C0OW3Gk2oikl1qZHZfJXBZRasFJHUAnHqetdB9u8b/APQveH//AAfT/wDyHSkrpoadnc8xtrS+ltYpLjXPEEEzIGki/sPxM2xiOVyLznB4zXqfgiKS38HWME9/fajJGHVrq/tZ7eaQ7yeUnJkGM4G4nIA5qL7d43/6F7w//wCD6f8A+Q6Pt3jf/oXvD/8A4Pp//kOquTYw9V8z/hINR/4S/wD4ST7H5y/2b/Yn2vyfK2DO77H+837t2fM46be9aPhH7f8A2xefZf7V/wCEe8iP7N/bO/zvOyd2zzf32zGM+bznpxVv7d43/wChe8P/APg+n/8AkOj7d43/AOhe8P8A/g+n/wDkOpSsD1M7VvC3i7WLrTZrjxJoqHTbwXkITQ5fmcI6YbN3yMOemOcUt7p+uHx14Xn1GSG+jgkui0tnYvCkIMGBvJkfqeByPxrQ+3eN/wDoXvD/AP4Pp/8A5Do+3eN/+he8P/8Ag+n/APkOn0sN6u50led+Jtn/AAsaT+2/+En/ALJ/sqHyP7H/ALR8rz/Nl35+ycbtuz73bFdB9u8b/wDQveH/APwfT/8AyHR9u8b/APQveH//AAfT/wDyHR1THfRr+tzm9I+z/wDCwNH/AOEd/wCEs+x+Tc/bv7V/tPyfur5eftXy5zuxjmvSK5v7d43/AOhe8P8A/g+n/wDkOj7d43/6F7w//wCD6f8A+Q6BDPBVpc2sniP7Vbyw+drlxLF5iFd6FUwwz1BweR6V09c39u8b/wDQveH/APwfT/8AyHR9u8b/APQveH//AAfT/wDyHQtEl2SX3KwdW+7b+93DxR/yMXgz/sNSf+m+8rpK878R3njE694TM+haGjrq0hhVNamYO32G64Ym1G0bdxyAeQBjnI6D7d43/wChe8P/APg+n/8AkOgDpKK5v7d43/6F7w//AOD6f/5Do+3eN/8AoXvD/wD4Pp//AJDoA6SvLrbTdGt7q/HxF8MXWsao95K6Xkujy6nFJCXJj8opG4iUJtGzCnIJ5zk9b9u8b/8AQveH/wDwfT//ACHR9u8b/wDQveH/APwfT/8AyHR1DoVPBWlzJZ6xFcWVxb6FdXH/ABL9O1D5mjhMYDgoSdkbNuIjPQHoucDNv/gz4Zu76Se3jgsY3IK29voumFI+OxktWb35Y9a3ft3jf/oXvD//AIPp/wD5Do+3eN/+he8P/wDg+n/+Q6AMjw14Zn8L+PPslq0txpbaW7rM+nWsIjlMwJQPBDH1GWKnOTzW7d3ni9LyVbHQ9EmtgxEUk2szRuy9iVFqwB9gx+tQ/bvG/wD0L3h//wAH0/8A8h0fbvG//QveH/8AwfT/APyHR0S/re4dW/62MjwvY+N/Dfhy30r+xvD9z5DSHzf7bnTdukZ+n2Q9N2Ovau3gaZreM3SJHMVBkSNy6q2OQGIBIz3wPoK5/wC3eN/+he8P/wDg+n/+Q6Pt3jf/AKF7w/8A+D6f/wCQ6AOkorm/t3jf/oXvD/8A4Pp//kOj7d43/wChe8P/APg+n/8AkOgDpK5v4cf8ks8Kf9gWz/8ARCUfbvG//QveH/8AwfT/APyHUXw6af8A4Vb4V2xxkf2NZ4JkI/5Yp/s0AS+A/wDkXbr/ALDWq/8ApwuK6Sub8B/8i7df9hrVf/ThcV0lABRRRQAUUUUAFFFFABRRRQAVzfgP/kXbr/sNar/6cLiukrm/Af8AyLt1/wBhrVf/AE4XFAHSUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHN/Ef/AJJZ4r/7At5/6Ieukrm/iP8A8ks8V/8AYFvP/RD10lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc34X/5GLxn/wBhqP8A9N9nXSVzfhf/AJGLxn/2Go//AE32ddJQAUUUUAFFFFADJpUggeaVtscalmY9gBkmuPsPHd7Ouj31/oX2TRtblSKyuBd+ZOpkGY/Oi2AIGA/hd8EjOOcdHr98+l+G9Sv47Vrx7W1lmW3UZMpVSduPfGK8wjsF0Hw94L1aLxC2rW3222W00ltht/3x2f6PtHmExK7FQ7SABT04II6yt5r8W/6X4hLSN/X8F/Vz1+iiigAooooAKKKKAOb8L/8AIxeM/wDsNR/+m+zrpK5vwv8A8jF4z/7DUf8A6b7OukoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOb+HH/JLPCn/YFs/wD0QldJXN/Dj/klnhT/ALAtn/6ISukoAKKKKACiiigAooooAKKKKACiiigAooooA5vxR/yMXgz/ALDUn/pvvK6Sub8Uf8jF4M/7DUn/AKb7yukoAKKKKAMvxBrkeg6ek7QvczzzJb2ttGQGmlc4VcngDqST0AJ7VS0fxHe3HiCXQ9f0yLT9QW2F3F9mujcQzRbtpKuUQhlbAIKj7wIJ7UvHhFtceGdSnIW0sdaja4djhUEkckSsT2AeROfeo724gk+LVrMJo0i0nRLh72UuAsQlkjKBj2yInbnsuaI76+f4RuEvLy/Oxp634hurLWbPRdF06PUNTuoZLjbPc+RDFEhUFncK7ZJcAAKc85wBmq1v45tj4Xu9VvrOe3uLK6NjPYqQ7tchggijPAfczLtPGdwzjnGRq7p4i+Jel2thqr6W0OlNeWupWRjaS8SRtrRoXDRsg2oxyrHJQgjqeRuBIvh1LKLUC1no/jGNbzWohlpldctM7HKh1kmCsw+VSuQFA2gim7Lv/wDJW/rz8gemv9fC3/Xl5nqmmalrLRzy+ItJtdNiSLzVe3vjcYA6h8xptYD+7uHXnpnFsPHd7Ouj31/oX2TRtblSKyuBd+ZOpkGY/Oi2AIGA/hd8EjOOcZl5dS+EfE+oW2jz3+sWaaFPf3OnXV5JdtFKhXytryMzDzAXG3ODtyB1zjR2C6D4e8F6tF4hbVrb7bbLaaS2w2/747P9H2jzCYldiodpAAp6cEOPvNfL82v00/EUlZff+Sf66/gd3d+JNSuNau9O8MaRBqJ08qt5PdXpto0kKhhEpEbln2kEggAbhzngdFGzPEjOjRsyglGIJU+hxkflXlOk6TC8PjWbWtf1HS7qw1a6nVre9e2W2jYB45WVSFlBXH3ww+XaBwc+heFL2/1HwfpF7rEfl39xZxSXC7duHKAnjtz27Uo6xv5J/erjekvv/D+v60NaiiigArm/hx/ySzwp/wBgWz/9EJXSVzfw4/5JZ4U/7Atn/wCiEoATwEQ3hu5KkEHWdVII7/8AEwuK6Wub8B/8i7df9hrVf/ThcV0lABRRRQAUUUUAFFFFABRRRQAVzfgP/kXbr/sNar/6cLiukrm/Af8AyLt1/wBhrVf/AE4XFAHSUUUUAFFFFABWN4nvNetNMU+F9Ptbu8kfaXvJzHFbrtJ8xgBufBAG0YJz1FbNR3ALWsoUZJQgAd+Kmd+V2KjuYPw/1a8134e6LqmqSiW8u7RJZnCBQzHrwOBXRVy3wztLmw+GPh+1vreW2uIbJFkhmQo6HHQqeQa3tT0yDVrM2t1JdRxlg260u5bZ8j/biZWx7ZxWk/idiI7Eekavb61bTz2qSIsF1NasJAAS8UjRsRgnjKnHt6VeYkKSo3EDgZxmuN8D+CU0Bbi4uW1NLj+0LuSJJdXuJo2ieZyjGMylGJUg5Ybs8nmuzqXsP7T9WcL4U8Q+KdQ+IGp6b4otrPT4o9OgurextpPNMO+SRTvlwNzfJ/DhQMdeTXdVyVnZ3S/GLVb1raYWsmi2sSTmM+WziaYlQ3QkAg49xXW0L4V8/wA2D+J/L8kFFFFABRRRQBzfxH/5JZ4r/wCwLef+iHrpK5v4j/8AJLPFf/YFvP8A0Q9dJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHCaZ4s8OaD4t8YWuua/pem3D6tFIsV5exwuymwtAGAYg4yCM+xrX/4WP4I/6HLw/wD+DSD/AOKo8L/8jF4z/wCw1H/6b7OukoA5v/hY/gj/AKHLw/8A+DSD/wCKo/4WP4I/6HLw/wD+DSD/AOKrpKKAOb/4WP4I/wChy8P/APg0g/8AiqP+Fj+CP+hy8P8A/g0g/wDiq6SigDm/+Fj+CP8AocvD/wD4NIP/AIqsy08RfCrT9Tk1Kw1jwda30ufMuobq1SV89cuDk/nXZXFzBZwma7njgiBALyuFUEkADJ9SQPqaWeeG1t5J7mVIYY1LPJIwVUA6kk8AUeYb6HP/APCx/BH/AEOXh/8A8GkH/wAVR/wsfwR/0OXh/wD8GkH/AMVWvpes6XrlobrRNStNRtwxQzWk6yoGHUZUkZ5HHvV2gDm/+Fj+CP8AocvD/wD4NIP/AIqj/hY/gj/ocvD/AP4NIP8A4qukooA5v/hY/gj/AKHLw/8A+DSD/wCKo/4WP4I/6HLw/wD+DSD/AOKrpKKAOS8D6lY6vqni6+0q8t760l1pPLuLaVZI3xYWgOGUkHBBH1FdbXN+F/8AkYvGf/Yaj/8ATfZ10lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfw4/5JZ4U/7Atn/wCiErpK5v4cf8ks8Kf9gWz/APRCV0lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHJeONSsdI1TwjfareW9jaRa0/mXFzKscaZsLsDLMQBkkD6mrP/Cx/BH/AEOXh/8A8GkH/wAVR4o/5GLwZ/2GpP8A033ldJQBzf8AwsfwR/0OXh//AMGkH/xVH/Cx/BH/AEOXh/8A8GkH/wAVXSUUAcvP4/8AAV1byW914t8OTQyqUkjk1KBldT1BBbBFU7LxT8MNN0yTTtO13wlaWMu7fawXlskT7hhsoDg5HXjmuxlljgheWeRY441LO7nCqBySSegqppWt6Vrts1xomp2eowK21pbO4WVQfQlSRmgLnL3viX4W6lp0On6jrXhC7soABFbT3Vq8cYAwNqk4GBxxVqLxv8O4NPFhB4n8MR2YQxi2TULcRhP7u0NjHtXQanq+m6JZ/a9Z1C10+23BfOu51iTJ6DcxAzUN74k0PTdNh1HUdZ0+0sbggQ3U90iRSZGRtcnByATxR3A5/SvFnwz0K2a30TX/AAnp0DNuaKzvLaJSfUhSBmorTxF8KtP1OTUrDWPB1rfS58y6hurVJXz1y4OT+ddBpfi7w3rl2bXRPEGlajcBS5htL2OVwo6narE45HPvU9t4g0a81abS7TVrGfULfPnWkVyjSx467kByPxFPW4tLHNX3if4Xanf299qWt+Eby7tv9RcXF3aySRc5+VicrzzxWj/wsfwR/wBDl4f/APBpB/8AFVp3niLRNO1KDT9Q1iwtb24x5NtPdIkkuTgbVJyeeOK0aXQfU5v/AIWP4I/6HLw//wCDSD/4qj/hY/gj/ocvD/8A4NIP/iq6SigDm/8AhY/gj/ocvD//AINIP/iqi+HVzAvwt8KhpowRo1mCC44/cpXU1zfw4/5JZ4U/7Atn/wCiEoAPAf8AyLt1/wBhrVf/AE4XFdJXN+A/+Rduv+w1qv8A6cLiukoAKKKKACiiigAooooAKKKKACub8B/8i7df9hrVf/ThcV0lc34D/wCRduv+w1qv/pwuKAOkooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOb+I//ACSzxX/2Bbz/ANEPXSVzfxH/AOSWeK/+wLef+iHrpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA5vwv8A8jF4z/7DUf8A6b7Oukrm/C//ACMXjP8A7DUf/pvs66SgAooooAKKKKAPNfi54bs7nT7bXrmW7luLW+sY7eBrhvIhJukBcRjjeQxG4546Yq78QbqefxR4V0OKwGox3c0909o7hIpmhRSglbBwgZw54PKLwTxXR+K/D3/CT6GNO+0/Zf8ASYLjzPL3/wCqlWTGMjrtxntnvR4h8PHWJbC9srr7DqmmytLaXJj8xRuUq6OmRuRlPIBB4BBGKS2+d/wX6jb/AC/zK/h3XJL7WtT03VdJi0zWLRYnmEE3nRzxNu8t1k2oWGVcYKggg+ua6KsPQvD82nahe6pqt8t/ql8qRyzRweTGkaZ2pGm5ioyzHlmJJPPQDcqmSFFFFIYUUUUAc34X/wCRi8Z/9hqP/wBN9nXSVzfhf/kYvGf/AGGo/wD032ddJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc38OP+SWeFP+wLZ/+iErpK5v4cf8ks8Kf9gWz/8ARCV0lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHN+KP+Ri8Gf9hqT/033ldJXN+KP+Ri8Gf9hqT/ANN95XSUAFFFFAHI+PP9IuPDOmzAG0v9ZjS5RvuyKkUkoQjuC0a8d8U24iSz+MthJbKFbUNGuFuQvG/yZYvLY+uPMcA+9bfiLQl1/TUgW4a0ubedLm1uUUMYZUOVbB6jqCO4JGR1rPtPDWpC7vNU1HWYptamszZ29zb2flQ2i5JysTO5JLYLbnIO1Rgd1HR39fxjb8wev4fncy/E072vxN0O7s9Om1u5gsLlWsLfYJbdXZMThpGWMZKFMFgTnjOGFTfDLZ/YWp/u/skzatcyTacQQbBmYN5RGAM4IfK/KS5IJBBNmbwpqiala6zp2uRR60tilleT3Nj5sN2qncHMSuhVtxYja2PmIIPFTaf4UnsNF1qIaq8uq6y0ks9+0ICpK0YjUrGDwqhVwuSTjliTmnrGL72f53/q/XyDSTXy/K39W/M5pr2ebwn4x8eW5/0iWzuItKkHWO1hVtjL/vyb5MjqCnoKn8SaXZ6P4H8Ly6fEiSaZqOn/AGZ1GGPmSpG/PX51kbPrnnNdjY6HZ2Xhi30HyxJZQ2i2ZQjhowmzH4isGx8F36DTLTWNcGoaXpEiS2cAtPLldkBEfnybyJNvB+VUywBOelPRS02Tj+Df5iesbta6/ilb7tjAljTTdJ8W6Nr2iXt7dapdXM6TJYvJDdxOMx7pgCibFwvzspGzjtXY+B7y51D4f+H7y/ZnubjTbeSVm6sxjUkn8ah1nw9q2tm5sZ9dSLRbobZoIrPbclD96MT78BTyP9XuwThs8joIoo4IUihRY441CoijAUDgAUo6Rt6fhcctXf1/Gw+iiigArm/hx/ySzwp/2BbP/wBEJXSVzfw4/wCSWeFP+wLZ/wDohKAE8BDHhu5BJP8AxOdV5Pf/AImFxXS1zfgP/kXbr/sNar/6cLiukoAKKKKACiiigAooooAKKKKACvP/AAnoOo3ul31xbeLNY0+J9a1TbbW0VmY0xfzjgyQM3OM8seT2HFegVzfgP/kXbr/sNar/AOnC4oAP+EX1f/oe/EH/AH40/wD+RaP+EX1f/oe/EH/fjT//AJFrpKKAOb/4RfV/+h78Qf8AfjT/AP5Fo/4RfV/+h78Qf9+NP/8AkWukooA5v/hF9X/6HvxB/wB+NP8A/kWj/hF9X/6HvxB/340//wCRa6SigDm/+EX1f/oe/EH/AH40/wD+RaP+EX1f/oe/EH/fjT//AJFrpKKAOb/4RfV/+h78Qf8AfjT/AP5Fo/4RfV/+h78Qf9+NP/8AkWukooA5v/hF9X/6HvxB/wB+NP8A/kWj/hF9X/6HvxB/340//wCRa6SigDm/+EX1f/oe/EH/AH40/wD+RaP+EX1f/oe/EH/fjT//AJFrpKKAOb/4RfV/+h78Qf8AfjT/AP5Fo/4RfV/+h78Qf9+NP/8AkWukooA878feHNUg+G3iWWXxprlykek3TNDLDYhJAIWJVttsGwehwQfQivRK5v4j/wDJLPFf/YFvP/RD10lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAcJpmjX2o+LfGEtn4l1TSkXVolMNnHasjH7BaHcfNhds844OOBx1zr/wDCL6v/AND34g/78af/APItHhf/AJGLxn/2Go//AE32ddJQBzf/AAi+r/8AQ9+IP+/Gn/8AyLR/wi+r/wDQ9+IP+/Gn/wDyLXSUUAc3/wAIvq//AEPfiD/vxp//AMi0f8Ivq/8A0PfiD/vxp/8A8i10lFAHN/8ACL6v/wBD34g/78af/wDItH/CL6v/AND34g/78af/APItdBcSNDayyRxmVkQsqL1YgdBXnGk+ItdNl4T1qXXU1F/ENwkVxpQgjWKEMjM/klV8wGLb829m6NnacYFq7en4ieiv6/gdP/wi+r/9D34g/wC/Gn//ACLR/wAIvq//AEPfiD/vxp//AMi10lFAzm/+EX1f/oe/EH/fjT//AJFo/wCEX1f/AKHvxB/340//AORa6SigDm/+EX1f/oe/EH/fjT//AJFo/wCEX1f/AKHvxB/340//AORa6SigDkvA9rNZap4ut7m/uNQlTWk3XNysYkfNhaHkRqq8Zxwo4Hc811tc34X/AORi8Z/9hqP/ANN9nXSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHN/Dj/AJJZ4U/7Atn/AOiErpK5v4cf8ks8Kf8AYFs//RCV0lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHJeOLWa91Twjb21/cafK+tPtubZYzImLC7PAkVl5xjlTwex5qz/wi+r/9D34g/wC/Gn//ACLR4o/5GLwZ/wBhqT/033ldJQBzf/CL6v8A9D34g/78af8A/ItH/CL6v/0PfiD/AL8af/8AItdJRQBzf/CL6v8A9D34g/78af8A/ItH/CL6v/0PfiD/AL8af/8AItS+LdYu9NtdPtNLZEvtVvUsoJXXcIchmeTb32ojEDpnGeKo6Xd6ro/jhfD+qapLq1teWD3lrc3MUaTI8bqsiHykRGGJEI+UEc9ewtXb+tr/AJA9P687fmWf+EX1f/oe/EH/AH40/wD+RaP+EX1f/oe/EH/fjT//AJFqDxFf6jN4w0nw/Zam+jwXlrPcPeRRRvLI8ZQCKPzFZBw7McqTheMcmsm28aanB4Knmlltry//ALWfSbG9ZdsNwRJsE7gEDCgOWCkA+W2MZwF/X42/MOv9dr/kbv8Awi+r/wDQ9+IP+/Gn/wDyLR/wi+r/APQ9+IP+/Gn/APyLWbY66lh4Y1nWrLxeni+OwtHleOL7OwSVFLbVMCjaDjo249Oeua0upa54ft9A1rUfEDajb6pdW9tdWTW0SRIZ+FMBVQ42sRw7Plc9+af2ren47feGyv6/hubf/CL6v/0PfiD/AL8af/8AItH/AAi+r/8AQ9+IP+/Gn/8AyLWR8TvFWp6Lo72/hqVY9QREubicoH+zW/mBc4IIy7fIAe28j7td3QHWxzf/AAi+r/8AQ9+IP+/Gn/8AyLR/wi+r/wDQ9+IP+/Gn/wDyLXSUUAc3/wAIvq//AEPfiD/vxp//AMi1F8OonPwt8KkXEg/4k1nwAvH7lPauprm/hx/ySzwp/wBgWz/9EJQAeA/+Rduv+w1qv/pwuK6Sua8BHPhu5JBH/E51Xg9v+JhcV0tABRRRQAUUUUAFFFFABRRRQAVzfgP/AJF26/7DWq/+nC4rpK5vwH/yLt1/2GtV/wDThcUAdJRRRQAUUUUAFFFYnirSb7WdJ+zWOt3WjoGLXElmq+bLHtPyK5B8vJwdw544xSk7K40ruxt0VyPwqYt8J/DbMSzGxQkk5JP1ro9T1fTdEszd6zqFrp9sGCma7mWJMnoNzEDNVJcrsJaot0VyPg/4g6N4nM1sut6RLf8A225igtra7RnkijkYI4XcScoobI4PUcV1c0fnQvGWZN6ldyNhhkdQexpa2DrYfRXnOoaJomk+OvDtl4RtI7bWkuPP1B7X772exg7XLdX3MVCl8sW5HQmvRqFqr/1/X63DZ2CiiigAooooA5v4j/8AJLPFf/YFvP8A0Q9dJXN/Ef8A5JZ4r/7At5/6IeukoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDm/C/wDyMXjP/sNR/wDpvs66SuE0zWb7TvFvjCKz8NapqqNq0TGazktVRT9gtBtPmzI2eM8DHI5641/+Eo1f/oRPEH/f/T//AJKoA6Siub/4SjV/+hE8Qf8Af/T/AP5Ko/4SjV/+hE8Qf9/9P/8AkqgDpKK5v/hKNX/6ETxB/wB/9P8A/kqj/hKNX/6ETxB/3/0//wCSqANXXY9Ql8O6jHojpHqLW0gtXfosu07CfxxXmdtpVns0MeGPC2o6d4oiurdr6/msZIGCbgbjz7lgFuAy7hgM+SQR0yO3/wCEo1f/AKETxB/3/wBP/wDkqj/hKNX/AOhE8Qf9/wDT/wD5KoWkr+n4f1qD1VvX8f60Okorm/8AhKNX/wChE8Qf9/8AT/8A5Ko/4SjV/wDoRPEH/f8A0/8A+SqAOkorm/8AhKNX/wChE8Qf9/8AT/8A5Ko/4SjV/wDoRPEH/f8A0/8A+SqAOkorm/8AhKNX/wChE8Qf9/8AT/8A5Ko/4SjV/wDoRPEH/f8A0/8A+SqADwv/AMjF4z/7DUf/AKb7OukrkvA91Ne6p4uuLmwuNPlfWk3W1y0bSJiwtByY2ZecZ4Y8HseK62gAooooAKKKKACiiigAooooAKKKKACiiigAooooA5v4cf8AJLPCn/YFs/8A0QldJXN/Dj/klnhT/sC2f/ohK6SgAooooAKKKKACiiigAooooAKKKKACiiigDm/FH/IxeDP+w1J/6b7yukrkvHF1NZap4RuLawuNQlTWn221s0ayPmwuxwZGVeM55YcDueKs/wDCUav/ANCJ4g/7/wCn/wDyVQB0lFc3/wAJRq//AEIniD/v/p//AMlUf8JRq/8A0IniD/v/AKf/APJVADPG1ldSQaTqthbyXUuj6il29vCMvJEVaOQKO7BZCwHU7cDk1QjupdW8XnxPFpupDTdJ0qaKJJrN4Z7qWRlZlSKQK/CxKBkAEvxnBrS/4SjV/wDoRPEH/f8A0/8A+SqP+Eo1f/oRPEH/AH/0/wD+SqSutvP8VYN/687nP68sOqeI9P1LxV4fvdQ8NzaarwWcmnPdG1uixLedbIHO7YVAbaQpDDIzzjyeFr+98M+ZFo1x/ZGm+IYtR07R7kYlNmqBXRYyflGWkdYzjjC4GQK7j/hKNX/6ETxB/wB/9P8A/kqj/hKNX/6ETxB/3/0//wCSqa02/rW/9eQO73/rS39eZmWS/wBt/EEa/p2l3sFjBpclpcPd2b2r3rs6MiCOUKxCBX+ZgB8+AeuMZfDOk6xqek2fh3RtWs7SyvYrq4k1BbmKG0WJt6xQRzHaCzqozENoUNz0B6z/AISjV/8AoRPEH/f/AE//AOSqP+Eo1f8A6ETxB/3/ANP/APkqhaNW6f53/MT1Tv1/yscb4q8HeLbTwd4h+z6xYarNqUwnmVNFlNxL867UDLcEAIoAACdAe5Jr1C0W5SziW/mimuQoEskMRjRm7kKWYgexY/WsH/hKNX/6ETxB/wB/9P8A/kqj/hKNX/6ETxB/3/0//wCSqOlh9bnSUVzf/CUav/0IniD/AL/6f/8AJVH/AAlGr/8AQieIP+/+n/8AyVQB0lc38OP+SWeFP+wLZ/8AohKP+Eo1f/oRPEH/AH/0/wD+Sqi+HUrj4W+FQLeQ/wDEms+QV5/cp70AS+A/+Rduv+w1qv8A6cLiukrm/Af/ACLt1/2GtV/9OFxXSUAFFFFABRRRQAUUUUAFFFFABXN+A/8AkXbr/sNar/6cLiukrm/Af/Iu3X/Ya1X/ANOFxQB0lFFFABRRRQAUyZDJBIi9WUgZ+lPopNXVmNOzuYXgnRLnw34H0jRr54pLiytlhkaEkoSPQkA4/AVu0UVTd3cWxl6Bo39h2dzB5/n+fe3F3u2bdvmytJt6npuxnvjoKs6ql9Jo14mkSRRag0Di1km+4su07C3B4Bxng1boqWrqw763OI8H6N4j8NWsNm2haKBK4fUNQGszS3FzIfvzMDajex5OCwHYECu3ooqm7kpWCiiikMKKKKAOb+I//JLPFf8A2Bbz/wBEPXSVzfxH/wCSWeK/+wLef+iHrpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA5vwv/AMjF4z/7DUf/AKb7Oukrm/C//IxeM/8AsNR/+m+zrpKACiiigAooooA5zxN488P+E7i2tdWvl+23UkccNnD88zb2Chtv8K5/iOBxjrxWnret2ug6eLq8Er75FihggTfJPI33URe5P5AAkkAE1y3xVtLdfCRu1giFy9/p8bTBBvZRdxkKW64BJ496j8cR3tz8QvBlraXYso5WvT9p8sO0cghGNgYFd+wy43AgcnB6FLVfP9Ex6X+R1ukapNqcMhutJvtKljYAw3ojJII4YNG7oR7bsjHIHGdCuV8N32qQeK9Y8PapqDarHZwwXMF7JEiS7ZS4McgjVUJBjyCFGQ3I4yeqqmLyCiiikAUUUUAc34X/AORi8Z/9hqP/ANN9nXSVzfhf/kYvGf8A2Go//TfZ10lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfw4/5JZ4U/wCwLZ/+iErpK5v4cf8AJLPCn/YFs/8A0QldJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfij/AJGLwZ/2GpP/AE33ldJXN+KP+Ri8Gf8AYak/9N95XSUAFFFFAFHWNYtND01ry+L7AyxpHGu55XY4VFUdWJIAH9Ko6N4oh1XU59MudPvdK1KCJZzaXwj3NETgOrRu6MMjBw2QeoGRWd44+XUvCUsn/HtHrkfm+gLQyqhP/A2UfUii8+f4xaV5PWLRbo3BHZWmh2A/Uq+PoaI6v5tfcr/15BLT7k/vdjU1rxLDo97a2EVleanqN2ryQ2VkqbyiY3uWkZUVQWUfMwySAM1Bb+LU1DRRqGjaRqOpOs7W89nF5Mc1tIuQyuJZEXIPHDHOQRkHNY2ui91D4oWVv4duYLDU7DTHluLm7haaKSCWTAj8oMhY74t24Ou3GOd2BL8P5/sOna/aam6tqGn6nM2o3SHKTu6rL5ijA2jY6jbzt24y33il8N32b+52+7v1vtoDTTsvL8Vf+vLzL+l+Mxf+IbjR7zQdU0qe2tBdzSXj2zRxxliF3NFM+CdrYB7KT2plp48sbq8sVk07UbWy1KTyrDUbiNBBdMQSoXDl13AErvVc9uozz0Vrd6h8H/E2uKjf2j4jsri9Vf4ljaIrBGPQiMJx/eLetXfFUsFz4C8Of2cQ32jUNMNnsP8A02jbI9ggY/QGqS95J/3V97f5Ce10+/4Jfg/yNXU/HVnp15fxx6bqV/BpZA1G7tIkaOzJUPhtzBnIRgxEauQDzzxXR29xFd20VxbSLLDMgeN1OQykZBHsRXmBsdb1628Zz+FdRtNO0+7u5rea3uYS8kksaCKZ0kyBBuC45STGN2BnFd54Sv7TVPBuj3umwNb2k9lE8MLHJjQoMLnvgcZ9qUdY39PxX9W/EbupW9fw/rX8DXooooAK5v4cf8ks8Kf9gWz/APRCV0lc38OP+SWeFP8AsC2f/ohKADwH/wAi7df9hrVf/ThcV0lc14CAXw3chQABrOqgAdv+JhcV0tABRRRQAUUUUAFFFFABRRRQAVzfgP8A5F26/wCw1qv/AKcLiukrz/wn4K8K6vpd9far4a0e+u5da1TzLi5sIpJHxfzgZZlJOAAPoKAPQKK5v/hXHgj/AKE3w/8A+CuD/wCJo/4Vx4I/6E3w/wD+CuD/AOJoA6Siub/4Vx4I/wChN8P/APgrg/8AiaP+FceCP+hN8P8A/grg/wDiaAOkorm/+FceCP8AoTfD/wD4K4P/AImj/hXHgj/oTfD/AP4K4P8A4mgDpKK5v/hXHgj/AKE3w/8A+CuD/wCJo/4Vx4I/6E3w/wD+CuD/AOJoA6Siub/4Vx4I/wChN8P/APgrg/8AiaP+FceCP+hN8P8A/grg/wDiaAOkorm/+FceCP8AoTfD/wD4K4P/AImj/hXHgj/oTfD/AP4K4P8A4mgDpKK5v/hXHgj/AKE3w/8A+CuD/wCJo/4Vx4I/6E3w/wD+CuD/AOJoA6Siub/4Vx4I/wChN8P/APgrg/8AiaP+FceCP+hN8P8A/grg/wDiaAD4j/8AJLPFf/YFvP8A0Q9dJXnfj7wD4Ps/ht4lurPwnocFxDpN1JFLFpsKvGwhYhlIXIIIyCK9EoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDm/C/8AyMXjP/sNR/8Apvs66SuE0zwn4c17xb4wutc0DS9SuE1aKNZbyyjmdVFhaEKCwJxkk49zWv8A8K48Ef8AQm+H/wDwVwf/ABNAHSUVzf8AwrjwR/0Jvh//AMFcH/xNH/CuPBH/AEJvh/8A8FcH/wATQB0lFc3/AMK48Ef9Cb4f/wDBXB/8TR/wrjwR/wBCb4f/APBXB/8AE0Aa+raRY65Y/Y9Ug8+DzY5dm9l+ZHDqcqQeGUH8KTVtGsdcsha6nAZY1cSIVdo3jcdHR1IZGH95SDWT/wAK48Ef9Cb4f/8ABXB/8TR/wrjwR/0Jvh//AMFcH/xNAGppGhadoUMsemwMhmfzJpZZXllmbGNzyOSznAAyxPAxWhXN/wDCuPBH/Qm+H/8AwVwf/E0f8K48Ef8AQm+H/wDwVwf/ABNAHSUVzf8AwrjwR/0Jvh//AMFcH/xNH/CuPBH/AEJvh/8A8FcH/wATQB0lFc3/AMK48Ef9Cb4f/wDBXB/8TR/wrjwR/wBCb4f/APBXB/8AE0AHhf8A5GLxn/2Go/8A032ddJXJeB9NsdI1TxdY6VZ29jaRa0nl29tEscaZsLQnCqABkkn6mutoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOb+HH/ACSzwp/2BbP/ANEJXSVzfw4/5JZ4U/7Atn/6ISukoAKKKKACiiigAooooAKKKKACiiigAooooA5vxR/yMXgz/sNSf+m+8rpK5Lxxptjq+qeEbHVbO3vrSXWn8y3uYlkjfFhdkZVgQcEA/UVZ/wCFceCP+hN8P/8Agrg/+JoA6Siub/4Vx4I/6E3w/wD+CuD/AOJo/wCFceCP+hN8P/8Agrg/+JoA2tT0yz1nTpbDU7dbi2mADxtnscggjkEEAgjkEAiqFp4S0aysb21jtpZFv4jDdS3NzLPNMmCNrSuxcgBmwN3GTjGaqf8ACuPBH/Qm+H//AAVwf/E0f8K48Ef9Cb4f/wDBXB/8TSsgJ7nwXoVza2MBtZYf7PgFvazWt3NBNFEABsEsbB9vAyC3OOasW3hjR7TQLjRbWyWKxulkWdFdg0u8YdmfO4sc8sTu96of8K48Ef8AQm+H/wDwVwf/ABNH/CuPBH/Qm+H/APwVwf8AxNN63v1BaWt0OgggitraO3gQJFEgRFHZQMAflWNpvgvQdJvo7uxsmV4Sxt43uJZIrYtkHyYmYpFkEj5AvBI6VB/wrjwR/wBCb4f/APBXB/8AE0f8K48Ef9Cb4f8A/BXB/wDE0dbhbSxJf+BvD+p3lxcXVnKGujm6jgu5oYrk4xmWJHCScDHzA5HFbsMMVvBHDbxpFFGoRI0UKqKBgAAdAB2rnv8AhXHgj/oTfD//AIK4P/iaP+FceCP+hN8P/wDgrg/+Jo6WDrc6Siub/wCFceCP+hN8P/8Agrg/+Jo/4Vx4I/6E3w//AOCuD/4mgDpK5v4cf8ks8Kf9gWz/APRCUf8ACuPBH/Qm+H//AAVwf/E1F8OraBvhb4VLQxknRrMklBz+5SgCXwH/AMi7df8AYa1X/wBOFxXSVzfgP/kXbr/sNar/AOnC4rpKACiiq2o6jZ6Tp8t9qdzFa2sIzJLK21V7dfrxjuaALNFY+m+KdL1Wd4bc3kUioXC3mnz229R1Keai7wP9nNP8OeJtH8W6Omq+Hb1b2zd2QSKrKQynBBVgCD9R0IPQ0AatFYN/428P6Z4butfvtQ8rTLSdreefyZDskWTyyNoXcfn4yBjv05rRu9YsLHQ5dYuLlRp8MBuXuEBdfLC7tw25JGOeM0dLjs72LtFNjdZY1kQ5VgGU+oNOoFuFc34D/wCRduv+w1qv/pwuK6Sub8B/8i7df9hrVf8A04XFAHSUUUUAFFFFABRRUV1d29jaS3V9PFbW8Kl5JpnCIijqSTwBQBLRVTS9Us9a0q31LS5xcWdygkhlAIDqeh55q3QAUUUjMEUs5CqoyST0FAC0Viaf4w0bU9UTT7ee4S5kVmhW5spoBOF6mNpEVZABz8pPHPStugAooooAKKKKAOb+I/8AySzxX/2Bbz/0Q9dJXN/Ef/klniv/ALAt5/6IeukoAKKKKACiiigAooooAKKiuru3sbSW6vp4ra3hUvJNM4REUdSSeAKh0zVbLWdJt9T024WeyuI/MimAIDL684NAFuisTSvF+i63eC30y4mmLBjFMbSVIZwOvlzMoST1+Rjxk9BW3QAUUUUAFFFFABRRRQBzfhf/AJGLxn/2Go//AE32ddJXN+F/+Ri8Z/8AYaj/APTfZ10lABRRRQAUUUUARXRcWc3lSLHJ5bbXf7qnHBPtXjHhybSS3gs6ba3Fl4imulXUdXmidFvwqN5wN0w23QkIygVn7EBdvHr2t6Wmt6Bf6XJLJCl7bSW7SxnDIHUrke4zXJyeG/FGq6bpei6sdItrDT57aaS8tJZHluPIdXULEyBYslBk73wM49QR+LXy/W//AA3UJWcfv/4H/D9DuqKKKACiiigAooooA5vwv/yMXjP/ALDUf/pvs66Sub8L/wDIxeM/+w1H/wCm+zrpKACiiigAooooAKKKpazrFjoGkT6pq0xgs7cBpZRGz7ASBkhQTjnk44HJ4FAF2iqGo63p2k2tvcX1wFiupo4ICiNIZXc4UKFBJz7dsk8DNX6ACiiigAooooAKKKKAOb+HH/JLPCn/AGBbP/0QldJXN/Dj/klnhT/sC2f/AKISukoAKKKKACiiigAooooAKKKKACiiigAooooA5vxR/wAjF4M/7DUn/pvvK6Sub8Uf8jF4M/7DUn/pvvK6SgAooooA5Tx1NJKND0dZHjh1fU0trkoxUtCsckrJkcjd5YU47E1SsNLsvCvxQtdP0G1isNO1TS5pZLK2QRwrNDJGBIEHAJWUgkdcDPSt3xVok+tafbNp8scOoafdx3lo8wJTzEyCrY5wysykjkbs84xVC20bXp9YufEGpLpsGqR2D2en2kM0k0ERZtzM8hRGbcyx5AUYC9TnhRdnf1/9J0/Hp8wkr/h99/8AL/IyfHTaefGmhxeJLV9U0eS1uc6bFbvd5nBjKyvbIGaRQocBtpClh0yDXOxa8dP+GsUVndXUFnq3iBtPtI4mZrmztmckwgA7kk2owVTym9RwVwOym0XxJb6/beI7P+zLvUZNNSyv7KaeSGDcrF98UgR2UbmYYKnI28gjmmfAeo3On3d3dX1tHrk2rx6xD5KMbeCWNFjWPn5mUou1m4J3EgDGKaVtH8//AAK/z0/DQH3X9e7+Gv8AmVrJtO0+01vS/CfhiXwz4kbS5Jba2mjiQ3eAQsm6J3SQhyASxLDdzw3PPHUPCWmweGdR8JtB/wAJB/aFpb6g0RP2pkmcRyi8/jzlv+WnO4DHSu+sdG1q98Srr2vCwtLi1s5LWztbOV7hF8xlZ5HdljLZ2KAoUYAPJzw19H13XtTsH8SJp9rY6dcC5WCyneY3UqghGcsibFUndtG7JC/Nxy18Sk/K/wAm/wA1uhPWLS8/xS/J7f1fmPivdya/4f1WxsZWXT9HMcl9Ih4muN6FIAe+3IdvfYOcsB6jXn/iH4UaXd+F7/T9Akv7Se5YyKsmtXvkb2kDuzJ5hXk5P3Tyc13Vpax2VnFbQtK0cShVM0zyuR7u5LMfckmktg+1cmooooGFc38OP+SWeFP+wLZ/+iErpK5v4cf8ks8Kf9gWz/8ARCUAJ4Cz/wAI3c7iCf7Z1XJAx/zELiulrm/Af/Iu3X/Ya1X/ANOFxXSUAFch4ixcfEnwpZ3m02ey7uY0cfK9zGqBPbIV5GH0z2rr6zdc0Cx8Q2aW+oLIDDKJoJ4XKSwSDo6MOQeT9QSDkEijqmPyLtz/AMek3+438q8Z8FQP4C0bw14ntBt8P61YW0Otx5wttPsCxXQHYEkI/wBQx6GvU9O0G4s3dr7X9U1XKFFF2YVVAevEUaAn3bOKdp/hvT7DwjB4bKNdadFaC0KXOGMke3bhsAA5HsKFpdry/W6/r16Bo1Znm9xFHcfCm6imRZYpPFhV0cZVlOqYII7jFQass/gnwj4r8EXzs2mSaVdXPh+eRskxbCZLYk/xRk5X1Q/7PHc6d8O9J0zwbb+GYLm+ezgvFvFkllVpS6ziYAttwRuGOmcd881e8ZeDtL8c+Hn0jWfOWJmDpNbsFliYcZViDjIJB4OQSKNo2X9aJfhb+rlKXvXfe/4tmtYf8g22/wCuS/yFWKZDGIYUiXJVFCjPXAFPpyd22ZRVopBXN+A/+Rduv+w1qv8A6cLiukrm/Af/ACLt1/2GtV/9OFxSKOkooooAKKKKACsnxF4f0nxBYxprdhDfJav9ohjmG5VkCkBivQ9T1zWtTZEEkbI3RgQcVMk3FpDi7M5L4Uf8kl8N/wDXhH/Kuk1O9nsLMzWumXWpybgPs9o0SuR65ldFwPrmofD2iW3hvw7Y6NYvLJb2UIhjaYguQPUgAZ/AVo1pN3k2iVojh/AHiHVdSiu4b/Q9XRDqd6PtlzPbOkIE74jOJmf5cBPlUqMcHHNdxVWw0200uGSKxi8pJZ5LhxuLZkkYu55J6sScdPSp5ohPBJEzOokUqWRirDI6gjkH3FS9h/ab82cLrNxqH/Ca+HZPFVha2mnx37rYTWVw1wXuWjdU80siGMFS3ChwWIywA+bva5238Hp/adte6vrOpa01k/m2kV6YRHA+Cu8LFGm5gCQC+4jPGDzXRULawPf+v6/phRRRQAUUUUAc38R/+SWeK/8AsC3n/oh66Sub+I//ACSzxX/2Bbz/ANEPXSUAFFFFABRRRQAUUUUAZPiLw/pPiCxjTW7CG+S1f7RDHMNyrIFIDFeh6nrmvNhdzWf7K9k9srM0mnW8DBX2EpJIqN83b5WPPavXZEEkbI3RgQcVjWHhLS7LwVF4Vkje80yO1+ylLkgtJHjHzEAc+4xS6P5fqUnqvIyotU17w/rujafrS6XNp+qO1rALCB4Ws5FjZ1Q7nYSLtRhuATBA+XnjsK57TfCEVlqVvfX2ralq8tmrJZ/b5IyLYMMHaERdzEcbn3NjPPJz0NU9SEFFFFIYUUUUAFFFFAHCaZbeI5vFvjBtD1XS7O3/ALWiDR3mmSXDlvsFpkhlnjAGMcYPQ884Gv8AYfG//Qw+H/8AwQz/APyZR4X/AORi8Z/9hqP/ANN9nXSUAc39h8b/APQw+H//AAQz/wDyZR9h8b/9DD4f/wDBDP8A/JldJRQBzf2Hxv8A9DD4f/8ABDP/APJlH2Hxv/0MPh//AMEM/wD8mV0lFAHN/YfG/wD0MPh//wAEM/8A8mUfYfG//Qw+H/8AwQz/APyZWd468b6n4Ymgh0vQJrpGmt1n1CchLaFZZhHgc7nfn7oAAyCT2Oz4l1y40sWNlpcMU+q6nOYLRJiRGuFLPI+OdqqCcDqcDIzmjpf5D2K/2Hxv/wBDD4f/APBDP/8AJlH2Hxv/ANDD4f8A/BDP/wDJlamkR6zFDImvXNjdSbgY5rK3eAEY5BRnfBB77uc9BjnQoEc39h8b/wDQw+H/APwQz/8AyZR9h8b/APQw+H//AAQz/wDyZXSUUAc39h8b/wDQw+H/APwQz/8AyZR9h8b/APQw+H//AAQz/wDyZXSUUAcl4HS+i1Txcmq3Fvc3Y1pPMltrdoY2/wBAtMYRncjjA+8cnnjoOtrm/C//ACMXjP8A7DUf/pvs66SgAooooAKKKKACorqKCe0mhvER7eRGWVZACrKRgg57YqWs3xBokPiPQ7jSbu4uYLa6ASY2zhGdM/MmSDgMMqcYOCcEUnqrDW55f8OZUu/Gdtb39xPLpVhaynwmbhRi4g8xleXdk7mVdqLnB8tg2PmNexVi6x4V0/WLbTYsy2L6VcRz2UtmVRoCg27RkEbSpKlSMEH6VtVV9P6+8nrf+vT0CiiikMKKKKACiiigDm/hx/ySzwp/2BbP/wBEJXSVzfw4/wCSWeFP+wLZ/wDohK6SgAooooAKKKKACiiigAooooAKKKKACiiigDkvHCX0uqeEU0q4t7a7OtP5ctzbtNGv+gXecoroTxkfeGDzz0Nn7D43/wChh8P/APghn/8AkyjxR/yMXgz/ALDUn/pvvK6SgDm/sPjf/oYfD/8A4IZ//kyj7D43/wChh8P/APghn/8AkyukooA5v7D43/6GHw//AOCGf/5Mo+w+N/8AoYfD/wD4IZ//AJMq34n1yTRbG2FnCk99f3SWdpHIxCGRsncxHO1VVmOOSFx3qjpOs6xb+LG8PeIzZXEstmb21vLKFoFkVXCOjRs7kFSyHIYghugxyLX+vK/5A9P6+X5j/sPjf/oYfD//AIIZ/wD5Mo+w+N/+hh8P/wDghn/+TKNd1nVR4msPD2gmzgubq1mu5Lu9iaVI442RdojVkLsTIP4gFA75AqDR9X1/xFolwLWbTtN1Owv5bK5kltXuYJTHwWjUSxsAcg8sccjnrRv/AF52/MNn/Xa/5E/2Hxv/ANDD4f8A/BDP/wDJlH2Hxv8A9DD4f/8ABDP/APJlU/D+reJbnxfqlhqN3pd/p2mwos01np8lu/2lhu8obp5AdqEE9PvqPWo/C3jXU/EPjLUNMvtBm0a1gsYrq3S7YfaJA7uu51UkJ9z7vJ7k84AtWkv6/qwdG+39fqaH2Hxv/wBDD4f/APBDP/8AJlH2Hxv/ANDD4f8A/BDP/wDJlZ2teN9TsPG+laLbaBMljdX62k2p3RCo5MTSAQqDlvu8scAEEYPbtaFqr/1/WoPR2Ob+w+N/+hh8P/8Aghn/APkyj7D43/6GHw//AOCGf/5MrpKKAOb+w+N/+hh8P/8Aghn/APkyovh0s/8Awq3wrtkjA/sazwDGT/yxT/arqa5v4cf8ks8Kf9gWz/8ARCUAHgP/AJF26/7DWq/+nC4rpK5rwEd3hu5IzzrOqnkY/wCYhcV0tABRRRQAUUUUAFFFFABRRRQAVzfgP/kXbr/sNar/AOnC4rpK8/8ACfi3TtM0u+tLm21h5Y9a1Tc1tol5cRnN/OeJI4mU9exODx1FAHoFFc3/AMJ5pH/Pn4g/8JzUP/jFH/CeaR/z5+IP/Cc1D/4xQB0lFc3/AMJ5pH/Pn4g/8JzUP/jFH/CeaR/z5+IP/Cc1D/4xQB0lFc3/AMJ5pH/Pn4g/8JzUP/jFH/CeaR/z5+IP/Cc1D/4xQB0lFc3/AMJ5pH/Pn4g/8JzUP/jFH/CeaR/z5+IP/Cc1D/4xQB0lFc3/AMJ5pH/Pn4g/8JzUP/jFH/CeaR/z5+IP/Cc1D/4xQB0lFc3/AMJ5pH/Pn4g/8JzUP/jFH/CeaR/z5+IP/Cc1D/4xQB0lFc3/AMJ5pH/Pn4g/8JzUP/jFH/CeaR/z5+IP/Cc1D/4xQB0lFc3/AMJ5pH/Pn4g/8JzUP/jFH/CeaR/z5+IP/Cc1D/4xQAfEf/klniv/ALAt5/6Ieukrzvx9400u6+G3iW3itdcV5tJukUy6BfRoCYWA3O0IVR6kkAdSa9EoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDm/C//IxeM/8AsNR/+m+zrpK4TTPEtjo3i3xhb3kGqSO2rRODZ6TdXSY+wWg5eKNlB46E56HHIrX/AOE80j/nz8Qf+E5qH/xigDpKK5v/AITzSP8Anz8Qf+E5qH/xij/hPNI/58/EH/hOah/8YoA6Siub/wCE80j/AJ8/EH/hOah/8Yo/4TzSP+fPxB/4Tmof/GKAKHxW/wCRGH/YSsP/AEqiqn8RNOtH8TeGNV11d2gWjXMOoFz+5QSIuxpu3l7kwc8fMM8Zrb/4TzSP+fPxB/4Tmof/ABij/hPNI/58/EH/AITmof8AxiktPvv+CQ7mT4DisI/Emuv4TEa+F3SA24thi1Nz8/mmDHy7ceXnb8u4Hvmu6rm/+E80j/nz8Qf+E5qH/wAYo/4TzSP+fPxB/wCE5qH/AMYqm7iOkorm/wDhPNI/58/EH/hOah/8Yo/4TzSP+fPxB/4Tmof/ABikB0lFc3/wnmkf8+fiD/wnNQ/+MUf8J5pH/Pn4g/8ACc1D/wCMUAHhf/kYvGf/AGGo/wD032ddJXJeB7+HU9U8XXdslwkUmtJtW5tpLeQYsLQcxyKrDp3AyOehrraACiiigAooooAKKKKACiiigAooooAKKKKACiiigDm/hx/ySzwp/wBgWz/9EJXSVzfw4/5JZ4U/7Atn/wCiErpKACiiigAooooAKKKKACiiigAooooAKKKKAOb8Uf8AIxeDP+w1J/6b7yukrkvHF/DpmqeEbu5S4eKPWn3LbW0lxIc2F2OI41Zj17A4HPQVZ/4TzSP+fPxB/wCE5qH/AMYoA6Siub/4TzSP+fPxB/4Tmof/ABij/hPNI/58/EH/AITmof8AxigCv49VrZNC1oqzW+kaolxdbVLFIWjeJnwOcL5gY+gBPas9da03WfHaeIdPvIrrRNE0i48/ULc+bCXkdGKq65DFVhJIXJG5fWtj/hPNI/58/EH/AITmof8Axij/AITzSP8Anz8Qf+E5qH/xikrrbz/FWG9f687nMeI9S0XVvFukXfiK/bT/AA4dN+16bqQuXslkmkOGUzgo8Z8vaQm5d245B28XPA2oQaL4Q16eIyP4f0y5nl066lTaZ7cIJHbdgFx5hkAkOS3XLdTt/wDCeaR/z5+IP/Cc1D/4xR/wnmkf8+fiD/wnNQ/+MU+jS8/zv+G3oLdpvy/L9dxfAWnzWPg2zlvR/p+oA316fWaX52H0GQo9lArPsf8AkuGr/wDYCtP/AEdNV/8A4TzSP+fPxB/4Tmof/GKP+E80j/nz8Qf+E5qH/wAYpu3Ndf1o0JX5Wn1/zTKHjz/kP+Cf+w6P/Seauzrm/wDhPNI/58/EH/hOah/8Yo/4TzSP+fPxB/4Tmof/ABiktFbzv+CX6Derv5W/F/5nSUVzf/CeaR/z5+IP/Cc1D/4xR/wnmkf8+fiD/wAJzUP/AIxQB0lc38OP+SWeFP8AsC2f/ohKP+E80j/nz8Qf+E5qH/xiovh1cIvwt8KgiTjRrMcRMf8AlintQBL4D/5F26/7DWq/+nC4rpK5vwH/AMi7df8AYa1X/wBOFxXSUAFFFFABRRRQAUUUUAFFFFABXN+A/wDkXbr/ALDWq/8ApwuK6Sub8B/8i7df9hrVf/ThcUAdJRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc38R/+SWeK/8AsC3n/oh66Sub+I//ACSzxX/2Bbz/ANEPXSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfhf/AJGLxn/2Go//AE32ddJXN+F/+Ri8Z/8AYaj/APTfZ10lABRRRQAUUUUAFYFh438PanqMVlZX5eSdmW3la3kSG5K9RFMyiOUjBOEY9D6GtLWbq0stCvrrUpTDaQ28jzyA8qgUliPfFeX20etWXh3wTD4i0+2t9BsLy1EdzBLuuSceXbebFgLFksm8o8nPYAkgjrK3p+P9fMJXUbrz/D+vkeu0UUUAFFFFABRRRQBzfhf/AJGLxn/2Go//AE32ddJXN+F/+Ri8Z/8AYaj/APTfZ10lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfw4/5JZ4U/7Atn/6ISukrm/hx/ySzwp/2BbP/wBEJXSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc34o/5GLwZ/2GpP/TfeV0lc34o/5GLwZ/2GpP8A033ldJQAUUUUAVtQ1C00qwlvdRnS3toRl5HPA7D6knAAHJJwKp6N4m0vXpZ4dPmlE9uFM1vc20ttMgb7rGOVVbacHBxg4PpWP44+bUvCUUn/AB7Sa5H5voSsMrID/wADVT9QKS8AT4yaS0I+eTRLtZ8D+FZoSmfxZsfU0R1f3/grhLT8H97sbes+ItM0HyF1GaQS3BIgt7eCSeaXHLFYo1Z2AyMkDAyM0618QaTe6G2s29/CdOVGd7h22LGFzu37sbSuCCDggg5rmNflvT8TtNbw3Bb3up2umyi6gvJzDClvI67W8xVdlcvFwAjAgNnGAa465uLxPDsemtaodWvPGSJqtq7bYBI375FDDO6IhYeerc5AJ2hLW3n/APJW/r7gen9eV/6+89S0jxRpWtmT7DJcL5aCQ/arOa23p/fXzUXev+0uRyPUVX0/xtoGqalDZWd5I0tzu+zPJayxxXW0ZPlSsoSXjJ+RjwCelYl9Lrt9eX3gvX7mydtY0m4ez1HT7d4PLxtR1eNnfkeYpDBueRgVj+ILvXjovhfT7vw/Jps9pq+nxtObmKSOQrIFYQbGLkbNxO9UwuapayS6O34uz+78QekX8/wV/wAfwO21DxlomlXxtb+4niKuqPP9jmNvGxxgPOE8tDyOGYdRW5XFfEdtYk8M6nbDTraXQntm+3XEdwWulhwfN8uEoEJ25wTJ77TjB62wmt7nTbaeybfbSxK8Lc/MhAKnn2xSWqB6MsUUUUAFc38OP+SWeFP+wLZ/+iErpK5v4cf8ks8Kf9gWz/8ARCUAHgP/AJF26/7DWq/+nC4rpK5rwENvhu5AzxrOqjk5/wCYhcV0tABRRRQAUUUUAFFFFABRRRQAVzfgP/kXbr/sNar/AOnC4rpK5vwH/wAi7df9hrVf/ThcUAdJRRRQAUUUUAFY/iXxPY+FtPS6vorq4eaTyre2s7dppZ5ME7VA9geSQBjkitiorn/j0m/3G/lUzbUW0VGzepneFdeHifwpp2trbm2W+gWYQl9xQHtnAzWtXIfCj/kkvhv/AK8I/wCVdJqcepS2ZXRru1tLncMSXdq06Y7jYsiHPvu/CtJq0mkQtUTW91b3aM9rPHOqO0bNG4YK6nDKcdwQQR2IqWuC+HFv4hS3vXvNU0yWyGr34lhi02SORn+0SZIczsFG7nBU4HGT1rrtcutQstCu7jRdP/tK/jiJt7TzVj81+wLMQAPXnpUvRXKt7zXnYyLzxnDbfELTvCsFo08l1FI89yHwtuQhZFxj5mYKxxkYGD3FdNXkVvNqWmeL/B8V34Y1n7bJcXct3czyWe66meHDyAJcNgKO3ZVAXOAK9doJTuwooooGFFFFAHN/Ef8A5JZ4r/7At5/6Ieukrm/iP/ySzxX/ANgW8/8ARD10lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc34X/5GLxn/ANhqP/032ddJXCaZ4ZsdZ8W+MLi8n1SN11aJALPVrq1TH2C0PKRSKpPPUjPQZ4Fa/wDwgekf8/niD/wo9Q/+P0AdJRXN/wDCB6R/z+eIP/Cj1D/4/R/wgekf8/niD/wo9Q/+P0AdJRXN/wDCB6R/z+eIP/Cj1D/4/R/wgekf8/niD/wo9Q/+P0Ab13aQX9lPZ3kSzW9xG0UsbjIdWGCD7EGubg8A2q/Yob3WNW1DT7CRJbXT7qaMxRshyhJVBJJtIBAkdhkA9qm/4QPSP+fzxB/4Ueof/H6P+ED0j/n88Qf+FHqH/wAfoWjuD1VjpKK5v/hA9I/5/PEH/hR6h/8AH6P+ED0j/n88Qf8AhR6h/wDH6AOkorm/+ED0j/n88Qf+FHqH/wAfo/4QPSP+fzxB/wCFHqH/AMfoA6Siub/4QPSP+fzxB/4Ueof/AB+j/hA9I/5/PEH/AIUeof8Ax+gA8L/8jF4z/wCw1H/6b7OukrkvA9hDpmqeLrS2e4eKPWk2tc3MlxIc2FoeZJGZj17k4HHQV1tABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfw4/5JZ4U/wCwLZ/+iErpK5v4cf8AJLPCn/YFs/8A0QldJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfij/AJGLwZ/2GpP/AE33ldJXJeOLCHU9U8I2ly9wkUmtPua2uZLeQYsLs8SRsrDp2IyOOhqz/wAIHpH/AD+eIP8Awo9Q/wDj9AHSUVzf/CB6R/z+eIP/AAo9Q/8Aj9H/AAgekf8AP54g/wDCj1D/AOP0Aamt6La6/pbWV6ZEXekscsL7ZIZEYMjqezAgH07EEEiqFn4SitlvpbjVdSvNRvbf7M+pTSIs8cfOBH5aKiYLE5C5JwTnAqL/AIQPSP8An88Qf+FHqH/x+j/hA9I/5/PEH/hR6h/8fpWQBceDIZJLK6tNX1Sy1K0tFs/7RikjeaeIc4lEiMjnOTkrkEnGMmiPwJo66HdadN9puGu7gXc97LMTcPcDBWbeMbWXauNoAG0ADHFH/CB6R/z+eIP/AAo9Q/8Aj9H/AAgekf8AP54g/wDCj1D/AOP0/wCv1/PX1Fb+v68ixpnhaKxvpr+91K/1W/lh+z/a7x0V44s52IIkRV55JC5JAyTgYbZeFI4NUg1DUdU1DV57Td9k+3NHtttw2kqI0QFtpI3PubBIzycw/wDCB6R/z+eIP/Cj1D/4/R/wgekf8/niD/wo9Q/+P0DF1TweNXe4ivde1c6Zck+fpiyRCGRT95S/l+aFP90SAY46cV0MUUcEKRQosccahURRgKBwAB6Vzv8Awgekf8/niD/wo9Q/+P0f8IHpH/P54g/8KPUP/j9GysG50lFc3/wgekf8/niD/wAKPUP/AI/R/wAIHpH/AD+eIP8Awo9Q/wDj9AHSVzfw4/5JZ4U/7Atn/wCiEo/4QPSP+fzxB/4Ueof/AB+ovh1bo3wt8KkmTnRrM8SsP+WKe9AEvgP/AJF26/7DWq/+nC4rpK5vwH/yLt1/2GtV/wDThcV0lABRRRQAUUUUAFFFFABRRRQAVzfgP/kXbr/sNar/AOnC4rpK5vwH/wAi7df9hrVf/ThcUAdJRRRQAUUUUAFBAZSGGQeCD3oooAhtLS2sLSK1sbeK2t4V2xwwoERB6BRwBU1FFABRRRQBFJaW81zDcTW8Uk1vuMMrIC0e4YO09RkcHFS0UUAFFFFABRRRQBzfxH/5JZ4r/wCwLef+iHrpK5v4j/8AJLPFf/YFvP8A0Q9dJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHN+F/8AkYvGf/Yaj/8ATfZ10lc34X/5GLxn/wBhqP8A9N9nXSUAFFFFABRRRQB578T5/FNlbwXml6vDp+kx3VmkkcEZ+03DPcKjKXJwiYYfdGTyCcddDx94g/s6fSNHF9Lp41SaTzri3UtOsMa5ZYlUFi7MyINoJG4kc4q38QdIvtc8Kiz0uDz5/t1pLs3qvypcRuxyxA4VSfwpvivRryXXtC8RaXai+uNGeYPZ7lV5opU2t5bMQocEKRkgEZGRmktte/6L9Rt9fL/Mm8HXGjTWt2mhajqNykUoWa31OW4ee3fHQi4/erkYOG47jqc9HXL+HdOv5fFOreI9SsTphvoILaKzeRHkCRFzvkKEruJkIADNgAc84HUVTJQUUUUhhRRRQBzfhf8A5GLxn/2Go/8A032ddJXN+F/+Ri8Z/wDYaj/9N9nXSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHN/Dj/klnhT/ALAtn/6ISukrm/hx/wAks8Kf9gWz/wDRCV0lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHN+KP8AkYvBn/Yak/8ATfeV0lc34o/5GLwZ/wBhqT/033ldJQAUUUUAc14z1C6gi0nTNPne2m1jUEs2uI8b4o9jySFSejbYyAexbPaqWnRTeHPiJDosF9e3Omajp0lzHFe3Uly0M0TorbZJGZ8Msg4JIBXjGTWj4w0m81Cz0+80mNZr/Sr6O9hhZ9gmADI6bjwCUdwM8ZxnjmqEFvrOoeJJfE9zosto1jpsltYabcXEXnTSOwdyzIzogPlxqDuJ5YkDuouzu/P7uXT8fxCSv+H33/y/AreN9QgtvE2j23iHV5tH8OzQTmS4jvGtFkuQU8uN51Ksg2+YQAwDEYOcAFfCNqfFHhBxqWoaldWCX839m3kV9NbTT2ysVjZpImVnHXBP3gFY5PNOubfXYPFlj4ol0GS/EmlLbSafBcQmawmLbn2NIyIwOQrEMD8gwCDxJ4d0vWdH0TxHepp0Vtdahcy3tjpUUqnyWMSqFLcIGd1LHB2gseTyaNou/RP8/wAXbZ9tA3kreX5fh5+epiWDrokvi3xTY3mqzaZo1tLbWtrd6pc3Uc8sSl5ZMSyN/FiMYxjY/rVi+tNQ8M6ZofiE6xqNxezXlrFqiTXTyQTrO6xsFhJ2R7WcFdgB+XBzk539O8Jxp8Mo/C94xzNpxtrmTqzSOhEjn1JZmbPqayBYeI9f0/RtE1nR2sU0+5t57++a4jeK58ghlEIVi53Oqk71TAz1PFUtJ27W+67v9/8AwwnZxv3v+St8/wBdSLx5Pp9rJcjTfEl3H4udVOm6dDqb5aT+BTaq2xkJB3MyHAySwxkegR7/ACl83bv2jdt6Z74rj/GA1fXtH1Lw7H4Vkn+2RvDFfTXEH2WPIO2Q/P5oK8HAjJyOD/FXVafbyWem21tPO1zJDCkbzP8AekIABY+5xmkvh/r+v8xvcsUUUUAFc38OP+SWeFP+wLZ/+iErpK5v4cf8ks8Kf9gWz/8ARCUAJ4Cz/wAI3c7gAf7Z1XIBz/zELiulrm/Af/Iu3X/Ya1X/ANOFxXSUAFFFFABRRRQAUUUUAFFFFABXn/hO78VRaXfJpWjaPc2g1rVPLludXlhkb/T585RbZwOcj7xyOeOg9Arm/Af/ACLt1/2GtV/9OFxQAfbvG/8A0L3h/wD8H0//AMh0fbvG/wD0L3h//wAH0/8A8h10lFAHN/bvG/8A0L3h/wD8H0//AMh0fbvG/wD0L3h//wAH0/8A8h10lFAHN/bvG/8A0L3h/wD8H0//AMh0fbvG/wD0L3h//wAH0/8A8h10lFAHN/bvG/8A0L3h/wD8H0//AMh0fbvG/wD0L3h//wAH0/8A8h10lFAHN/bvG/8A0L3h/wD8H0//AMh0fbvG/wD0L3h//wAH0/8A8h10lFAHN/bvG/8A0L3h/wD8H0//AMh0fbvG/wD0L3h//wAH0/8A8h10lFAHN/bvG/8A0L3h/wD8H0//AMh0fbvG/wD0L3h//wAH0/8A8h10lFAHN/bvG/8A0L3h/wD8H0//AMh0fbvG/wD0L3h//wAH0/8A8h10lFAHnfj688Yt8NvEq3mhaHFbnSboSyRa1M7qvktkqptVDEDoCRn1HWvRK5v4j/8AJLPFf/YFvP8A0Q9dJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHCaZc+I4fFvjBdD0rS7y3/taItJeanJbuG+wWmQFWCQEYxzkdTxxk6/27xv/wBC94f/APB9P/8AIdHhf/kYvGf/AGGo/wD032ddJQBzf27xv/0L3h//AMH0/wD8h0fbvG//AEL3h/8A8H0//wAh10lFAHN/bvG//QveH/8AwfT/APyHR9u8b/8AQveH/wDwfT//ACHXSUUAc39u8b/9C94f/wDB9P8A/IdH27xv/wBC94f/APB9P/8AIddDNKkEDzSttjjUszHsAMk1x9h47vZ10e+v9C+yaNrcqRWVwLvzJ1MgzH50WwBAwH8LvgkZxzgWrt/WuwPRXZf+3eN/+he8P/8Ag+n/APkOj7d43/6F7w//AOD6f/5DrpKKAOb+3eN/+he8P/8Ag+n/APkOj7d43/6F7w//AOD6f/5DrpKKAOb+3eN/+he8P/8Ag+n/APkOj7d43/6F7w//AOD6f/5DrpKKAOS8DyX0uqeLn1W3t7a7OtJ5kVtcNNGv+gWmMOyITxg/dGDxz1PW1zfhf/kYvGf/AGGo/wD032ddJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc38OP+SWeFP+wLZ/+iErpK5v4cf8ks8Kf9gWz/8ARCV0lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHJeOJL6LVPCL6Vb29zdjWn8uK5uGhjb/QLvOXVHI4yfunJ446iz9u8b/8AQveH/wDwfT//ACHR4o/5GLwZ/wBhqT/033ldJQBzf27xv/0L3h//AMH0/wD8h0fbvG//AEL3h/8A8H0//wAh10lFAHN/bvG//QveH/8AwfT/APyHR9u8b/8AQveH/wDwfT//ACHWh4g1yPQdPSdoXuZ55kt7W2jIDTSucKuTwB1JJ6AE9qpaP4jvbjxBLoev6ZFp+oLbC7i+zXRuIZot20lXKIQytgEFR94EE9ha7f11B6bjPt3jf/oXvD//AIPp/wD5Do+3eN/+he8P/wDg+n/+Q6l1vxDdWWs2ei6Lp0eoandQyXG2e58iGKJCoLO4V2yS4AAU55zgDNQaf4l1TW9Fkn0bSLb+0bW7e0vLO+vmhWJ0+9tkSJ945Ug7RkHnB4o3/r5fmH9fqO+3eN/+he8P/wDg+n/+Q6Pt3jf/AKF7w/8A+D6f/wCQ6h0bxNrd54rvdH1XRrC2jsbZZ57uz1J7hUdydsZDQR/MVBbjOBj1FR+F/iFY+LfEl7pul2N4ltbWsdzHeXMTQi5V2ZcojANt+U/McZOcDHJN3b+v60Do3/X9alr7d43/AOhe8P8A/g+n/wDkOj7d43/6F7w//wCD6f8A+Q6b458Zw+CtES8No19cSyqkVqj7NwyN7FsHCquTnHXA6kV01AHN/bvG/wD0L3h//wAH0/8A8h0fbvG//QveH/8AwfT/APyHXSUUAc39u8b/APQveH//AAfT/wDyHUXw6af/AIVb4V2xxkf2NZ4JkI/5Yp/s11Nc38OP+SWeFP8AsC2f/ohKADwH/wAi7df9hrVf/ThcV0lc14CIbw3clSCDrOqkEd/+JhcV0tABRRRQAUUUUAFFFFABRRRQAVzfgP8A5F26/wCw1qv/AKcLiukrm/Af/Iu3X/Ya1X/04XFAHSUUUUAFFFFABRRWN4nvNetNMU+F9Ptbu8kfaXvJzHFbrtJ8xgBufBAG0YJz1FJuyuNK7sbNFc78P9WvNd+Hui6pqkolvLu0SWZwgUMx68DgV0VU1Z2JWqCiqGkavb61bTz2qSIsF1NasJAAS8UjRsRgnjKnHt6VdlkEULyN0RSx/Cpbsrsq2th1FedfDXWm8T6Zp2oS+PpNT1BrcT3mlQvZFIiw+6ypCJFAJHVs5HJNei1TTW4gooopAFFFFAHN/Ef/AJJZ4r/7At5/6Ieukrm/iP8A8ks8V/8AYFvP/RD10lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc34X/5GLxn/wBhqP8A9N9nXSVwmmeLPDmg+LfGFrrmv6Xptw+rRSLFeXscLspsLQBgGIOMgjPsa1/+Fj+CP+hy8P8A/g0g/wDiqAOkorm/+Fj+CP8AocvD/wD4NIP/AIqj/hY/gj/ocvD/AP4NIP8A4qgDpKK5v/hY/gj/AKHLw/8A+DSD/wCKo/4WP4I/6HLw/wD+DSD/AOKoA1Nfvn0vw3qV/HatePa2ssy26jJlKqTtx74xXmEdgug+HvBerReIW1a2+22y2mktsNv++Oz/AEfaPMJiV2Kh2kACnpwR3f8AwsfwR/0OXh//AMGkH/xVZlp4i+FWn6nJqVhrHg61vpc+ZdQ3Vqkr565cHJ/OiOkr+n4f5/gD1jb1/H+vmdvRXN/8LH8Ef9Dl4f8A/BpB/wDFUf8ACx/BH/Q5eH//AAaQf/FUAdJRXN/8LH8Ef9Dl4f8A/BpB/wDFUf8ACx/BH/Q5eH//AAaQf/FUAdJRXN/8LH8Ef9Dl4f8A/BpB/wDFUf8ACx/BH/Q5eH//AAaQf/FUAHhf/kYvGf8A2Go//TfZ10lcl4H1Kx1fVPF19pV5b31pLrSeXcW0qyRviwtAcMpIOCCPqK62gAooooAKKKKACiiigAooooAKKKKACiiigAooooA5v4cf8ks8Kf8AYFs//RCV0lc38OP+SWeFP+wLZ/8AohK6SgAooooAKKKKACiiigAooooAKKKKACiiigDm/FH/ACMXgz/sNSf+m+8rpK5LxxqVjpGqeEb7Vby3sbSLWn8y4uZVjjTNhdgZZiAMkgfU1Z/4WP4I/wChy8P/APg0g/8AiqAOkorm/wDhY/gj/ocvD/8A4NIP/iqP+Fj+CP8AocvD/wD4NIP/AIqgCr48ItrjwzqU5C2ljrUbXDscKgkjkiViewDyJz71He3EEnxatZhNGkWk6JcPeylwFiEskZQMe2RE7c9lzVqfx/4CureS3uvFvhyaGVSkkcmpQMrqeoILYIqnZeKfhhpumSadp2u+ErSxl3b7WC8tkifcMNlAcHI68c0ldfj+KsN6/gvxuVNXdPEXxL0u1sNVfS2h0pry11KyMbSXiSNtaNC4aNkG1GOVY5KEEdTJ4Av4NM0PxDBLcpd2+j6jOJNSB5u/lWV3c5ILguytjjK8BR8olvfEvwt1LTodP1HWvCF3ZQACK2nurV44wBgbVJwMDjirC+NPhymlnTU8S+F1sDGYjai/txFsIwV2bsYIPTGKeyaXn+d/+B+It2r+X5W/r7if4f2kqeFY9TvU23+tSHUroHqrSgFU/wCAIET/AIDVOy/5LfrH/YCtP/R01XU+IngWONUj8YeHkRQAqrqcAAHoPmqJfHXw+W+e9XxT4ZF1JGInnGo2/mMgJIUtuyQCSce5pu3Mmtl/k0ha8rT3f+aZwnjS515/DfiTUte8JapHcTBbe2kW4s3htbZZVKgYn3FnIDMdvXaOiA17BaTyXNnFNNay2kjqC0ExQvGfQlGZc/Qke9c3dePPh/fWr2174q8NXMEnDxTajburc55BbB5qb/hY/gj/AKHLw/8A+DSD/wCKpdLD63Okorm/+Fj+CP8AocvD/wD4NIP/AIqj/hY/gj/ocvD/AP4NIP8A4qgDpK5v4cf8ks8Kf9gWz/8ARCUf8LH8Ef8AQ5eH/wDwaQf/ABVRfDq5gX4W+FQ00YI0azBBccfuUoAl8B/8i7df9hrVf/ThcV0lc34D/wCRduv+w1qv/pwuK6SgAooooAKKKKACiiigAooooAK5vwH/AMi7df8AYa1X/wBOFxXSVzfgP/kXbr/sNar/AOnC4oA6SiiigAooooAKjuAWtZQoyShAA78VJRSkrpoadnc5b4Z2lzYfDHw/a31vLbXENkiyQzIUdDjoVPINb2p6ZBq1mbW6kuo4ywbdaXcts+R/txMrY9s4q3RVSfM7iWhxngfwSmgLcXFy2ppcf2hdyRJLq9xNG0TzOUYxmUoxKkHLDdnk812LtsjZgrNtBO1ep9hTqKXQOrZweq3C+LvEPh46RpOpRXGmX4uZ7680+W1FtEEYPGGkVd+/IXCbh3PQZ7yiijpYN3cKKKKACiiigDm/iP8A8ks8V/8AYFvP/RD10lc38R/+SWeK/wDsC3n/AKIeukoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDm/C//ACMXjP8A7DUf/pvs66Sub8L/APIxeM/+w1H/AOm+zrpKACiiigAooooAiuLmCzhM13PHBECAXlcKoJIAGT6kgfU0s88NrbyT3MqQwxqWeSRgqoB1JJ4Arzn4ueG7O50+2165lu5bi1vrGO3ga4byISbpAXEY43kMRuOeOmKu/EG6nn8UeFdDisBqMd3NPdPaO4SKZoUUoJWwcIGcOeDyi8E8Ulqvnb8mO2p2Gl6zpeuWhutE1K01G3DFDNaTrKgYdRlSRnkce9Xa53w7rkl9rWp6bqukxaZrFosTzCCbzo54m3eW6ybULDKuMFQQQfXNdFVMQUUUUgCiiigDm/C//IxeM/8AsNR/+m+zrpK5vwv/AMjF4z/7DUf/AKb7OukoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOb+HH/ACSzwp/2BbP/ANEJXSVzfw4/5JZ4U/7Atn/6ISukoAKKKKACiiigAooooAKKKKACiiigAooooA5vxR/yMXgz/sNSf+m+8rpK5vxR/wAjF4M/7DUn/pvvK6SgAooooAZLLHBC8s8ixxxqWd3OFUDkkk9BVTStb0rXbZrjRNTs9RgVtrS2dwsqg+hKkjNc/wCPP9IuPDOmzAG0v9ZjS5RvuyKkUkoQjuC0a8d8U24iSz+MthJbKFbUNGuFuQvG/wAmWLy2PrjzHAPvRHV/f+CuErr8/wAbHSanq+m6JZ/a9Z1C10+23BfOu51iTJ6DcxAzUN74k0PTdNh1HUdZ0+0sbggQ3U90iRSZGRtcnByATxXMeJp3tfibod3Z6dNrdzBYXKtYW+wS26uyYnDSMsYyUKYLAnPGcMKm+GWz+wtT/d/ZJm1a5km04gg2DMwbyiMAZwQ+V+UlyQSCCRaq/wDW9v6fTbcHo/67X/r79jc0vxd4b1y7NroniDStRuApcw2l7HK4UdTtViccjn3rSFzAbs2onjNwqCQw7xvCEkBsdcZBGfauV8HoNcvtV8WS8/2g5tdPcdUs4yQpX/fffJkdQU9BWL4Q8O2fhr4va1a2Ul1O0ujWs09zeTtNNPIZZQWd26nCgdgMcChbpd/8m/8Ahwezfb/NI7e48R6HaavHpV1rOnwajLjy7OS6RZnz0whO45+laVcH8SZseGNU0xtBuFsbuPddawqxmG1B+9MVRjMzIADkJjIHzAAkdxbMj2sTQy+dGyArJu3bxjg57565oWwPckooooAK5v4cf8ks8Kf9gWz/APRCV0lc38OP+SWeFP8AsC2f/ohKADwH/wAi7df9hrVf/ThcV0lef+EtA1K80q9nt/FusWEbazqeLe3isyiYv5xwZLdm5Izyx5JxgYFbn/CL6v8A9D34g/78af8A/ItAHSUVzf8Awi+r/wDQ9+IP+/Gn/wDyLR/wi+r/APQ9+IP+/Gn/APyLQB0lFc3/AMIvq/8A0PfiD/vxp/8A8i0f8Ivq/wD0PfiD/vxp/wD8i0AdJRXN/wDCL6v/AND34g/78af/APItH/CL6v8A9D34g/78af8A/ItAHSUVzf8Awi+r/wDQ9+IP+/Gn/wDyLR/wi+r/APQ9+IP+/Gn/APyLQB0lc34D/wCRduv+w1qv/pwuKP8AhF9X/wCh78Qf9+NP/wDkWuf8F+HNUm0G5aPxprkAGrakpSOGxIJF9OC3zWxOWILHtknAAwAAeiUVzf8Awi+r/wDQ9+IP+/Gn/wDyLR/wi+r/APQ9+IP+/Gn/APyLQB0lFc3/AMIvq/8A0PfiD/vxp/8A8i0f8Ivq/wD0PfiD/vxp/wD8i0AdJRXN/wDCL6v/AND34g/78af/APItH/CL6v8A9D34g/78af8A/ItAHSUVzf8Awi+r/wDQ9+IP+/Gn/wDyLR/wi+r/APQ9+IP+/Gn/APyLQB0lFc3/AMIvq/8A0PfiD/vxp/8A8i0f8Ivq/wD0PfiD/vxp/wD8i0AdJRXN/wDCL6v/AND34g/78af/APItH/CL6v8A9D34g/78af8A/ItAHSUVzf8Awi+r/wDQ9+IP+/Gn/wDyLR/wi+r/APQ9+IP+/Gn/APyLQB0lFc3/AMIvq/8A0PfiD/vxp/8A8i0f8Ivq/wD0PfiD/vxp/wD8i0AHxH/5JZ4r/wCwLef+iHrpK878feHNUg+G3iWWXxprlykek3TNDLDYhJAIWJVttsGwehwQfQiug/4RfV/+h78Qf9+NP/8AkWgDpKK5v/hF9X/6HvxB/wB+NP8A/kWj/hF9X/6HvxB/340//wCRaAOkorm/+EX1f/oe/EH/AH40/wD+RaP+EX1f/oe/EH/fjT//AJFoA6Siub/4RfV/+h78Qf8AfjT/AP5Fo/4RfV/+h78Qf9+NP/8AkWgDpKK5v/hF9X/6HvxB/wB+NP8A/kWj/hF9X/6HvxB/340//wCRaAOkorm/+EX1f/oe/EH/AH40/wD+RaP+EX1f/oe/EH/fjT//AJFoA6Siub/4RfV/+h78Qf8AfjT/AP5Fo/4RfV/+h78Qf9+NP/8AkWgDpKK5v/hF9X/6HvxB/wB+NP8A/kWj/hF9X/6HvxB/340//wCRaAOkorm/+EX1f/oe/EH/AH40/wD+RaP+EX1f/oe/EH/fjT//AJFoAPC//IxeM/8AsNR/+m+zrpK878OeHNUk17xYqeNNciMerRqzpDY5lP2G1O5s2xGcEL8uBhRxnJPQf8Ivq/8A0PfiD/vxp/8A8i0AdJRXN/8ACL6v/wBD34g/78af/wDItH/CL6v/AND34g/78af/APItAHSUVzf/AAi+r/8AQ9+IP+/Gn/8AyLR/wi+r/wDQ9+IP+/Gn/wDyLQBa8V+Hv+En0Mad9p+y/wCkwXHmeXv/ANVKsmMZHXbjPbPejxD4eOsS2F7ZXX2HVNNlaW0uTH5ijcpV0dMjcjKeQCDwCCMVV/4RfV/+h78Qf9+NP/8AkWj/AIRfV/8Aoe/EH/fjT/8A5FoAsaF4fm07UL3VNVvlv9UvlSOWaODyY0jTO1I03MVGWY8sxJJ56Ablc3/wi+r/APQ9+IP+/Gn/APyLR/wi+r/9D34g/wC/Gn//ACLQB0lFc3/wi+r/APQ9+IP+/Gn/APyLR/wi+r/9D34g/wC/Gn//ACLQB0lFc3/wi+r/APQ9+IP+/Gn/APyLR/wi+r/9D34g/wC/Gn//ACLQAeF/+Ri8Z/8AYaj/APTfZ10led+HPDmqSa94sVPGmuRGPVo1Z0hscyn7Danc2bYjOCF+XAwo4zknoP8AhF9X/wCh78Qf9+NP/wDkWgDpKK5v/hF9X/6HvxB/340//wCRaP8AhF9X/wCh78Qf9+NP/wDkWgDpKK5v/hF9X/6HvxB/340//wCRaP8AhF9X/wCh78Qf9+NP/wDkWgDpKK5v/hF9X/6HvxB/340//wCRaP8AhF9X/wCh78Qf9+NP/wDkWgDpKK5v/hF9X/6HvxB/340//wCRaP8AhF9X/wCh78Qf9+NP/wDkWgDpKK5v/hF9X/6HvxB/340//wCRaP8AhF9X/wCh78Qf9+NP/wDkWgDpKK5v/hF9X/6HvxB/340//wCRaP8AhF9X/wCh78Qf9+NP/wDkWgDpKK5v/hF9X/6HvxB/340//wCRaP8AhF9X/wCh78Qf9+NP/wDkWgA+HH/JLPCn/YFs/wD0QldJXN/Dj/klnhT/ALAtn/6ISukoAyfEGu/2EunH7P5/27UIbL7+3Z5hI3dDnGOnGfWtauS8f/6vw5/2MFn/AOhGuUN5rviO/wDEE7ab4olltL+ey099J1GC2gthH8qkxtcIZGJ+c+YjDDADjqk9H6v7ko/qwe69F97cv8j1isnVNc/s3XdF037P5v8Aas0sXmb8eVsiaTOMc5246jrXJXd3qmurpujXun6gdch02K61GG21htPggd8rzLCS7ncj4A3Lgc9q5SfxPrUPg/wRrTW7a1qltcX6Yjff5vlxTIHJABcAKCSq7mwcLk4qnpe4t/68rnt1Fea3RutJ8FaV4ssfEt3rK292l/qNwk7GG6tpPkmCxAlVRFO5VA42c8kk9H4dvJtc8T6zq0d1I2mQMun2cSyfu3ZOZpcA4J3nZk8jyz60W1t2/wCB+rsF9L/1/VtTp6K5P4oXl1YfDLWrnTrmW0uY4VMc0LlWQ71GQQQaxfFbX+k6poWiaaNcvoNWknnv2tb8C5l8tF/do8sqLErFtxEZU4U7QMmp62Gdh4p13/hGvDN5q/2f7T9mVT5W/ZuywXrg46+la1eR66mt2/gXxZBf6fq1npHlW72I1e8iuZ1cyASJvSWRivCEb2JyzdsV1/h69uZfiP4wtbi5leC3+xGCF5CVjDRNuKg8DJHOOpFPqK+p1tFct8Nr6bUvh/p93c3Ul3JK0x86SQuXHnOB8x6jAGPaupoGc34o/wCRi8Gf9hqT/wBN95XSVyXji1mvdU8I29tf3GnyvrT7bm2WMyJiwuzwJFZecY5U8Hseas/8Ivq//Q9+IP8Avxp//wAi0AdJRXN/8Ivq/wD0PfiD/vxp/wD8i0f8Ivq//Q9+IP8Avxp//wAi0AX/ABFoS6/pqQLcNaXNvOlza3KKGMMqHKtg9R1BHcEjI61n2nhrUhd3mqajrMU2tTWZs7e5t7PyobRck5WJncklsFtzkHaowO6/8Ivq/wD0PfiD/vxp/wD8i0f8Ivq//Q9+IP8Avxp//wAi0rf1+H5AQzeFNUTUrXWdO1yKPWlsUsrye5sfNhu1U7g5iV0KtuLEbWx8xBB4qbT/AApPYaLrUQ1V5dV1lpJZ79oQFSVoxGpWMHhVCrhcknHLEnNH/CL6v/0PfiD/AL8af/8AItH/AAi+r/8AQ9+IP+/Gn/8AyLTeqa7/AK6gtGn2NjR9Mh0XQ7HS7b/U2VvHBHxj5UUKP5VRg8PeT44vPEX2nd9psIrP7P5f3dju27dnnO/GMdutVf8AhF9X/wCh78Qf9+NP/wDkWj/hF9X/AOh78Qf9+NP/APkWm23Lme4kko8q2G614e13WY7vT38QQQ6ReK0csaaf/pQjYEMizeZsHBwD5ZIHfPNdDaWsNjZQWlqnlwQRrFGgP3VUYA/IVgf8Ivq//Q9+IP8Avxp//wAi0f8ACL6v/wBD34g/78af/wDItJaKw3qdJRXN/wDCL6v/AND34g/78af/APItH/CL6v8A9D34g/78af8A/ItAHSVzfw4/5JZ4U/7Atn/6ISj/AIRfV/8Aoe/EH/fjT/8A5FqL4dROfhb4VIuJB/xJrPgBeP3Ke1AEvgP/AJF26/7DWq/+nC4rpK5vwH/yLt1/2GtV/wDThcV0lABRRRQAUUUUAFFFFABRRRQAVzfgP/kXbr/sNar/AOnC4rpK5vwH/wAi7df9hrVf/ThcUAdJRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc38R/+SWeK/wDsC3n/AKIeukrm/iP/AMks8V/9gW8/9EPXSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfhf8A5GLxn/2Go/8A032ddJXN+F/+Ri8Z/wDYaj/9N9nXSUAFFFFABRRRQBHcSNDayyRxmVkQsqL1YgdBXnGk+ItdNl4T1qXXU1F/ENwkVxpQgjWKEMjM/klV8wGLb829m6NnacY7zXY9Ql8O6jHojpHqLW0gtXfosu07CfxxXmdtpVns0MeGPC2o6d4oiurdr6/msZIGCbgbjz7lgFuAy7hgM+SQR0yCPxW9P1v/AMHsEvh+/wD4H/A7nrdFFFABRRRQAUUUUAc34X/5GLxn/wBhqP8A9N9nXSVzfhf/AJGLxn/2Go//AE32ddJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc38OP+SWeFP+wLZ/8AohK6Sub+HH/JLPCn/YFs/wD0QldJQBU1DS7PVBbC/h80WtwlzD8xXbIhyrcEZx6His2+8GaJf6pLqEkN1Bcz7fPazv57YT4GB5ixOok44+YHjjpW7RQBi6j4Q0TVLmGe5tZElhiEAa2uZbfdEORG/lsu9Ovytkcnjk0tj4S0PTIdNisLBYI9Lkkls0R2xC0m4PgZ5B3tweBnjGBWzRQByup6GujaPqVp4V0Np5dZeTzU89RbRSOuGldHfAU5ywjUlj2Oc1astIu/CvhHT9I8L2dretZosW29u3twwwdzlljkJYtzjHc810FFG34fhsHX7/xOdNjqfiOxu9L8Y6LpkWnTxgMtnqkszOcg4OYYio4zkN+FaWsaDpuvWcdtqlv5qRSCWJ0kaOSFx0ZJEIZG5IypB5NaFFAGKPCOjf2Nc6XLBcXFtd4883N5NNJJg5AMruXwCOBuwPxpdQ8J6PqmrLqd3byi7EYieSC5lhE0YJISRUYCReT8rgjk+tbNFHW4FPSdJsdC0uHTtKgFvaQ7vLiDEhcsWPJJPUmrlFFAHN+KP+Ri8Gf9hqT/ANN95XSVzfij/kYvBn/Yak/9N95XSUAFFFFAGB4t1i70210+00tkS+1W9SyglddwhyGZ5NvfaiMQOmcZ4qjpd3quj+OF8P6pqkurW15YPeWtzcxRpMjxuqyIfKREYYkQj5QRz17TeNrK6kg0nVbC3kupdH1FLt7eEZeSIq0cgUd2CyFgOp24HJqhHdS6t4vPieLTdSGm6TpU0USTWbwz3UsjKzKkUgV+FiUDIAJfjODSi0nr5/dy6fiElfby++/+Rb8RX+ozeMNJ8P2Wpvo8F5az3D3kUUbyyPGUAij8xWQcOzHKk4XjHJrnb7xlqlv8MdQv5tWhgntdXXTYtYVI1SWL7SkbTYYFAdpcE4K5UnAHAs68sOqeI9P1LxV4fvdQ8NzaarwWcmnPdG1uixLedbIHO7YVAbaQpDDIzzc8HyTeH9D1S4n0vUrbRvt5bTLIQPLPBbFEBxCuXVN4chMZUH7o6Bpd/wCve/y/DUHa6t5fl/n+OhpaFfWcGjXusJ4xm8S6fFGzNMz2rpFsBLbTBGmTjqCT26Vk+Ftbn13ULW4uvGVtHqM6C4fw3CbZhBCy5CMMedvCkEtuAz/DjiqzaK/i3W/Et7p9lc6XY6poh01pru2e3e7mO/EhicBwEVtu5lBO7jgVSitJNR8NeGfDlp4fvbDVtJu7WSeV7R0hszEwMrrOQEk3gMBsZi3mcjrhx1evl+bu/wAn6ClZL7/yVv1Rd1jXdZlfxbfReIF0ZPDjYgszBEyTKIVkDzlwXKuzFR5bJwOpPTu9MuZrzSbO5uoDbTzQJJJCf+WbFQSv4E4rzO80uwa713/hNPC1/q+tS3cp067t9PkuCYP+WCwzqCLcqMZyyYbLZ5zXoXhiLU4PCelQ+IH8zVI7SJbttwbMoUbiSOCc96Ufhv6flr/wew5aS08/0t/wO5qUUUUAFc38OP8AklnhT/sC2f8A6ISukrm/hx/ySzwp/wBgWz/9EJQAngI58N3JII/4nOq8Ht/xMLiulrm/Af8AyLt1/wBhrVf/AE4XFdJQAUUUUAFFFFABRRRQAUUUUAFc34D/AORduv8AsNar/wCnC4rpK5vwH/yLt1/2GtV/9OFxQB0lFFFABRRRQAVieKtJvtZ0n7NY63daOgYtcSWar5sse0/IrkHy8nB3DnjjFbdMmQyQSIvVlIGfpUzTcXYqLszlPhUxb4T+G2YlmNihJJySfrXR6nq+m6JZm71nULXT7YMFM13MsSZPQbmIGazfBOiXPhvwPpGjXzxSXFlbLDI0JJQkehIBx+ArdrSesnYiOxyPg/4g6N4nM1sut6RLf/bbmKC2trtGeSKORgjhdxJyihsjg9RxXWsCVIU7SRwcZxWZoGjf2HZ3MHn+f597cXe7Zt2+bK0m3qem7Ge+OgrUqXaw/tP1Z5x4R0u+0j4uaxb6prd5rNy+jW0slxc7VAYyyjCRqAqL8o+Ud8k5Jr0euft9BuofiNf6+0kJtbnTYLREDHzA6SSMSRjGMOO/rxXQUL4UvX82D+Jv0/JBRRRQAUUUUAc38R/+SWeK/wDsC3n/AKIeukrm/iP/AMks8V/9gW8/9EPXSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBwmmazfad4t8YRWfhrVNVRtWiYzWclqqKfsFoNp82ZGzxngY5HPXGv/AMJRq/8A0IniD/v/AKf/APJVHhf/AJGLxn/2Go//AE32ddJQBzf/AAlGr/8AQieIP+/+n/8AyVR/wlGr/wDQieIP+/8Ap/8A8lV0lFAHN/8ACUav/wBCJ4g/7/6f/wDJVH/CUav/ANCJ4g/7/wCn/wDyVXSUUAc3/wAJRq//AEIniD/v/p//AMlUf8JRq/8A0IniD/v/AKf/APJVL4m8eeH/AAncW1rq18v226kjjhs4fnmbewUNt/hXP8RwOMdeK09b1u10HTxdXglffIsUMECb5J5G+6iL3J/IAEkgAmgdjL/4SjV/+hE8Qf8Af/T/AP5Ko/4SjV/+hE8Qf9/9P/8AkqtTSNUm1OGQ3Wk32lSxsAYb0RkkEcMGjd0I9t2RjkDjOhQI5v8A4SjV/wDoRPEH/f8A0/8A+SqP+Eo1f/oRPEH/AH/0/wD+Sq6SigDm/wDhKNX/AOhE8Qf9/wDT/wD5Ko/4SjV/+hE8Qf8Af/T/AP5KrpKKAOS8D3U17qni64ubC40+V9aTdbXLRtImLC0HJjZl5xnhjwex4rra5vwv/wAjF4z/AOw1H/6b7OukoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOb+HH/JLPCn/YFs//AEQldJXN/Dj/AJJZ4U/7Atn/AOiErpKACiiigAooooAKKKKACiiigAooooAKKKKAOS8cXU1lqnhG4trC41CVNafbbWzRrI+bC7HBkZV4znlhwO54qz/wlGr/APQieIP+/wDp/wD8lUeKP+Ri8Gf9hqT/ANN95XSUAc3/AMJRq/8A0IniD/v/AKf/APJVH/CUav8A9CJ4g/7/AOn/APyVXSUUAc3/AMJRq/8A0IniD/v/AKf/APJVH/CUav8A9CJ4g/7/AOn/APyVWtrGsWmh6a15fF9gZY0jjXc8rscKiqOrEkAD+lUdG8UQ6rqc+mXOn3ulalBEs5tL4R7miJwHVo3dGGRg4bIPUDIo3B6Ff/hKNX/6ETxB/wB/9P8A/kqj/hKNX/6ETxB/3/0//wCSqt614lh0e9tbCKyvNT1G7V5IbKyVN5RMb3LSMqKoLKPmYZJAGapyeO9MTwlPr6QXkiW84tZbMRqtxHOZFj8oqzBQwZhzuxg5BIwaA62F/wCEo1f/AKETxB/3/wBP/wDkqj/hKNX/AOhE8Qf9/wDT/wD5KrQ0vV7q/Exv9C1DR0iAIa+kt2D9c48qV8Yx3x1rJsPiBp9/PYE6fqNrYao4j0/UriJFgu2IJUKAxddwBK70XPbqMnWwr2Jv+Eo1f/oRPEH/AH/0/wD+SqP+Eo1f/oRPEH/f/T//AJKpdR8eeH9O8VWPhyS+WbVryURC1g+doflLZk7IMDjPJzwDzjo6N1cb0dmc3/wlGr/9CJ4g/wC/+n//ACVR/wAJRq//AEIniD/v/p//AMlV0lFAHN/8JRq//QieIP8Av/p//wAlVF8OpXHwt8KgW8h/4k1nyCvP7lPeuprm/hx/ySzwp/2BbP8A9EJQAeA/+Rduv+w1qv8A6cLiukrm/Af/ACLt1/2GtV/9OFxXSUAFFFFABRRRQAUUUUAFFFFABXN+A/8AkXbr/sNar/6cLiukrm/Af/Iu3X/Ya1X/ANOFxQB0lFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfxH/AOSWeK/+wLef+iHrpK5v4j/8ks8V/wDYFvP/AEQ9dJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHN+F/+Ri8Z/wDYaj/9N9nXSVzfhf8A5GLxn/2Go/8A032ddJQAUUUUAFFFFAHDfFW0t18JG7WCIXL3+nxtMEG9lF3GQpbrgEnj3qPxxHe3PxC8GWtpdiyjla9P2nyw7RyCEY2BgV37DLjcCBycHoew1bSLHXLH7HqkHnwebHLs3svzI4dTlSDwyg/hSato1jrlkLXU4DLGriRCrtG8bjo6OpDIw/vKQaS0+/8ARD/yMPw3fapB4r1jw9qmoNqsdnDBcwXskSJLtlLgxyCNVQkGPIIUZDcjjJ6qs/SNC07QoZY9NgZDM/mTSyyvLLM2MbnkclnOABlieBitCqYgooopAFFFFAHN+F/+Ri8Z/wDYaj/9N9nXSVzfhf8A5GLxn/2Go/8A032ddJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc38OP8AklnhT/sC2f8A6ISukrm/hx/ySzwp/wBgWz/9EJXSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc34o/5GLwZ/wBhqT/033ldJXN+KP8AkYvBn/Yak/8ATfeV0lABRRRQByXjj5dS8JSyf8e0euR+b6AtDKqE/wDA2UfUii8+f4xaV5PWLRbo3BHZWmh2A/Uq+Poa6PU9Ms9Z06Ww1O3W4tpgA8bZ7HIII5BBAII5BAIqhaeEtGsrG9tY7aWRb+Iw3UtzcyzzTJgja0rsXIAZsDdxk4xmkrrX1/FWG9fwX3O5z+ui91D4oWVv4duYLDU7DTHluLm7haaKSCWTAj8oMhY74t24Ou3GOd2BR8PaCuv+HNc8O6rdzwalZ63515f2TJmafMdwkiB0KqMFBsIONuMt949Vc+C9CubWxgNrLD/Z8At7Wa1u5oJoogANgljYPt4GQW5xzUkXhPRrfRG0m1tGt7VpDKxgnkjlaQnJkMqsHLnu27J9aasv687/ANLvqJ6v+u1v68tDnJNbvfDep67pfiG+k1zTbXRm1QTyQolwiAsrxP5aqhB25UhVPDA5xmsFLHWdE8O+D7rXL60vNDs7y1EdjDGVmi8wiOAtMSRN5ZkXokecZycYPouleGtJ0aO5WytmZrv/AI+JbmZ7iWcAYAeSQszAAkAEkAHiqVn4D8O2F3b3FvYyH7I2+1hmu5pYLZuxihdzHGR2KqMdqcdHd+X4Nv8A4CfTfqKWqa9fxSX/AAfw6GR43tLeDxL4Plggijkn19WmdEAaQi2mALEdTgAc13NUr/SLHU7ixnvoPNksJ/tNs29l8uTay7uDzwzDByOau0loref6JfoN6u/l+r/zCiiigArm/hx/ySzwp/2BbP8A9EJXSVzfw4/5JZ4U/wCwLZ/+iEoATwEAvhu5CgADWdVAA7f8TC4rpa5vwH/yLt1/2GtV/wDThcV0lABRRRQAUUUUAFFFFABRRRQAV5/4T8FeFdX0u+vtV8NaPfXcutap5lxc2EUkj4v5wMsyknAAH0FegVzfgP8A5F26/wCw1qv/AKcLigA/4Vx4I/6E3w//AOCuD/4mj/hXHgj/AKE3w/8A+CuD/wCJrpKKAOb/AOFceCP+hN8P/wDgrg/+Jo/4Vx4I/wChN8P/APgrg/8Aia6SigDm/wDhXHgj/oTfD/8A4K4P/iaP+FceCP8AoTfD/wD4K4P/AImukooA5v8A4Vx4I/6E3w//AOCuD/4mj/hXHgj/AKE3w/8A+CuD/wCJrpKKAOb/AOFceCP+hN8P/wDgrg/+Jo/4Vx4I/wChN8P/APgrg/8Aia6SigDm/wDhXHgj/oTfD/8A4K4P/iaP+FceCP8AoTfD/wD4K4P/AImukooA5v8A4Vx4I/6E3w//AOCuD/4mj/hXHgj/AKE3w/8A+CuD/wCJrpKKAOb/AOFceCP+hN8P/wDgrg/+Jo/4Vx4I/wChN8P/APgrg/8Aia6SigDzvx94B8H2fw28S3Vn4T0OC4h0m6kili02FXjYQsQykLkEEZBFeiVzfxH/AOSWeK/+wLef+iHrpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA4TTPCfhzXvFvjC61zQNL1K4TVoo1lvLKOZ1UWFoQoLAnGSTj3Na/8AwrjwR/0Jvh//AMFcH/xNHhf/AJGLxn/2Go//AE32ddJQBzf/AArjwR/0Jvh//wAFcH/xNH/CuPBH/Qm+H/8AwVwf/E10lFAHN/8ACuPBH/Qm+H//AAVwf/E0f8K48Ef9Cb4f/wDBXB/8TXSUUAc3/wAK48Ef9Cb4f/8ABXB/8TR/wrjwR/0Jvh//AMFcH/xNb90XFnN5UixyeW213+6pxwT7V4x4cm0kt4LOm2txZeIprpV1HV5onRb8KjecDdMNt0JCMoFZ+xAXbwLV29Px/wAuoO6V/X8P60PSP+FceCP+hN8P/wDgrg/+Jo/4Vx4I/wChN8P/APgrg/8Aia6SigDm/wDhXHgj/oTfD/8A4K4P/iaP+FceCP8AoTfD/wD4K4P/AImukooA5v8A4Vx4I/6E3w//AOCuD/4mj/hXHgj/AKE3w/8A+CuD/wCJrpKKAOS8D6bY6Rqni6x0qzt7G0i1pPLt7aJY40zYWhOFUADJJP1NdbXN+F/+Ri8Z/wDYaj/9N9nXSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHN/Dj/klnhT/ALAtn/6ISukrm/hx/wAks8Kf9gWz/wDRCV0lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHJeONNsdX1TwjY6rZ299aS60/mW9zEskb4sLsjKsCDggH6irP8AwrjwR/0Jvh//AMFcH/xNHij/AJGLwZ/2GpP/AE33ldJQBzf/AArjwR/0Jvh//wAFcH/xNH/CuPBH/Qm+H/8AwVwf/E10lFAHN/8ACuPBH/Qm+H//AAVwf/E0f8K48Ef9Cb4f/wDBXB/8TUHjqaSUaHo6yPHDq+ppbXJRipaFY5JWTI5G7ywpx2JqlYaXZeFfiha6foNrFYadqmlzSyWVsgjhWaGSMCQIOASspBI64GelEdXb1/BXB3X9edjU/wCFceCP+hN8P/8Agrg/+Jo/4Vx4I/6E3w//AOCuD/4msPx02nnxpocXiS1fVNHktbnOmxW73eZwYysr2yBmkUKHAbaQpYdMg1iW1hda/wDCC+tNHs5dStJdZBt9NaWPzIbRLpGMDCRgFIVW/dseAwUgYwBar+u9v+D6A9H/AF2v/wAD1O3/AOFceCP+hN8P/wDgrg/+Jo/4Vx4I/wChN8P/APgrg/8AiaoeF4fCctxqei2nhG30C8aFTe6dNp8EZnhbcFYmItHKhO4cMcHIOM1k3HgnwtefEnTrDS/DWkWcWjINSu5rWxiiYyklYI9yqDjIdyM/wLng0+qX9f1/wwdH/X9f0zpf+FceCP8AoTfD/wD4K4P/AImj/hXHgj/oTfD/AP4K4P8A4mub8Y6VfwfEPwrqdzrl5PbTa0sUGnALHBAv2eQkkDmRiy53MeASAK9IpLVX8/0T/UHo7eX+f+Rzf/CuPBH/AEJvh/8A8FcH/wATR/wrjwR/0Jvh/wD8FcH/AMTXSUUAc3/wrjwR/wBCb4f/APBXB/8AE1F8OraBvhb4VLQxknRrMklBz+5Suprm/hx/ySzwp/2BbP8A9EJQAeA/+Rduv+w1qv8A6cLiukrmvAWf+EbudxBP9s6rkgY/5iFxXS0AFFFFABRRRQAUUUUAFFFFABXN+A/+Rduv+w1qv/pwuK6Sub8B/wDIu3X/AGGtV/8AThcUAdJRRRQAUUUUAFRXV3b2NpLdX08VtbwqXkmmcIiKOpJPAFS1k+IvD+k+ILGNNbsIb5LV/tEMcw3KsgUgMV6HqeuamTtFscVd2Lel6pZ61pVvqWlzi4s7lBJDKAQHU9DzzVuuQ+FH/JJfDf8A14R/yrpNTvZ7CzM1rpl1qcm4D7PaNErkeuZXRcD65q5LlbRK1RbprukUbSSMqIoLMzHAAHUk1xPgDxDqupRXcN/oeroh1O9H2y5ntnSECd8RnEzP8uAnyqVGODjmu3ZVdCrgMpGCCOCKT2H1a7GFYeNdB1LUoLG1u5BNcgm2M1rLCl0AMkxSOoWXjn5CeOelb1cNPeL478RaUuixeZo2jX32ufU2XEc0qKyLFBn7/LEs4+UAYBJPHc0dL/1/X/D9Q6hRRRQAUUUUAc38R/8Aklniv/sC3n/oh66Sub+I/wDySzxX/wBgW8/9EPXSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfhf/kYvGf/AGGo/wD032ddJXCaZbeI5vFvjBtD1XS7O3/taINHeaZJcOW+wWmSGWeMAYxxg9Dzzga/2Hxv/wBDD4f/APBDP/8AJlAHSUVzf2Hxv/0MPh//AMEM/wD8mUfYfG//AEMPh/8A8EM//wAmUAdJRXN/YfG//Qw+H/8AwQz/APyZR9h8b/8AQw+H/wDwQz//ACZQBra3paa3oF/pckskKXttJbtLGcMgdSuR7jNcnJ4b8Uarpul6Lqx0i2sNPntppLy0lkeW48h1dQsTIFiyUGTvfAzj1Gt9h8b/APQw+H//AAQz/wDyZR9h8b/9DD4f/wDBDP8A/JlC0d15fhsD1Vv613Okorm/sPjf/oYfD/8A4IZ//kyj7D43/wChh8P/APghn/8AkygDpKK5v7D43/6GHw//AOCGf/5Mo+w+N/8AoYfD/wD4IZ//AJMoA6Siub+w+N/+hh8P/wDghn/+TKPsPjf/AKGHw/8A+CGf/wCTKADwv/yMXjP/ALDUf/pvs66SuS8DpfRap4uTVbi3ubsa0nmS21u0Mbf6BaYwjO5HGB945PPHQdbQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc38OP+SWeFP+wLZ/8AohK6Sub+HH/JLPCn/YFs/wD0QldJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfij/kYvBn/Yak/wDTfeV0lcl44S+l1TwimlXFvbXZ1p/Llubdpo1/0C7zlFdCeMj7wweeehs/YfG//Qw+H/8AwQz/APyZQB0lFc39h8b/APQw+H//AAQz/wDyZR9h8b/9DD4f/wDBDP8A/JlAFnxVok+tafbNp8scOoafdx3lo8wJTzEyCrY5wysykjkbs84xVC20bXp9YufEGpLpsGqR2D2en2kM0k0ERZtzM8hRGbcyx5AUYC9Tnib7D43/AOhh8P8A/ghn/wDkyj7D43/6GHw//wCCGf8A+TKVv6+VvyD+vxv+ZTm0XxJb6/beI7P+zLvUZNNSyv7KaeSGDcrF98UgR2UbmYYKnI28gjmXR9E13RrPVr5W0+61fVL0XklsXeK3QbEjEavtZs7UGXK8n+EVP9h8b/8AQw+H/wDwQz//ACZR9h8b/wDQw+H/APwQz/8AyZT9P61v+Yf1+FvyDRtG1V/E1x4h8Q/Y4bprVbOC0spGlSGMOXYmRlUuzHH8KgBcc5Jqx4c0S40u61q7v3ie51PUXucxMSBEFWOJeQOQiDI6Ak4qv9h8b/8AQw+H/wDwQz//ACZR9h8b/wDQw+H/APwQz/8AyZQtNv61v+Yf1+FiTxNoN1rOqeHbm1khRNL1IXcwkYgsnlSJhcA5OXHXHGea6Cub+w+N/wDoYfD/AP4IZ/8A5Mo+w+N/+hh8P/8Aghn/APkyhaK39f1oG7v/AF/Wp0lFc39h8b/9DD4f/wDBDP8A/JlH2Hxv/wBDD4f/APBDP/8AJlAHSVzfw4/5JZ4U/wCwLZ/+iEo+w+N/+hh8P/8Aghn/APkyovh0s/8Awq3wrtkjA/sazwDGT/yxT/aoAl8B/wDIu3X/AGGtV/8AThcV0lc34D/5F26/7DWq/wDpwuK6SgAooooAKKKKACiiigAooooAK5vwH/yLt1/2GtV/9OFxXSVzfgP/AJF26/7DWq/+nC4oA6SiiigAooooAKbIgkjZG6MCDinUUmrqzAzvD2iW3hvw7Y6NYvLJb2UIhjaYguQPUgAZ/AVo0UVTd3cCrYabaaXDJFYxeUks8lw43FsySMXc8k9WJOOnpSarp8er6PeadNLLFHeQPA8kLbXQMpUlTg4PPHFW6KlpNWY02nc5nSPCF3osVlb23i3WXsrNUSO0eGyEZRQAEO23DYwMcEH3rpqKKptvcm1gooopDCiiigDm/iP/AMks8V/9gW8/9EPXSVzfxH/5JZ4r/wCwLef+iHrpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA5vwv/yMXjP/ALDUf/pvs66Sub8L/wDIxeM/+w1H/wCm+zrpKACiiigAooooA4rx1431PwxNBDpegTXSNNbrPqE5CW0KyzCPA53O/P3QABkEnsdnxLrlxpYsbLS4Yp9V1OcwWiTEiNcKWeR8c7VUE4HU4GRnNZHxW/5EYf8AYSsP/SqKqfxE060fxN4Y1XXV3aBaNcw6gXP7lBIi7Gm7eXuTBzx8wzxmktvn+i/4Yb/T/M6/SI9ZihkTXrmxupNwMc1lbvACMcgozvgg993OegxzoVwvgOKwj8Sa6/hMRr4XdIDbi2GLU3Pz+aYMfLtx5edvy7ge+a7qqZKCiiikMKKKKAOb8L/8jF4z/wCw1H/6b7Oukrm/C/8AyMXjP/sNR/8Apvs66SgAooooAKKKKACiiigAooooAKKKKACiiigAooooA5v4cf8AJLPCn/YFs/8A0QldJXN/Dj/klnhT/sC2f/ohK6SgAooooAKKKKACiiigAooooAKKKKACiiigDm/FH/IxeDP+w1J/6b7yukrm/FH/ACMXgz/sNSf+m+8rpKACiiigDG8T65JotjbCzhSe+v7pLO0jkYhDI2TuYjnaqqzHHJC471R0nWdYt/FjeHvEZsriWWzN7a3llC0CyKrhHRo2dyCpZDkMQQ3QY5i8eq1smha0VZrfSNUS4utqlikLRvEz4HOF8wMfQAntWeutabrPjtPEOn3kV1omiaRcefqFufNhLyOjFVdchiqwkkLkjcvrSi1fXz+7luvx6/IJLt5ffe35f5mxrus6qPE1h4e0E2cFzdWs13Jd3sTSpHHGyLtEashdiZB/EAoHfIFZ9v44uY/Ct3dX1jHJq1tqR0lIIHIiurneEQqTkqh3AnOSoDdcZOR4j1LRdW8W6Rd+Ir9tP8OHTftem6kLl7JZJpDhlM4KPGfL2kJuXduOQdvGA+nNc+DoxZJeT+GdH8TJcQTxqyyT2JT964IAaRRJLITJyWVSck/MWk9n8/8AwK3ysv8AMHbdf17t/nr/AJHqekL4hh8xvEFxpt0pQMgsLaSExt3X5nfeP9r5enTnjC8LeNdT8Q+MtQ0y+0GbRrWCxiurdLth9okDu67nVSQn3Pu8nuTzgZ/heLQv+Fhed8PfsY0Q6e41E6Zt+xtPvTysbPkMoXzM45wRntWjY/8AJcNX/wCwFaf+jpqf2o+d/wAE/wDIPsy8rfmv8xPFd/4t8P6Ve6nBrGivGrbbS0bRpWkld22xRb/tQBZmKrnaBznArq9O+2jTLb+1jA195S/aDbKVj8zHzbQSTjPTJrm9Y/4nHxJ0bSW5ttMt31Wdf70ufKgB9hmVvqi+ldbSXw/100/O/wCAP4v66/8AAt94UUUUAFc38OP+SWeFP+wLZ/8AohK6Sub+HH/JLPCn/YFs/wD0QlACeAju8N3JGedZ1U8jH/MQuK6Wub8B/wDIu3X/AGGtV/8AThcV0lABXHaqg8TePj4evjIdKsLFL24t1bat3JI7KivjlkURsSvQkjOQMV2Nc5reg6g2v2/iHw7PBHqMUBtp7e6LCG7hzuCsyglGVslWAbG5hg54XVX/AK0/zHumv63/AMjK8ZeHNG0H4X+KhoemWunJLpc++K0jEUbYjbnYuFzz1xmszwJd3XhiaXwHrMrzJFZm60O7k6z2mOYif78RIHupU4FdFq+m+IvEng3W9M1GDS7G4vrKS3gSC6knQMykbmkMaHHI4CH6mn+KfCsmveGoILS4W01ew2zafeYyIZlXHPcowyrDurGlK/K/Nf5/l/wOo9Pd+f6f1+PQ841DQ28R/Cj4Z6XFdyWU80sLQXUR+aGVbSV0cfRlU1sX/ie48R/DhYtXhFrrmma3YWeqW4GAsy3UXzL6o4IZT6H2rf07wZqNpoHgeymmtTL4fkR7sqzbXxbyRnZ8vPzOOuOM/SovHPgK71/WdP1XQbqG0uFuLcaik2Ql1bxTLKvQH94rL8p9GYE1s2vaX6c1/wAVr/X6E7pen+en9fqd3RRRWYBXn/hPxbp2maXfWlzbaw8setapua20S8uIzm/nPEkcTKevYnB46ivQK5vwH/yLt1/2GtV/9OFxQAf8J5pH/Pn4g/8ACc1D/wCMUf8ACeaR/wA+fiD/AMJzUP8A4xXSUUAc3/wnmkf8+fiD/wAJzUP/AIxR/wAJ5pH/AD5+IP8AwnNQ/wDjFdJRQBzf/CeaR/z5+IP/AAnNQ/8AjFH/AAnmkf8APn4g/wDCc1D/AOMV0lFAHN/8J5pH/Pn4g/8ACc1D/wCMUf8ACeaR/wA+fiD/AMJzUP8A4xXSUUAc3/wnmkf8+fiD/wAJzUP/AIxR/wAJ5pH/AD5+IP8AwnNQ/wDjFdJRQBzf/CeaR/z5+IP/AAnNQ/8AjFH/AAnmkf8APn4g/wDCc1D/AOMV0lFAHN/8J5pH/Pn4g/8ACc1D/wCMUf8ACeaR/wA+fiD/AMJzUP8A4xXSUUAc3/wnmkf8+fiD/wAJzUP/AIxR/wAJ5pH/AD5+IP8AwnNQ/wDjFdJRQB534+8aaXdfDbxLbxWuuK82k3SKZdAvo0BMLAbnaEKo9SSAOpNeiVzfxH/5JZ4r/wCwLef+iHrpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA4TTPEtjo3i3xhb3kGqSO2rRODZ6TdXSY+wWg5eKNlB46E56HHIrX/4TzSP+fPxB/wCE5qH/AMYo8L/8jF4z/wCw1H/6b7OukoA5v/hPNI/58/EH/hOah/8AGKP+E80j/nz8Qf8AhOah/wDGK6SigDm/+E80j/nz8Qf+E5qH/wAYo/4TzSP+fPxB/wCE5qH/AMYrpKKAOb/4TzSP+fPxB/4Tmof/ABij/hPNI/58/EH/AITmof8AxiukrAsPG/h7U9RisrK/LyTsy28rW8iQ3JXqIpmURykYJwjHofQ0ARf8J5pH/Pn4g/8ACc1D/wCMUf8ACeaR/wA+fiD/AMJzUP8A4xXSUUAc3/wnmkf8+fiD/wAJzUP/AIxR/wAJ5pH/AD5+IP8AwnNQ/wDjFdJRQBzf/CeaR/z5+IP/AAnNQ/8AjFH/AAnmkf8APn4g/wDCc1D/AOMV0lFAHJeB7+HU9U8XXdslwkUmtJtW5tpLeQYsLQcxyKrDp3AyOehrra5vwv8A8jF4z/7DUf8A6b7OukoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOb+HH/JLPCn/YFs/wD0QldJXN/Dj/klnhT/ALAtn/6ISukoAKKKKACiiigAooooAKKKKACiiigAooooA5Lxxfw6ZqnhG7uUuHij1p9y21tJcSHNhdjiONWY9ewOBz0FWf8AhPNI/wCfPxB/4Tmof/GKPFH/ACMXgz/sNSf+m+8rpKAOb/4TzSP+fPxB/wCE5qH/AMYo/wCE80j/AJ8/EH/hOah/8YrpKKAOb/4TzSP+fPxB/wCE5qH/AMYo/wCE80j/AJ8/EH/hOah/8Yrb1DULTSrCW91GdLe2hGXkc8DsPqScAAcknAqno3ibS9elnh0+aUT24UzW9zbS20yBvusY5VVtpwcHGDg+lAbFD/hPNI/58/EH/hOah/8AGKP+E80j/nz8Qf8AhOah/wDGK0dZ8RaZoPkLqM0gluCRBb28Ek80uOWKxRqzsBkZIGBkZqF/F2hp4ZPiD7cH00EKZY4ndgxcJs2KC+7cQu3GQeMUB1sVP+E80j/nz8Qf+E5qH/xij/hPNI/58/EH/hOah/8AGK0dJ8QWetNKLOHUIvKALfbdNuLQHPoZkXd07ZxVOw8b+HtT1GKysr8vJOzLbytbyJDcleoimZRHKRgnCMeh9DQFyL/hPNI/58/EH/hOah/8Yo/4TzSP+fPxB/4Tmof/ABitPXNe0zw3pbajrd0traK6RmQqW+ZmCqAFBJJJHQVo0Ac3/wAJ5pH/AD5+IP8AwnNQ/wDjFH/CeaR/z5+IP/Cc1D/4xXSUUAc3/wAJ5pH/AD5+IP8AwnNQ/wDjFRfDq4Rfhb4VBEnGjWY4iY/8sU9q6mub+HH/ACSzwp/2BbP/ANEJQAeA/wDkXbr/ALDWq/8ApwuK6Sub8B/8i7df9hrVf/ThcV0lABRRUNzeWtksZvLmG3EsixRmWQLvduFUZ6k9h1NAE1FQi9tTfNZC5hN2sYlNv5g8wISQG29cZBGemRWJceJYINQa6Or6INEjsXnd2ugJQ6yBd2c7fL6qT/ewKTaW4HQ0V5u/xKi17wn4e1fw7f20Mt5qtnBe28U0c7QJKx3Rvx8pIHoD6V3Ol69pGuCY6LqtlqIgbZKbS4SXy29G2k4P1qrPXydvy/zD+vz/AMi/RRRSAK5vwH/yLt1/2GtV/wDThcV0lc34D/5F26/7DWq/+nC4oA6SiiigAooooAKKKx/Eviex8Lael1fRXVw80nlW9tZ27TSzyYJ2qB7A8kgDHJFJuyuxpN7GxRWT4V14eJ/Cmna2tubZb6BZhCX3FAe2cDNa1U1Z2YgoqK3ure7RntZ451R2jZo3DBXU4ZTjuCCCOxFSMSqkhSxAyAO9IBaK5hPE+q2WvafY+IdFgsoNUkaG0ntr43BEgQuElUxrsJVW5UuMjGe9dPQAUUUUAFFFFAHN/Ef/AJJZ4r/7At5/6Ieukrm/iP8A8ks8V/8AYFvP/RD10lABRRRQAUUUUAFFFFABRWP4l8T2PhbT0ur6K6uHmk8q3trO3aaWeTBO1QPYHkkAY5Iqvo/i601HwBb+LL5PsFnJZ/bJVd93lIBk5IHPApX0b7Ds9PM6CisLRdW17UZo5dR8Px6fYzoXiY33mXCdwJYtgVcj+674PHqRu1TViU7hRRRSGFFFFABRRRQBzfhf/kYvGf8A2Go//TfZ10lc34X/AORi8Z/9hqP/ANN9nXSUAFFFFABRRRQBS1m6tLLQr661KUw2kNvI88gPKoFJYj3xXl9tHrVl4d8Ew+ItPtrfQbC8tRHcwS7rknHl23mxYCxZLJvKPJz2AJI9Xu7SC/sp7O8iWa3uI2iljcZDqwwQfYg1zcHgG1X7FDe6xq2oafYSJLa6fdTRmKNkOUJKoJJNpAIEjsMgHtRHSV35fg3/AEvxCWsbev4/1r+B1VFFFABRRRQAUUUUAc34X/5GLxn/ANhqP/032ddJXN+F/wDkYvGf/Yaj/wDTfZ10lABRRRQAUUUUAFFFZHiHxFBoENopt5ry8vpxbWdnBjfNIQSeSQFUKCzMeAAe+AQDXorlpfE+saPLDJ4p0S2s9PmlWH7ZY37XIgZjtUyq0UZVSSBuXcASM4HNdTQAUUUUAFFFFABRRRQBzfw4/wCSWeFP+wLZ/wDohK6Sub+HH/JLPCn/AGBbP/0QldJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfij/kYvBn/AGGpP/TfeV0lc34o/wCRi8Gf9hqT/wBN95XSUAFFFFAHJeOPm1LwlFJ/x7Sa5H5voSsMrID/AMDVT9QKS8AT4yaS0I+eTRLtZ8D+FZoSmfxZsfU1va3otrr+ltZXpkRd6SxywvtkhkRgyOp7MCAfTsQQSKoWfhKK2W+luNV1K81G9t/sz6lNIizxx84EfloqJgsTkLknBOcCktNfV/fGw3r+C+53MbX5b0/E7TW8NwW97qdrpsouoLycwwpbyOu1vMVXZXLxcAIwIDZxgGsrRtBufEfg/WtJe4j0zW1177XqAe386GOYSRzqqqHXfGUEfO4E5JIB4HU3HgyGSSyurTV9UstStLRbP+0YpI3mniHOJRIjI5zk5K5BJxjJqWz8I2+naTc2un6jqFvdXc/2m41ISq9xLLgDcxdSh4AG3btAAAAprT5f/JX/AK8/IT1f3flb+vLzMseJL3Tr3V9H8aPZmO30xtQXULBHhV4ASsgMbM5RlOOjMCD2xiuVtk1qy8O+CYfEWn21voOn3lqEuYJd1yTjy7bzYsBYslk3lHk57AEkd9Y+ELG3F++pXF1rNzqMH2a6uNQZC0kI3YjCoqoq/M3CqM5JOTVSDwDar9ihvdY1bUNPsJEltdPupozFGyHKElUEkm0gECR2GQD2px0evl+Df6bedxS1Tt5/ikvzvf5WPOfHvjPw14q0fWLmTX9LWLTG+z6bZveRiWabeFln2E7sAbkXjpvbkMMe1Wl5bahZxXdhcRXVtMoeKaFw6Op6EMOCPpVTX9Ft/EWh3OlXryxwXIAdoSAwwwbgkEdR6Vo0ug+twooooAK5v4cf8ks8Kf8AYFs//RCV0lc38OP+SWeFP+wLZ/8AohKAE8BDb4buQM8azqo5Of8AmIXFdLXN+A/+Rduv+w1qv/pwuK6SgArn/HWlPrHgrUYLdd11FGLm1x1E8REkf/jyCugopO9tBrfU8XutUdJo/ibp6zM+sedpltG2f9W0QFuMY4zcRcH/AKbV02j6Mmh+OtP0e3+YWfhT7ODjG4rMoz+J5/GvQqKGk9F/WjX6t+Ytbf13T/RI8Ss7jT9Q+EXgnSmmt7iey1fT7a/s94Z4H8wgxyp1U8EYYc813rQxQfGe3eCNI2n0GQSlVALhJ49ufpubH1rsKKq+t/Nv742/4Imr/cl9zuFFFFIYVzfgP/kXbr/sNar/AOnC4rpK5vwH/wAi7df9hrVf/ThcUAdJRRRQAUUUUAFRXP8Ax6Tf7jfyqWggMpDDIPBB71MleLQ07O5yHwo/5JL4b/68I/5V0mpx6lLZldGu7W0udwxJd2rTpjuNiyIc++78KltLS2sLSK1sbeK2t4V2xwwoERB6BRwBU1XJ8zbEtEcF8OLfxClveveappktkNXvxLDFpskcjP8AaJMkOZ2CjdzgqcDjJ613csscELyzOsccalndzgKB1JPYU6ggMpDDIPBB70nsHVvuzgNYiuNE8b+HLyTV59da+vGt4rK7EebZHRi00IiVB8oABZw52kgMMnPf1maX4a0LRLiWfRdF07TppuJZLS0SJpO/JUDP41p0dLB1uFFFFABRRRQBzfxH/wCSWeK/+wLef+iHrpK5v4j/APJLPFf/AGBbz/0Q9dJQAUUUUAFFFFABRRRQBFc/8ek3+438q8lMN1N+ytYiy3eYmn28rFU3kRpIjOdvfCBjjvXr5AZSGGQeCD3qG0tLaws47Wxt4ra2iXbHDCgREHoFHAFLv8vwuO+xw5jGi+MPDX9ha3fagurmT7ZBc373KTQCJn+0KGYiPD7B8gVTvxjpjvqz9M8P6Noss8mj6TY6fJcHdM9rbJEZT6sVAz171oVTZOvUKKKKQwooooAKKKKAOE0zwzY6z4t8YXF5Pqkbrq0SAWerXVqmPsFoeUikVSeepGegzwK1/wDhA9I/5/PEH/hR6h/8fo8L/wDIxeM/+w1H/wCm+zrpKAOb/wCED0j/AJ/PEH/hR6h/8fo/4QPSP+fzxB/4Ueof/H66SigDm/8AhA9I/wCfzxB/4Ueof/H6P+ED0j/n88Qf+FHqH/x+ukooA5v/AIQPSP8An88Qf+FHqH/x+j/hA9I/5/PEH/hR6h/8frB+J8/imyt4LzS9Xh0/SY7qzSSOCM/abhnuFRlLk4RMMPujJ5BOOuh4+8Qf2dPpGji+l08apNJ51xbqWnWGNcssSqCxdmZEG0EjcSOcUul/Ow7al7/hA9I/5/PEH/hR6h/8fo/4QPSP+fzxB/4Ueof/AB+l8HXGjTWt2mhajqNykUoWa31OW4ee3fHQi4/erkYOG47jqc9HVNWEc3/wgekf8/niD/wo9Q/+P0f8IHpH/P54g/8ACj1D/wCP10lFIDm/+ED0j/n88Qf+FHqH/wAfo/4QPSP+fzxB/wCFHqH/AMfrpKKAOS8D2EOmap4utLZ7h4o9aTa1zcyXEhzYWh5kkZmPXuTgcdBXW1zfhf8A5GLxn/2Go/8A032ddJQAUUUUAFFFFABXHeLJE0rxr4Z1y/k8rTYftNnNK3CQyTBPLdj/AAglCmTxlwO9djTZYo54XimRZI3Uq6OMhgeoI7ijzGcj8TLmGfwPeaNDKr6hrUf2OxgU5eWR+NwHXCj5iegCk116KVjVSckADNZuleGdB0KSSTQ9E07TXkGHaztI4S/1KgZrTo6CCiiigAooooAKKKKAOb+HH/JLPCn/AGBbP/0QldJXN/Dj/klnhT/sC2f/AKISukoAKKKKACiiigAooooAKKKKACiiigAooooA5LxxYQ6nqnhG0uXuEik1p9zW1zJbyDFhdniSNlYdOxGRx0NWf+ED0j/n88Qf+FHqH/x+jxR/yMXgz/sNSf8ApvvK6SgDm/8AhA9I/wCfzxB/4Ueof/H6P+ED0j/n88Qf+FHqH/x+ukooA5v/AIQPSP8An88Qf+FHqH/x+j/hA9I/5/PEH/hR6h/8fpPGeoXUEWk6Zp87202saglm1xHjfFHseSQqT0bbGQD2LZ7VS06Kbw58RIdFgvr250zUdOkuY4r26kuWhmidFbbJIzPhlkHBJAK8YyaFq7f1org9P687F7/hA9I/5/PEH/hR6h/8fo/4QPSP+fzxB/4Ueof/AB+srxvqEFt4m0e28Q6vNo/h2aCcyXEd41oslyCnlxvOpVkG3zCAGAYjBzgA40fi290/4cif+1mMV/rDWGlardYLi1LnEx3D5yEWQqSDuwpOc5KWv9edv68tQ6/12v8A156HXf8ACB6R/wA/niD/AMKPUP8A4/R/wgekf8/niD/wo9Q/+P1h2Wu6HoWia9faPqOs3V3puntdT2WsyXXmNtUlZBHcAMoJBGUAT24GIr601Dwzpmh+ITrGo3F7NeWsWqJNdPJBOs7rGwWEnZHtZwV2AH5cHOTmra29Px2E7pX9fwOh/wCED0j/AJ/PEH/hR6h/8fo/4QPSP+fzxB/4Ueof/H6xPHWg2tppzHTrzWk1jVrlbWz2a9eqiSyE5fy1mChUXc5UDGExiu206zGnaZbWYnnuBbxLH51zIZJJMDG5mPJJ6k0lqrjejsYn/CB6R/z+eIP/AAo9Q/8Aj9H/AAgekf8AP54g/wDCj1D/AOP10lFAHN/8IHpH/P54g/8ACj1D/wCP1F8OrdG+FvhUkyc6NZniVh/yxT3rqa5v4cf8ks8Kf9gWz/8ARCUAHgP/AJF26/7DWq/+nC4rW1XW9K0K2W51zU7PTYHfYst5cJCrNjOAWIGcA8e1ZHgLP/CN3O4AH+2dVyAc/wDMQuKr+M/+Rj8F/wDYZb/0lno6pD6N+T/BG9pWu6RrsLTaJqllqUSHDPZ3CSqp9ypNX64vx3bw2F/oOv2cYj1WPVbazEsa4eeGZ9kkTEcsu1i+D0KA9qjsvF+qSN4l1HUGsbXR/D17cRShbd3mnijiD8HzAFYZ64OemF6lXVm+1/wt/mhWd0u/63/yO4org7zxF4t0nwuvirUo9JbT44lubrTIoZBPBCeWInMhV2VTnHlgHBAPQ1ck13xFqPjbVdB0X+z7WCytba4W9urd5sGTfldiyJuzs67l2/7WeKaa0YXW52FFcIvjzUU0ySzmsbVvEK6uNGWNZCLeSUoJfNyfmCeUd+3k5G3J61fTWNf0bxNpmmeI5NOvrfVjJFb3VjbPbmKZEMmxkaSTcCqsQwIwVwRzml5/1tf8mH9fodZRXCQ+ONSk+Dv/AAlhgtft+1j5YRvK4nMfTdnp79arWseuN8d9TCalYi1XSrZ2iaxcsYjLL8obzsB+Dl8EHj5eOT7Sj/W1w+y3/W9j0Sub8B/8i7df9hrVf/ThcV0lef8AhO78VRaXfJpWjaPc2g1rVPLludXlhkb/AE+fOUW2cDnI+8cjnjoAD0Ciub+3eN/+he8P/wDg+n/+Q6Pt3jf/AKF7w/8A+D6f/wCQ6AOkorm/t3jf/oXvD/8A4Pp//kOj7d43/wChe8P/APg+n/8AkOgDpKK5v7d43/6F7w//AOD6f/5Do+3eN/8AoXvD/wD4Pp//AJDoA6Siub+3eN/+he8P/wDg+n/+Q6Pt3jf/AKF7w/8A+D6f/wCQ6AOkorm/t3jf/oXvD/8A4Pp//kOj7d43/wChe8P/APg+n/8AkOgDpKK5v7d43/6F7w//AOD6f/5Do+3eN/8AoXvD/wD4Pp//AJDoA6Siub+3eN/+he8P/wDg+n/+Q6Pt3jf/AKF7w/8A+D6f/wCQ6AOkorm/t3jf/oXvD/8A4Pp//kOj7d43/wChe8P/APg+n/8AkOgA+I//ACSzxX/2Bbz/ANEPXSV534+vPGLfDbxKt5oWhxW50m6EskWtTO6r5LZKqbVQxA6AkZ9R1r0SgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOb8L/wDIxeM/+w1H/wCm+zrpK4TTLnxHD4t8YLoelaXeW/8Aa0RaS81OS3cN9gtMgKsEgIxjnI6njjJ1/t3jf/oXvD//AIPp/wD5DoA6Siub+3eN/wDoXvD/AP4Pp/8A5Do+3eN/+he8P/8Ag+n/APkOgDpKK5v7d43/AOhe8P8A/g+n/wDkOj7d43/6F7w//wCD6f8A+Q6AGfEHSL7XPCos9Lg8+f7daS7N6r8qXEbscsQOFUn8Kb4r0a8l17QvEWl2ovrjRnmD2e5VeaKVNreWzEKHBCkZIBGRkZqX7d43/wChe8P/APg+n/8AkOj7d43/AOhe8P8A/g+n/wDkOhafn+gEfh3Tr+XxTq3iPUrE6Yb6CC2is3kR5AkRc75ChK7iZCAAzYAHPOB1Fc39u8b/APQveH//AAfT/wDyHR9u8b/9C94f/wDB9P8A/IdAHSUVzf27xv8A9C94f/8AB9P/APIdH27xv/0L3h//AMH0/wD8h0AdJRXN/bvG/wD0L3h//wAH0/8A8h0fbvG//QveH/8AwfT/APyHQAeF/wDkYvGf/Yaj/wDTfZ10lcl4HkvpdU8XPqtvb212daTzIra4aaNf9AtMYdkQnjB+6MHjnqetoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOb+HH/JLPCn/YFs//AEQldJXN/Dj/AJJZ4U/7Atn/AOiErpKACiiigAooooAKKKKACiiigAooooAKKKKAOb8Uf8jF4M/7DUn/AKb7yukrkvHEl9FqnhF9Kt7e5uxrT+XFc3DQxt/oF3nLqjkcZP3Tk8cdRZ+3eN/+he8P/wDg+n/+Q6AOkorm/t3jf/oXvD//AIPp/wD5Do+3eN/+he8P/wDg+n/+Q6AH+MNJvNQs9PvNJjWa/wBKvo72GFn2CYAMjpuPAJR3AzxnGeOaoQW+s6h4kl8T3Oiy2jWOmyW1hptxcRedNI7B3LMjOiA+XGoO4nliQO9z7d43/wChe8P/APg+n/8AkOj7d43/AOhe8P8A/g+n/wDkOltt/V1b8g33/rW5m3NvrsHiyx8US6DJfiTSltpNPguITNYTFtz7GkZEYHIViGB+QYBB4yf+EJ1e40q4vxZWtpdp4gj1yy0kyAogVFVo2YfKHf52yMqHYHJ5NdR9u8b/APQveH//AAfT/wDyHR9u8b/9C94f/wDB9P8A/IdNabf1rf8AMHrv/WlvyMm78PX3jTWLi81fS5tFtDpFxpix3EkTzymcruY+UzqFXYMfNkkngY5YLDxHr+n6Noms6O1imn3NvPf3zXEbxXPkEMohCsXO51UneqYGep4rZ+3eN/8AoXvD/wD4Pp//AJDo+3eN/wDoXvD/AP4Pp/8A5DoWlrf1Zt/mweu/9XVv0HXOl3l78RbG/nh/4lum2EnkOWUhrmVgCducgrGhGcYxIQO9dFXN/bvG/wD0L3h//wAH0/8A8h0fbvG//QveH/8AwfT/APyHR0sHW50lFc39u8b/APQveH//AAfT/wDyHR9u8b/9C94f/wDB9P8A/IdAHSVzfw4/5JZ4U/7Atn/6ISj7d43/AOhe8P8A/g+n/wDkOovh00//AAq3wrtjjI/sazwTIR/yxT/ZoAl8B/8AIu3X/Ya1X/04XFS+KPD97rcmk3GmahBY3Wl3n2qNri1Nwj/u3j2lRIh6OTnd2qLwH/yLt1/2GtV/9OFxXSUAc/beHLu51K01HxNqUeo3Fkxe2htrY29vE5BXzNhd2L4JAJYgZOAM0mmeEoLO18QWt7KLy31y8muJYzHtCpIioY+pzwvXjr0roaKVl+n9fcH9f195xreDNXu9JTQdW8RpeaEqrG8Qsdl1cRLj93JN5hUggYYrGpI7g81RjstVm+KniSTQtTgsZksrFWW6tTcQup83qiuhDDHBDY5OQeMegUVTbe4rHJDwFF/YX2b+0rj+1P7Q/tT+09i7/tX97Yfl27fk2/3eM55q1aeHNRuNatNU8T6rb6hLYBzZw2dkbaKN2Xa0jBpJGZ9pKj5gAGPGea6OikPc4Cf4b38nhe78MweIlh0WSUy28YsczxAy+b5bSeZh0ByMBVOMAk8535/Dl0vjhfEWm38MHm2qWl5bz2xl82NHZlKMHXY3zsMkMOnHHPQUULS3l/wwd/MK5vwH/wAi7df9hrVf/ThcV0lc34D/AORduv8AsNar/wCnC4oA6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA5v4j/wDJLPFf/YFvP/RD10lc38R/+SWeK/8AsC3n/oh66SgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOb8L/8jF4z/wCw1H/6b7Oukrm/C/8AyMXjP/sNR/8Apvs66SgAooooAKKKKAGTSpBA80rbY41LMx7ADJNcfYeO72ddHvr/AEL7Jo2typFZXAu/MnUyDMfnRbAEDAfwu+CRnHOOj1++fS/DepX8dq149rayzLbqMmUqpO3HvjFeYR2C6D4e8F6tF4hbVrb7bbLaaS2w2/747P8AR9o8wmJXYqHaQAKenBBHWVvNfi3/AEvxCWkb+v4L+rnr9FFFABRRRQAUUUUAc34X/wCRi8Z/9hqP/wBN9nXSVzfhf/kYvGf/AGGo/wD032ddJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc38OP+SWeFP+wLZ/+iErpK5v4cf8ks8Kf9gWz/8ARCV0lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHN+KP+Ri8Gf9hqT/033ldJXN+KP+Ri8Gf9hqT/ANN95XSUAFFFFAGX4g1yPQdPSdoXuZ55kt7W2jIDTSucKuTwB1JJ6AE9qpaP4jvbjxBLoev6ZFp+oLbC7i+zXRuIZot20lXKIQytgEFR94EE9qXjwi2uPDOpTkLaWOtRtcOxwqCSOSJWJ7APInPvUd7cQSfFq1mE0aRaTolw97KXAWISyRlAx7ZETtz2XNEd9fP8I3CXl5fnY09b8Q3VlrNnoui6dHqGp3UMlxtnufIhiiQqCzuFdskuAAFOec4AzWbN49ZPBt3qyaUft9nfLp0thLPtAuDKkeBIFOV+cMGC5I7A8Cjq7p4i+Jel2thqr6W0OlNeWupWRjaS8SRtrRoXDRsg2oxyrHJQgjqa/hPTdK1jw7rXh3V5hfWllrTINQjuHhe8myk28yIwPmrI207SBlOAo+UEU2v66St/wPUHo/u/K/8AXkdZDq2q2OnX9/4qsdP0+1s4TMXsr+S6JVQSxIaGPGAO2c+1Zlv4w1OOfTJta0FLDS9VkWK2uFvfNlidxmMTR7AE3dPld8MQD1zWdZ2cA8V694Vk1G51Hw++lLJdxXt01w1nI5ZSnmuS+HQFtrMdu3IwDWZr2kaqT4X0GbxHBqgGo2s9pFDZiOV4YGEjSzOHYMoVcZVUBZl9QKI6yXZ2/Np/8DoEtE11V/yTX/BOj1P4iWFj4zsPDdtZXl3c3F2LWe4ETJBbMYzIAXIwzFRnaueM5I79fXGePP8AkP8Agn/sOj/0nmrs6I/D8/0X+Y5fFp2/VhRRRQIK5v4cf8ks8Kf9gWz/APRCV0lc38OP+SWeFP8AsC2f/ohKAE8BEN4buSpBB1nVSCO//EwuK6Wub8B/8i7df9hrVf8A04XFdJQAUUUUAFFFFABRRRQAUUUUAFc34D/5F26/7DWq/wDpwuK6Sub8B/8AIu3X/Ya1X/04XFAHSUUUUAFFFFABWN4nvNetNMU+F9Ptbu8kfaXvJzHFbrtJ8xgBufBAG0YJz1FbNR3ALWsoUZJQgAd+Kmd+V2KjuYPw/wBWvNd+Hui6pqkolvLu0SWZwgUMx68DgV0Vct8M7S5sPhj4ftb63ltriGyRZIZkKOhx0KnkGt7U9Mg1azNrdSXUcZYNutLuW2fI/wBuJlbHtnFaT+J2IjsR6Rq9vrVtPPapIiwXU1qwkABLxSNGxGCeMqce3pV+uM8D+CU0Bbi4uW1NLj+0LuSJJdXuJo2ieZyjGMylGJUg5Ybs8nmuk1yzvtQ0K7s9J1D+zLyeIpFeeT5vkk/xBcjJx0561L0WhX2mulzk7jxVqd18U9J07TpVTQt9zbXDbAftVwke5gCRkCMgLkHliwP3a7uvMj4X8U6V4n8G21ve6XJY6eZ0D2+izKsKeVg7ybluW5AJI+Y5O7pXptBKvcKKKKBhRRRQBzfxH/5JZ4r/AOwLef8Aoh66Sub+I/8AySzxX/2Bbz/0Q9dJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHCaZ4s8OaD4t8YWuua/pem3D6tFIsV5exwuymwtAGAYg4yCM+xrX/wCFj+CP+hy8P/8Ag0g/+Ko8L/8AIxeM/wDsNR/+m+zrpKAOb/4WP4I/6HLw/wD+DSD/AOKo/wCFj+CP+hy8P/8Ag0g/+KrpKKAOb/4WP4I/6HLw/wD+DSD/AOKo/wCFj+CP+hy8P/8Ag0g/+KrpKKAOb/4WP4I/6HLw/wD+DSD/AOKrMtPEXwq0/U5NSsNY8HWt9LnzLqG6tUlfPXLg5P512VxcwWcJmu544IgQC8rhVBJAAyfUkD6mlnnhtbeSe5lSGGNSzySMFVAOpJPAFHmG+hz/APwsfwR/0OXh/wD8GkH/AMVR/wALH8Ef9Dl4f/8ABpB/8VWvpes6XrlobrRNStNRtwxQzWk6yoGHUZUkZ5HHvV2gDm/+Fj+CP+hy8P8A/g0g/wDiqP8AhY/gj/ocvD//AINIP/iq6SigDm/+Fj+CP+hy8P8A/g0g/wDiqP8AhY/gj/ocvD//AINIP/iq6SigDkvA+pWOr6p4uvtKvLe+tJdaTy7i2lWSN8WFoDhlJBwQR9RXW1zfhf8A5GLxn/2Go/8A032ddJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc38OP8AklnhT/sC2f8A6ISukrm/hx/ySzwp/wBgWz/9EJXSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAcl441Kx0jVPCN9qt5b2NpFrT+ZcXMqxxpmwuwMsxAGSQPqas/8LH8Ef9Dl4f8A/BpB/wDFUeKP+Ri8Gf8AYak/9N95XSUAc3/wsfwR/wBDl4f/APBpB/8AFUf8LH8Ef9Dl4f8A/BpB/wDFV0lFAHLz+P8AwFdW8lvdeLfDk0MqlJI5NSgZXU9QQWwRVOy8U/DDTdMk07Ttd8JWljLu32sF5bJE+4YbKA4OR145rsZZY4IXlnkWOONSzu5wqgckknoKqaVrela7bNcaJqdnqMCttaWzuFlUH0JUkZoC5y974l+FupadDp+o614Qu7KAARW091avHGAMDapOBgccVJJ4s+Gc2kf2VNr/AITk07bs+xte2xh2+mzO3Htium1PV9N0Sz+16zqFrp9tuC+ddzrEmT0G5iBmp7e6t7q1jurWeOa3kUOksbhkZTyCCOCPejuGzRymm+MfhtotmLTR/EXhWwtgSwhtb62iQE9TtVgKj0zxR8L9FknfR9c8I6e9w26ZrW7tojKfVipGTz3rpNL8QaNrhmGi6tY6ibchZhaXKS+WTnAbaTjoevpRbeINGvNWm0u01axn1C3z51pFco0seOu5Acj8RT1uLQxLjx18PrqSCS68U+GZnt5PNhaTUbdjE+CNyktwcEjI7E1P/wALH8Ef9Dl4f/8ABpB/8VWlceI9DtNXj0q61nT4NRlx5dnJdIsz56YQncc/StKl0Gc3/wALH8Ef9Dl4f/8ABpB/8VR/wsfwR/0OXh//AMGkH/xVdJRQBzf/AAsfwR/0OXh//wAGkH/xVRfDq5gX4W+FQ00YI0azBBccfuUrqa5v4cf8ks8Kf9gWz/8ARCUAHgP/AJF26/7DWq/+nC4rpK5vwH/yLt1/2GtV/wDThcV0lABRRRQAUUUUAFFFFABRRRQAVzfgP/kXbr/sNar/AOnC4rpK5vwH/wAi7df9hrVf/ThcUAdJRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc38R/+SWeK/wDsC3n/AKIeukrm/iP/AMks8V/9gW8/9EPXSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfhf8A5GLxn/2Go/8A032ddJXN+F/+Ri8Z/wDYaj/9N9nXSUAFFFFABRRRQB5r8XPDdnc6fba9cy3ctxa31jHbwNcN5EJN0gLiMcbyGI3HPHTFXfiDdTz+KPCuhxWA1GO7mnuntHcJFM0KKUErYOEDOHPB5ReCeK6PxX4e/wCEn0Mad9p+y/6TBceZ5e//AFUqyYxkdduM9s96PEPh46xLYXtldfYdU02VpbS5MfmKNylXR0yNyMp5AIPAIIxSW3zv+C/Ubf5f5lfw7rkl9rWp6bqukxaZrFosTzCCbzo54m3eW6ybULDKuMFQQQfXNdFWHoXh+bTtQvdU1W+W/wBUvlSOWaODyY0jTO1I03MVGWY8sxJJ56AblUyQooopDCiiigDm/C//ACMXjP8A7DUf/pvs66Sub8L/APIxeM/+w1H/AOm+zrpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDm/hx/ySzwp/2BbP8A9EJXSVzfw4/5JZ4U/wCwLZ/+iErpKACiiigAooooAKKKKACiiigAooooAKKKKAOb8Uf8jF4M/wCw1J/6b7yukrm/FH/IxeDP+w1J/wCm+8rpKACiiigDkfHn+kXHhnTZgDaX+sxpco33ZFSKSUIR3BaNeO+KbcRJZ/GWwktlCtqGjXC3IXjf5MsXlsfXHmOAfetvxFoS6/pqQLcNaXNvOlza3KKGMMqHKtg9R1BHcEjI61n2nhrUhd3mqajrMU2tTWZs7e5t7PyobRck5WJncklsFtzkHaowO6jo7+v4xt+YPX8PzuZfiad7X4m6Hd2enTa3cwWFyrWFvsEtursmJw0jLGMlCmCwJzxnDCuPkvTD4FGnx2cqvrPitra80eIbWtldjK1sc4ADqo3EfLiViCRye/m8KaompWus6drkUetLYpZXk9zY+bDdqp3BzEroVbcWI2tj5iCDxUI+H8Uuk3aXmpzzardX6amdRWNU8q5QKIykfQIAgXaScjOSc5ppWtfp/wDJX/Fd+umwPXb+vda/B9vzMrXPFF/o+k61ZX2iWuk6tb6FcXWmz2Nx58TRxqAyhjGjKVYodu3GMEHjh/iTS7PR/A/heXT4kSTTNR0/7M6jDHzJUjfnr86yNn1zzmt218KT3OpTah4qv4NVuHtHskjt7Q28EcLkFwELuxZsDJLdAMAc5q2Pgu/QaZaaxrg1DS9IkSWzgFp5crsgIj8+TeRJt4PyqmWAJz0prdN90/ubf5fiJ7WXn+KX/BKXxJmx4Y1TTG0G4Wxu4911rCrGYbUH70xVGMzMgAOQmMgfMACR3FsyPaxNDL50bICsm7dvGODnvnrmud1rw9rusx3env4ggh0i8Vo5Y00//ShGwIZFm8zYODgHyyQO+ea6G0tYbGygtLVPLggjWKNAfuqowB+QpLbUb3RLRRRQAVzfw4/5JZ4U/wCwLZ/+iErpK5v4cf8AJLPCn/YFs/8A0QlACeAhjw3cgkn/AInOq8nv/wATC4rpa5vwH/yLt1/2GtV/9OFxXSUAFFFFABRRRQAUUUUAFFFFABXn/hPQdRvdLvri28Waxp8T61qm22torMxpi/nHBkgZucZ5Y8nsOK9Arm/Af/Iu3X/Ya1X/ANOFxQAf8Ivq/wD0PfiD/vxp/wD8i0f8Ivq//Q9+IP8Avxp//wAi10lFAHN/8Ivq/wD0PfiD/vxp/wD8i0f8Ivq//Q9+IP8Avxp//wAi10lFAHN/8Ivq/wD0PfiD/vxp/wD8i0f8Ivq//Q9+IP8Avxp//wAi10lFAHN/8Ivq/wD0PfiD/vxp/wD8i0f8Ivq//Q9+IP8Avxp//wAi10lFAHN/8Ivq/wD0PfiD/vxp/wD8i0f8Ivq//Q9+IP8Avxp//wAi10lFAHN/8Ivq/wD0PfiD/vxp/wD8i0f8Ivq//Q9+IP8Avxp//wAi10lFAHN/8Ivq/wD0PfiD/vxp/wD8i0f8Ivq//Q9+IP8Avxp//wAi10lFAHN/8Ivq/wD0PfiD/vxp/wD8i0f8Ivq//Q9+IP8Avxp//wAi10lFAHnfj7w5qkHw28Syy+NNcuUj0m6ZoZYbEJIBCxKtttg2D0OCD6EV6JXN/Ef/AJJZ4r/7At5/6IeukoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDhNM0a+1Hxb4wls/EuqaUi6tEphs47VkY/YLQ7j5sLtnnHBxwOOudf/AIRfV/8Aoe/EH/fjT/8A5Fo8L/8AIxeM/wDsNR/+m+zrpKAOb/4RfV/+h78Qf9+NP/8AkWj/AIRfV/8Aoe/EH/fjT/8A5FrpKKAOb/4RfV/+h78Qf9+NP/8AkWj/AIRfV/8Aoe/EH/fjT/8A5FrpKKAOb/4RfV/+h78Qf9+NP/8AkWj/AIRfV/8Aoe/EH/fjT/8A5FroLiRobWWSOMysiFlRerEDoK840nxFrpsvCetS66mov4huEiuNKEEaxQhkZn8kqvmAxbfm3s3Rs7TjAtXb0/ET0V/X8Dp/+EX1f/oe/EH/AH40/wD+RaP+EX1f/oe/EH/fjT//AJFrpKKBnN/8Ivq//Q9+IP8Avxp//wAi0f8ACL6v/wBD34g/78af/wDItdJRQBzf/CL6v/0PfiD/AL8af/8AItH/AAi+r/8AQ9+IP+/Gn/8AyLXSUUAcl4HtZrLVPF1vc39xqEqa0m65uVjEj5sLQ8iNVXjOOFHA7nmutrm/C/8AyMXjP/sNR/8Apvs66SgAooooAKKKKACiiigAooooAKKKKACiiigAooooA5v4cf8AJLPCn/YFs/8A0QldJXN/Dj/klnhT/sC2f/ohK6SgAooooAKKKKACiiigAooooAKKKKACiiigDkvHFrNe6p4Rt7a/uNPlfWn23NssZkTFhdngSKy84xyp4PY81Z/4RfV/+h78Qf8AfjT/AP5Fo8Uf8jF4M/7DUn/pvvK6SgDm/wDhF9X/AOh78Qf9+NP/APkWj/hF9X/6HvxB/wB+NP8A/kWukooA5v8A4RfV/wDoe/EH/fjT/wD5Fo/4RfV/+h78Qf8AfjT/AP5FqXxbrF3ptrp9ppbIl9qt6llBK67hDkMzybe+1EYgdM4zxVHS7vVdH8cL4f1TVJdWtrywe8tbm5ijSZHjdVkQ+UiIwxIhHygjnr2Fq7f1tf8AIHp/Xnb8yz/wi+r/APQ9+IP+/Gn/APyLR/wi+r/9D34g/wC/Gn//ACLUHiK/1GbxhpPh+y1N9HgvLWe4e8iijeWR4ygEUfmKyDh2Y5UnC8Y5NZNt401ODwVPNLLbXl//AGs+k2N6y7YbgiTYJ3AIGFAcsFIB8tsYzgL+vxt+Ydf67X/I3f8AhF9X/wCh78Qf9+NP/wDkWj/hF9X/AOh78Qf9+NP/APkWqGma9bWHh7VtbTxnH4rtLC2eacRm2IidFLEKYVG0ED7rbj0565qTX3iXQrPRdd1PWDdRX91bwX+nNbxrDbLOwQGJlUSAozKPnZsjPTjFW1t6fjsJ6K/r+G5tf8Ivq/8A0PfiD/vxp/8A8i0f8Ivq/wD0PfiD/vxp/wD8i1hnUPEOuadr2tafrraWNLurmC2sfssTQyCAkEzl1LncQT8jJhSOp5PYaBq0eveHNO1eFDHHf2sdyqHqodQ2P1pLVX9Px2G9Hb1/Dcy/+EX1f/oe/EH/AH40/wD+RaP+EX1f/oe/EH/fjT//AJFrpKKAOb/4RfV/+h78Qf8AfjT/AP5FqL4dROfhb4VIuJB/xJrPgBeP3Ke1dTXN/Dj/AJJZ4U/7Atn/AOiEoAPAf/Iu3X/Ya1X/ANOFxXSVzXgI58N3JII/4nOq8Ht/xMLiuloAKKKKACiiigAooooAKKKKACub8B/8i7df9hrVf/ThcV0lc34D/wCRduv+w1qv/pwuKAOkooooAKKKKACiisTxVpN9rOk/ZrHW7rR0DFriSzVfNlj2n5Fcg+Xk4O4c8cYpSdlcaV3Y26K5H4VMW+E/htmJZjYoSSckn610ep6vpuiWZu9Z1C10+2DBTNdzLEmT0G5iBmqkuV2EtUW6K5Hwf8QdG8Tma2XW9Ilv/ttzFBbW12jPJFHIwRwu4k5RQ2Rweo4rrJSwhcxjc+07R6mpldK4dbDqK8r8CadonhiPw/ZeI/BK6Nr8iCGPVZ7S1k+0XO0lgJ4mdgxG7G/aWAI5PFeqVTVg6hRRRSAKKKKAOb+I/wDySzxX/wBgW8/9EPXSVzfxH/5JZ4r/AOwLef8Aoh66SgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOb8L/8AIxeM/wDsNR/+m+zrpK4TTNZvtO8W+MIrPw1qmqo2rRMZrOS1VFP2C0G0+bMjZ4zwMcjnrjX/AOEo1f8A6ETxB/3/ANP/APkqgDpKK5v/AISjV/8AoRPEH/f/AE//AOSqP+Eo1f8A6ETxB/3/ANP/APkqgDpKK5v/AISjV/8AoRPEH/f/AE//AOSqP+Eo1f8A6ETxB/3/ANP/APkqgDV12PUJfDuox6I6R6i1tILV36LLtOwn8cV5nbaVZ7NDHhjwtqOneKIrq3a+v5rGSBgm4G48+5YBbgMu4YDPkkEdMjt/+Eo1f/oRPEH/AH/0/wD+SqP+Eo1f/oRPEH/f/T//AJKoWkr+n4f1qD1VvX8f60Okorm/+Eo1f/oRPEH/AH/0/wD+SqP+Eo1f/oRPEH/f/T//AJKoA6Siub/4SjV/+hE8Qf8Af/T/AP5Ko/4SjV/+hE8Qf9/9P/8AkqgDpKK5v/hKNX/6ETxB/wB/9P8A/kqj/hKNX/6ETxB/3/0//wCSqADwv/yMXjP/ALDUf/pvs66SuS8D3U17qni64ubC40+V9aTdbXLRtImLC0HJjZl5xnhjwex4rraACiiigAooooAKKKKACiiigAooooAKKKKACiiigDm/hx/ySzwp/wBgWz/9EJXSVzfw4/5JZ4U/7Atn/wCiErpKACiiigAooooAKKKKACiiigAooooAKKKKAOb8Uf8AIxeDP+w1J/6b7yukrkvHF1NZap4RuLawuNQlTWn221s0ayPmwuxwZGVeM55YcDueKs/8JRq//QieIP8Av/p//wAlUAdJRXN/8JRq/wD0IniD/v8A6f8A/JVH/CUav/0IniD/AL/6f/8AJVADPG1ldSQaTqthbyXUuj6il29vCMvJEVaOQKO7BZCwHU7cDk1QjupdW8XnxPFpupDTdJ0qaKJJrN4Z7qWRlZlSKQK/CxKBkAEvxnBrS/4SjV/+hE8Qf9/9P/8Akqj/AISjV/8AoRPEH/f/AE//AOSqSutvP8VYN/687nP68sOqeI9P1LxV4fvdQ8NzaarwWcmnPdG1uixLedbIHO7YVAbaQpDDIzzjyeFr+98M+ZFo1x/ZGm+IYtR07R7kYlNmqBXRYyflGWkdYzjjC4GQK7j/AISjV/8AoRPEH/f/AE//AOSqP+Eo1f8A6ETxB/3/ANP/APkqmtNv61v/AF5A7vf+tLf15nOajo58c69qFzptleafZz6FcabPdXlpJatcSSFfLHlyBXIjwx3FcfPgE81JPdX/AIs0fRNCbSNRtLyG7tZtUa5tXjigEDCRtsrAJLuZAo8stw2TgCt//hKNX/6ETxB/3/0//wCSqP8AhKNX/wChE8Qf9/8AT/8A5KoWlrdP0bf5sHd/15JfoYHinT9Mub7UotN8PatNrt0NoRVuYrG4fbtWWZlIt3AGM78vhcbc4FdnoGkx6D4c07SIXMkdhax2yuerBFC5/Ssv/hKNX/6ETxB/3/0//wCSqP8AhKNX/wChE8Qf9/8AT/8A5KoWisD1dzpKK5v/AISjV/8AoRPEH/f/AE//AOSqP+Eo1f8A6ETxB/3/ANP/APkqgDpK5v4cf8ks8Kf9gWz/APRCUf8ACUav/wBCJ4g/7/6f/wDJVRfDqVx8LfCoFvIf+JNZ8grz+5T3oAl8B/8AIu3X/Ya1X/04XFdJXN+A/wDkXbr/ALDWq/8ApwuK6SgAooooAKKKKACiiigAooooAK5vwH/yLt1/2GtV/wDThcV0lc34D/5F26/7DWq/+nC4oA6SiiigAooooAKZMhkgkRerKQM/Sn0UmrqzGnZ3MLwTolz4b8D6Ro188UlxZWywyNCSUJHoSAcfgK3aKKpu7uLYy9A0b+w7O5g8/wA/z724u92zbt82VpNvU9N2M98dBWk+/wAtvL2h8HaWGRn3p1FIOtzkptI8ReINT03/AISCLS7Gx027W822VzJcSXMiAhAd0aCNQTuIG8nAGQM562iigOtwooooAKKKKAOb+I//ACSzxX/2Bbz/ANEPXSVzfxH/AOSWeK/+wLef+iHrpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA5vwv8A8jF4z/7DUf8A6b7Oukrm/C//ACMXjP8A7DUf/pvs66SgAooooAKKKKAOc8TePPD/AITuLa11a+X7bdSRxw2cPzzNvYKG2/wrn+I4HGOvFaet63a6Dp4urwSvvkWKGCBN8k8jfdRF7k/kACSQATXLfFW0t18JG7WCIXL3+nxtMEG9lF3GQpbrgEnj3qPxxHe3PxC8GWtpdiyjla9P2nyw7RyCEY2BgV37DLjcCBycHoUtV8/0THpf5HW6Rqk2pwyG60m+0qWNgDDeiMkgjhg0buhHtuyMcgcZ0K5Xw3fapB4r1jw9qmoNqsdnDBcwXskSJLtlLgxyCNVQkGPIIUZDcjjJ6qqYvIKKKKQBRRRQBzfhf/kYvGf/AGGo/wD032ddJXN+F/8AkYvGf/Yaj/8ATfZ10lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfw4/5JZ4U/7Atn/wCiErpK5v4cf8ks8Kf9gWz/APRCV0lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHN+KP+Ri8Gf9hqT/ANN95XSVzfij/kYvBn/Yak/9N95XSUAFFFFAFHWNYtND01ry+L7AyxpHGu55XY4VFUdWJIAH9Ko6N4oh1XU59MudPvdK1KCJZzaXwj3NETgOrRu6MMjBw2QeoGRWd44+XUvCUsn/AB7R65H5voC0MqoT/wADZR9SKLz5/jFpXk9YtFujcEdlaaHYD9Sr4+hojq/m19yv/XkEtPuT+92NTWvEsOj3trYRWV5qeo3avJDZWSpvKJje5aRlRVBZR8zDJIAzUdt4x0i48NXGtySS21taO8d1HNGRLBKpw0bIMkvnAAGc5GM5GcPXRe6h8ULK38O3MFhqdhpjy3FzdwtNFJBLJgR+UGQsd8W7cHXbjHO7A467a+i0eDSWlhGpQeNIU1O9Yb4ZZJF82OULxgZaEBD0KgEn7xI628//AJLl/rz8geny/wDkW/68vM9U0fXJtUaQXWianpIVBIjXyxASL6gxu+0jj5W2tz04OKeheO/D/ibX73SdBvRfyWMSyTTwjdD8xI2q/RjxzjI985FUrC41bSfHkWgahq0utWd9YS3SSXUMSTW7RuilT5SIpRhJxlcgqeTnitpFtBZ/GbVLezgjt4I9AtFSKJAqoPOm4AHAp7yXZ3/BP/INovurfi1/mbOo+K0tNWk03T9J1HWLqBFkuVsFjxbhvu7mkdBuI52qS2OcYIzuxyCWJJFDAOoYBlKkZ9QeQfY15f4dstdvF8Y3lp4ibSJ7fW7siJLeJ1cqF2GcyKzFfLEYAQphe/PHe+F9Wl17wlpWrXEAt5b60ineIZwhZQSBntzxSWsU/R/erg9JW9V9xq0UUUAFc38OP+SWeFP+wLZ/+iErpK5v4cf8ks8Kf9gWz/8ARCUAHgP/AJF26/7DWq/+nC4rpK5r/hAfB95JNc3fhPQ555ZpHkll02Fmdi5ySSuSfel/4Vx4I/6E3w//AOCuD/4mgDpKK5v/AIVx4I/6E3w//wCCuD/4mj/hXHgj/oTfD/8A4K4P/iaAOkorm/8AhXHgj/oTfD//AIK4P/iaP+FceCP+hN8P/wDgrg/+JoA6Siub/wCFceCP+hN8P/8Agrg/+Jo/4Vx4I/6E3w//AOCuD/4mgDpKK5v/AIVx4I/6E3w//wCCuD/4mj/hXHgj/oTfD/8A4K4P/iaAOkrm/Af/ACLt1/2GtV/9OFxR/wAK48Ef9Cb4f/8ABXB/8TUVv8OvBLRknwdoB+dxzpcP94/7NAHU0Vzf/CuPBH/Qm+H/APwVwf8AxNH/AArjwR/0Jvh//wAFcH/xNAHSUVzf/CuPBH/Qm+H/APwVwf8AxNH/AArjwR/0Jvh//wAFcH/xNAHSUVzf/CuPBH/Qm+H/APwVwf8AxNH/AArjwR/0Jvh//wAFcH/xNAHSUVzf/CuPBH/Qm+H/APwVwf8AxNH/AArjwR/0Jvh//wAFcH/xNAHSUVzf/CuPBH/Qm+H/APwVwf8AxNH/AArjwR/0Jvh//wAFcH/xNAHSUVzf/CuPBH/Qm+H/APwVwf8AxNH/AArjwR/0Jvh//wAFcH/xNAHSUVzf/CuPBH/Qm+H/APwVwf8AxNH/AArjwR/0Jvh//wAFcH/xNAHSUVzf/CuPBH/Qm+H/APwVwf8AxNH/AArjwR/0Jvh//wAFcH/xNAB8R/8Aklniv/sC3n/oh66SuWufh14JW0mK+DtABCMQRpcPHH+7Uv8AwrjwR/0Jvh//AMFcH/xNAHSUVzf/AArjwR/0Jvh//wAFcH/xNH/CuPBH/Qm+H/8AwVwf/E0AdJRXN/8ACuPBH/Qm+H//AAVwf/E0f8K48Ef9Cb4f/wDBXB/8TQB0lFc3/wAK48Ef9Cb4f/8ABXB/8TR/wrjwR/0Jvh//AMFcH/xNAHSUVzf/AArjwR/0Jvh//wAFcH/xNH/CuPBH/Qm+H/8AwVwf/E0AdJRXN/8ACuPBH/Qm+H//AAVwf/E0f8K48Ef9Cb4f/wDBXB/8TQB0lFc3/wAK48Ef9Cb4f/8ABXB/8TR/wrjwR/0Jvh//AMFcH/xNAHSUVzf/AArjwR/0Jvh//wAFcH/xNH/CuPBH/Qm+H/8AwVwf/E0AdJRXN/8ACuPBH/Qm+H//AAVwf/E0f8K48Ef9Cb4f/wDBXB/8TQAeF/8AkYvGf/Yaj/8ATfZ10lctF8OvBJknB8HaAcOAP+JXDx8o/wBmpf8AhXHgj/oTfD//AIK4P/iaAOkorm/+FceCP+hN8P8A/grg/wDiaP8AhXHgj/oTfD//AIK4P/iaAOkorm/+FceCP+hN8P8A/grg/wDiaP8AhXHgj/oTfD//AIK4P/iaANfVtIsdcsfseqQefB5scuzey/Mjh1OVIPDKD+FJq2jWOuWQtdTgMsauJEKu0bxuOjo6kMjD+8pBrJ/4Vx4I/wChN8P/APgrg/8AiaP+FceCP+hN8P8A/grg/wDiaANTSNC07QoZY9NgZDM/mTSyyvLLM2MbnkclnOABlieBitCub/4Vx4I/6E3w/wD+CuD/AOJo/wCFceCP+hN8P/8Agrg/+JoA6Siub/4Vx4I/6E3w/wD+CuD/AOJo/wCFceCP+hN8P/8Agrg/+JoA6Siub/4Vx4I/6E3w/wD+CuD/AOJo/wCFceCP+hN8P/8Agrg/+JoAPC//ACMXjP8A7DUf/pvs66SuWi+HXgkyTg+DtAOHAH/Erh4+Uf7NS/8ACuPBH/Qm+H//AAVwf/E0AdJRXN/8K48Ef9Cb4f8A/BXB/wDE0f8ACuPBH/Qm+H//AAVwf/E0AdJRXN/8K48Ef9Cb4f8A/BXB/wDE0f8ACuPBH/Qm+H//AAVwf/E0AdJRXN/8K48Ef9Cb4f8A/BXB/wDE0f8ACuPBH/Qm+H//AAVwf/E0AdJRXN/8K48Ef9Cb4f8A/BXB/wDE0f8ACuPBH/Qm+H//AAVwf/E0AdJRXN/8K48Ef9Cb4f8A/BXB/wDE0f8ACuPBH/Qm+H//AAVwf/E0AdJRXN/8K48Ef9Cb4f8A/BXB/wDE0f8ACuPBH/Qm+H//AAVwf/E0AdJRXN/8K48Ef9Cb4f8A/BXB/wDE0f8ACuPBH/Qm+H//AAVwf/E0AHw4/wCSWeFP+wLZ/wDohK6SuWtvh14Ja0hLeDtAJKKSTpcPPH+7Uv8AwrjwR/0Jvh//AMFcH/xNAHSUVzf/AArjwR/0Jvh//wAFcH/xNH/CuPBH/Qm+H/8AwVwf/E0AdJRXN/8ACuPBH/Qm+H//AAVwf/E0f8K48Ef9Cb4f/wDBXB/8TQB0lFc3/wAK48Ef9Cb4f/8ABXB/8TR/wrjwR/0Jvh//AMFcH/xNAHSUVzf/AArjwR/0Jvh//wAFcH/xNH/CuPBH/Qm+H/8AwVwf/E0AdJRXN/8ACuPBH/Qm+H//AAVwf/E0f8K48Ef9Cb4f/wDBXB/8TQB0lFc3/wAK48Ef9Cb4f/8ABXB/8TR/wrjwR/0Jvh//AMFcH/xNAB4o/wCRi8Gf9hqT/wBN95XSVy0vw68EiSADwdoAy5B/4lcPPyn/AGal/wCFceCP+hN8P/8Agrg/+JoA6Siub/4Vx4I/6E3w/wD+CuD/AOJo/wCFceCP+hN8P/8Agrg/+JoA2tT0yz1nTpbDU7dbi2mADxtnscggjkEEAgjkEAiqFp4S0aysb21jtpZFv4jDdS3NzLPNMmCNrSuxcgBmwN3GTjGaqf8ACuPBH/Qm+H//AAVwf/E0f8K48Ef9Cb4f/wDBXB/8TSsgJ7nwXoVza2MBtZYf7PgFvazWt3NBNFEABsEsbB9vAyC3OOamh8K6Hb6DNo0emw/YJyWmibLGVicl2Yncz5AO4ndkA54ql/wrjwR/0Jvh/wD8FcH/AMTR/wAK48Ef9Cb4f/8ABXB/8TT3FZF/R/DWl6HLLNYQzNcTALJcXVzLczMo6L5krM20ZOFzgZPFWE0ixj1ybWEgxfzwJbSTb2+aNWZlXGccFm5xnmsj/hXHgj/oTfD/AP4K4P8A4mj/AIVx4I/6E3w//wCCuD/4mgZY1PwZoWsX0l3f2kjSTKFuFiuZYo7lR0E0aMFlAHGHDccdK20RY41SNQiKAFVRgAegrnP+FceCP+hN8P8A/grg/wDiaP8AhXHgj/oTfD//AIK4P/iaAOkorm/+FceCP+hN8P8A/grg/wDiaP8AhXHgj/oTfD//AIK4P/iaAOkrm/hx/wAks8Kf9gWz/wDRCUf8K48Ef9Cb4f8A/BXB/wDE1tW1tA1pCWhjJKKSSg54oA//2Q==)"
      ],
      "metadata": {
        "id": "497jFoYATOJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![수정_그래프.JPG](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "-m9tXeIjTRpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체적으로 CNN을 사용한 모델이 성능이 더 좋았고, CNN의 9번째 모델이 accuracy 0.8714로 비교적 가장 좋은 성능을 보여줍니다."
      ],
      "metadata": {
        "id": "Y9hS1M8zTVc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "연속형 데이터들의 평균과 표준편차 값 ▼"
      ],
      "metadata": {
        "id": "e0Ro6vE3YEj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n",
        "# 제곱값을 취했기 때문에 값이 큽니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "IbB8Fd6pYPsL",
        "outputId": "53aff6ba-b98d-4a51-93f9-a3b020f1d38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             DI1_dg           sex           age       HE_sbp        HE_dbp  \\\n",
              "count  46354.000000  46354.000000  46354.000000  46354.00000  46354.000000   \n",
              "mean       0.347910      0.592009   2850.478988  14246.06733   5725.101507   \n",
              "std        0.476312      0.491467   1632.110824   4091.54374   1439.500727   \n",
              "min        0.000000      0.000000    361.000000   5112.25000   1444.000000   \n",
              "25%        0.000000      0.000000   1444.000000  11342.25000   4761.000000   \n",
              "50%        0.000000      1.000000   2704.000000  13456.00000   5625.000000   \n",
              "75%        1.000000      1.000000   4096.000000  16384.00000   6561.000000   \n",
              "max        1.000000      1.000000   7921.000000  51984.00000  21904.000000   \n",
              "\n",
              "             HE_PLS        HE_BMI    sm_present       pa_walk   total_sleep  \n",
              "count  46354.000000  46354.000000  46354.000000  46354.000000  46354.000000  \n",
              "mean     315.843875    575.804000      0.184623      0.559089     47.680787  \n",
              "std       82.486101    159.758407      0.387995      0.496502     17.105735  \n",
              "min       64.000000    130.951911      0.000000      0.000000      4.000000  \n",
              "25%      256.000000    461.285061      0.000000      0.000000     36.000000  \n",
              "50%      289.000000    557.790762      0.000000      1.000000     49.000000  \n",
              "75%      361.000000    668.756647      0.000000      1.000000     64.000000  \n",
              "max     2809.000000   2866.284614      1.000000      1.000000    441.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fed9ecb8-fa87-4f7c-b52c-2dd407ae661d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DI1_dg</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>HE_sbp</th>\n",
              "      <th>HE_dbp</th>\n",
              "      <th>HE_PLS</th>\n",
              "      <th>HE_BMI</th>\n",
              "      <th>sm_present</th>\n",
              "      <th>pa_walk</th>\n",
              "      <th>total_sleep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.00000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "      <td>46354.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.347910</td>\n",
              "      <td>0.592009</td>\n",
              "      <td>2850.478988</td>\n",
              "      <td>14246.06733</td>\n",
              "      <td>5725.101507</td>\n",
              "      <td>315.843875</td>\n",
              "      <td>575.804000</td>\n",
              "      <td>0.184623</td>\n",
              "      <td>0.559089</td>\n",
              "      <td>47.680787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.476312</td>\n",
              "      <td>0.491467</td>\n",
              "      <td>1632.110824</td>\n",
              "      <td>4091.54374</td>\n",
              "      <td>1439.500727</td>\n",
              "      <td>82.486101</td>\n",
              "      <td>159.758407</td>\n",
              "      <td>0.387995</td>\n",
              "      <td>0.496502</td>\n",
              "      <td>17.105735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>361.000000</td>\n",
              "      <td>5112.25000</td>\n",
              "      <td>1444.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>130.951911</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1444.000000</td>\n",
              "      <td>11342.25000</td>\n",
              "      <td>4761.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>461.285061</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2704.000000</td>\n",
              "      <td>13456.00000</td>\n",
              "      <td>5625.000000</td>\n",
              "      <td>289.000000</td>\n",
              "      <td>557.790762</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>49.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4096.000000</td>\n",
              "      <td>16384.00000</td>\n",
              "      <td>6561.000000</td>\n",
              "      <td>361.000000</td>\n",
              "      <td>668.756647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>64.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7921.000000</td>\n",
              "      <td>51984.00000</td>\n",
              "      <td>21904.000000</td>\n",
              "      <td>2809.000000</td>\n",
              "      <td>2866.284614</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>441.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fed9ecb8-fa87-4f7c-b52c-2dd407ae661d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fed9ecb8-fa87-4f7c-b52c-2dd407ae661d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fed9ecb8-fa87-4f7c-b52c-2dd407ae661d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a31acece-7a1b-43a9-9307-fbe3be106059\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a31acece-7a1b-43a9-9307-fbe3be106059')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a31acece-7a1b-43a9-9307-fbe3be106059 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# \\uc81c\\uacf1\\uac12\\uc744 \\ucde8\\ud588\\uae30 \\ub54c\\ubb38\\uc5d0 \\uac12\\uc774 \\ud07d\\ub2c8\\ub2e4\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"DI1_dg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16388.47122808311,\n        \"min\": 0.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.34790956551753893,\n          1.0,\n          0.47631228632475187\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16388.407626150463,\n        \"min\": 0.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5920093195840704,\n          1.0,\n          0.49146667828866875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15497.990878705601,\n        \"min\": 361.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2850.478987789619,\n          2704.0,\n          46354.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HE_sbp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18342.35818269747,\n        \"min\": 4091.5437396481566,\n        \"max\": 51984.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          14246.067329680287,\n          13456.0,\n          46354.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HE_dbp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15411.698196493217,\n        \"min\": 1439.5007268281315,\n        \"max\": 46354.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5725.101506881822,\n          5625.0,\n          46354.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HE_PLS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16203.16070868869,\n        \"min\": 64.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          315.84387539370925,\n          289.0,\n          46354.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HE_BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16138.586049161373,\n        \"min\": 130.9519110385199,\n        \"max\": 46354.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          575.8039999629589,\n          557.7907624550442,\n          46354.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sm_present\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16388.53444197795,\n        \"min\": 0.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.18462268628381584,\n          1.0,\n          0.3879953577272705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pa_walk\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16388.40903458618,\n        \"min\": 0.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5590887517797817,\n          1.0,\n          0.49650159867170013\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_sleep\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16355.964006188513,\n        \"min\": 4.0,\n        \"max\": 46354.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          47.68078670545033,\n          49.0,\n          46354.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- age(나이) 평균: 2850.478988  / 표준편차: 1632.110824\n",
        "- HE_sbp(수축기 혈압) 평균: 14246.06733  / 표준편차: 4091.54374\n",
        "- HE_dbp(확장기 혈압) 평균: 5725.101507  / 표준편차: 1439.500727\n",
        "- HE_BMI(체질량지수) 평균: 575.804000  / 표준편차: 159.758407\n",
        "- total_sleep(수면시간) 평균: 47.680787  / 표준편차: 17.105735"
      ],
      "metadata": {
        "id": "YktutsAtbR4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sex(성별) 남자 - 0 / 여자 - 1\n",
        "- sm_present(흡연 여부) 흡연 X - 0 / 흡연 O - 1\n",
        "- pa_walk(유산소운동 여부) 운동 X - 0 / 운동 O - 1"
      ],
      "metadata": {
        "id": "ENhteOwGaW7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MGMMKH8sHsGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리 과정 요약"
      ],
      "metadata": {
        "id": "OC07VGigSlY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 수집 -> 이상치 제거 -> 연속형 데이터들 제곱 취하기 -> 이상치 제거 -> 평균과 표준편차 값으로 z-score 정규화\n",
        "\n",
        "\n",
        "제곱을 취한 이유는 차이를 두드러지게 하기 위해서 입니다."
      ],
      "metadata": {
        "id": "5TIiCIBylhj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 처리 과정\n",
        "1. health connect에서 사용자 데이터 받아오기 (+ 키와 몸무게로 BMI 구하기)\n",
        "2. 서버로 전달\n",
        "3. 서버에서 데이터 전처리\n",
        "4. 연속형 데이터들 평균값 구하기\n",
        "5. 연속형 데이터들 제곱값 취하기\n",
        "6. 사전에 구해둔 (5/26 - 3) 평균값과 표준편차값으로 정규화하기 ( (값 - 평균) / 표준편차)\n",
        "7. AI 모델로 전처리한 데이터 전송\n",
        "8. AI 모델에서 나온 예측값을 앱으로 전송"
      ],
      "metadata": {
        "id": "jWELhmjTniOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tfjs로 모델 convert"
      ],
      "metadata": {
        "id": "hqDAmDYORDpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn9.save('/content/drive/MyDrive/hypertension_predict.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoIZC2kLRETv",
        "outputId": "84e4ab3c-0604-4b69-ed43-8c55adde60ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = keras.models.load_model('/content/drive/MyDrive/hypertension_predict.h5')\n",
        "tfjs.converters.save_keras_model(save_model, '/content/drive/MyDrive/predict_model')"
      ],
      "metadata": {
        "id": "J1sp31YWRTVf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}